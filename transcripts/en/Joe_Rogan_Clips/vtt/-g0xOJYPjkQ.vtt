WEBVTT

1
00:00:01.020 --> 00:00:05.040
<v 0>The Joe Rogan experience. It was a fake video that I sent Jamie today. These.</v>

2
00:00:05.830 --> 00:00:09.360
Yeah. They keep getting me. There's a new fake video. I think that.

3
00:00:09.360 --> 00:00:11.920
<v 1>Was the same one. I think there's, someone's took another clip from it. Oh,</v>

4
00:00:11.921 --> 00:00:15.400
is it? Those guys have been making VFX videos on YouTube for 10 plus years.

5
00:00:15.401 --> 00:00:16.160
They're really good at.

6
00:00:16.160 --> 00:00:17.000
<v 0>It. So this it's so good.</v>

7
00:00:17.100 --> 00:00:20.440
<v 2>For people who don't know, there's a YouTube channel where people, I think,</v>

8
00:00:20.510 --> 00:00:23.950
think it's a single YouTube channel, uh, that does like, yeah.

9
00:00:23.951 --> 00:00:28.950
Visual effects like fake humanoid or yes, robot,

10
00:00:29.050 --> 00:00:33.670
dog, uh, robots that kind of resembles something like Boston dynamics who do,

11
00:00:33.700 --> 00:00:35.350
this is one crazy stuff with guns.

12
00:00:35.410 --> 00:00:39.230
<v 0>And yeah, this one, they gave the robot a gun and have, see if you pull it up.</v>

13
00:00:39.231 --> 00:00:41.460
Jamie, what, what is the gentle, the, uh.

14
00:00:42.100 --> 00:00:45.660
<v 1>Corridor digital on YouTube is the guys that keep that make it quarter crew as</v>

15
00:00:45.661 --> 00:00:46.020
the YouTube.

16
00:00:46.020 --> 00:00:50.700
<v 0>Channel. I think incredible that it's not real. It looks so real. And so the,</v>

17
00:00:50.980 --> 00:00:52.220
uh, the robot, they kick it,

18
00:00:52.221 --> 00:00:55.220
they hit it with a hockey helmet or a hockey stick rather.

19
00:00:55.480 --> 00:00:56.460
Is there like long video.

20
00:00:56.460 --> 00:00:58.940
<v 1>They made a while ago? They might have made a new one,</v>

21
00:00:59.150 --> 00:01:01.260
which is one out in desert. But I think I've, I'd.

22
00:01:01.260 --> 00:01:04.490
<v 0>Seen it for, uh, I see they, they trick you with the Boston dynamics.</v>

23
00:01:04.491 --> 00:01:07.370
It's boss town. &lt;laugh&gt; bostontown dynamics.

24
00:01:07.690 --> 00:01:08.523
<v 2>&lt;Laugh&gt;.</v>

25
00:01:08.670 --> 00:01:11.130
<v 0>It looks so realistic, but here's the thing.</v>

26
00:01:11.580 --> 00:01:13.770
We're not that far off from this thing. No.

27
00:01:14.000 --> 00:01:16.650
<v 2>Okay. Okay. Let's let's let's walk it back. Let's walk it back.</v>

28
00:01:17.270 --> 00:01:19.210
It it's not realistic.

29
00:01:20.010 --> 00:01:20.470
<v 0>Uh.</v>

30
00:01:20.470 --> 00:01:21.970
<v 2>In what way? So let,</v>

31
00:01:22.420 --> 00:01:25.080
it looks human realistic so you can tell it's a human &lt;affirmative&gt; like a

32
00:01:25.081 --> 00:01:26.520
robotics person could tell it's a human,

33
00:01:26.870 --> 00:01:30.600
because it's really difficult to do that kind of motion. That kind of movement.

34
00:01:31.380 --> 00:01:32.600
<v 0>Oh, like when it's getting shot.</v>

35
00:01:32.910 --> 00:01:35.240
<v 2>Well, not the getting shot, so there's a lot of movement.</v>

36
00:01:35.260 --> 00:01:39.320
It does for the purpose of comedy, right? Like it actually is on purpose,

37
00:01:39.340 --> 00:01:43.870
trying to look like a human for comedic internet effect,

38
00:01:43.871 --> 00:01:46.510
like getting a human that's getting off and so on. Yes.

39
00:01:46.511 --> 00:01:48.350
Those qualities are like another order of.

40
00:01:48.550 --> 00:01:50.990
<v 0>Agnitude like this here, where it's like, gimme that. Come on. Gimme that.</v>

41
00:01:50.991 --> 00:01:53.790
Gimme that. Come on guys. Aw, come on. So for a term.

42
00:01:54.130 --> 00:01:54.963
<v 2>Oh yeah. &lt;laugh&gt;.</v>

43
00:01:54.980 --> 00:01:56.350
<v 0>Yeah. Ah.</v>

44
00:01:58.170 --> 00:02:02.310
<v 2>Do Brucely type of, uh, movements. Some of those are just comedic, you know,</v>

45
00:02:02.311 --> 00:02:04.780
you don't need term, uh, type robot that, right.

46
00:02:04.780 --> 00:02:09.660
<v 0>But they do have legitimate robots that can do back flips now and</v>

47
00:02:09.661 --> 00:02:10.440
do.

48
00:02:10.440 --> 00:02:13.220
<v 2>So. It's a really, it's really, it is a backli part. This.</v>

49
00:02:13.530 --> 00:02:14.363
<v 0>This one is real.</v>

50
00:02:14.730 --> 00:02:18.540
<v 2>This is all real it's manipulation. So all of these robots, uh,</v>

51
00:02:18.541 --> 00:02:20.060
depending on what we're talking about here,

52
00:02:20.080 --> 00:02:24.450
but those are remote controlled and these are single demonstrate ations that

53
00:02:24.451 --> 00:02:26.890
they've perfected. So they're,

54
00:02:26.960 --> 00:02:31.850
it's really important to distinguish between the body of the robot and

55
00:02:31.851 --> 00:02:36.130
the brain of the robot. So these bodies, unlike anything else, unlike a Roomba,

56
00:02:36.150 --> 00:02:39.610
unlike a drone who can also be very threatening the,

57
00:02:39.620 --> 00:02:43.650
these bodies somehow &lt;laugh&gt; we anthroppomorphies them.

58
00:02:43.710 --> 00:02:47.000
And they terrify us. I don't know what it is. I met spot mini in person.

59
00:02:47.390 --> 00:02:50.080
That was one of the most transformative moments in my life, really,

60
00:02:50.230 --> 00:02:54.720
because I know how dumb it is, but the experience of it,

61
00:02:54.721 --> 00:02:58.760
like it's not even a head, it's supposed to be a hand, but it looks like a head.

62
00:02:59.340 --> 00:03:04.040
And it like looking up at me with that hand, I felt like I was like, I,

63
00:03:04.620 --> 00:03:09.360
it was magic. It was like a, um, it was like Frankenstein coming to life.

64
00:03:09.620 --> 00:03:11.320
It was this moment of creation.

65
00:03:12.180 --> 00:03:15.760
And what I realized is my own brain sort of anthropomorphizing the same way.

66
00:03:15.761 --> 00:03:18.400
You're like looking at these robots and you're thinking these things,

67
00:03:18.650 --> 00:03:22.670
it terrifying. Yeah. Like what's like, you know, in 10, 20 years,

68
00:03:22.671 --> 00:03:27.070
where are we gonna be? Yeah. The that's our brain playing tricks on us.

69
00:03:27.630 --> 00:03:31.910
Cuz the key thing that's a threat to humanity or an exciting possibility for

70
00:03:32.150 --> 00:03:35.110
humanity is the intelligence of the robots, the brains, the mind,

71
00:03:35.770 --> 00:03:40.380
and these robots have very, very little intelligence. So one of,

72
00:03:40.560 --> 00:03:43.540
so in terms of being able to perceive and understand the world,

73
00:03:44.090 --> 00:03:45.700
very importantly, very importantly,

74
00:03:45.701 --> 00:03:48.940
to be learn to learn about the world from scratch.

75
00:03:49.280 --> 00:03:53.460
So the terrifying thing is you talked often like with this sort of philosophical

76
00:03:53.530 --> 00:03:57.300
kind of notion that Sam Harris talks about sort of exponential improvement,

77
00:03:57.560 --> 00:04:00.090
be able to become human intelligence,

78
00:04:00.091 --> 00:04:02.210
superhuman level intelligence in a matter of days,

79
00:04:02.230 --> 00:04:06.170
become more intelligent than that. That's all learning process.

80
00:04:06.630 --> 00:04:08.050
That's being able to learn.

81
00:04:08.310 --> 00:04:12.570
That's the key aspect where in the very early days of that, there's um,

82
00:04:13.280 --> 00:04:15.530
there's an idea of, you know,

83
00:04:15.550 --> 00:04:19.770
big bang is a funny word for one of the most fundamental ideas in the,

84
00:04:19.771 --> 00:04:21.720
the R universe. Same way.

85
00:04:22.190 --> 00:04:26.040
Self play is a term for, uh,

86
00:04:26.360 --> 00:04:27.480
I think one of the most important,

87
00:04:27.920 --> 00:04:29.840
powerful ideas and artificial intelligence that,

88
00:04:30.030 --> 00:04:33.760
that people are currently working on. So self play, I,

89
00:04:33.800 --> 00:04:36.600
I don't know if you're familiar with a company called deep mind and open AI

90
00:04:36.601 --> 00:04:39.360
mm-hmm &lt;affirmative&gt; so Google deep mind, uh, and a game.

91
00:04:39.760 --> 00:04:44.750
I know you're first person, some shooter guy, but uh, StarCraft and Dota two.

92
00:04:45.330 --> 00:04:49.390
So last year these are, what do you call them real time strategy,

93
00:04:49.550 --> 00:04:53.110
I guess in people who win millions of dollars in eSport competitions.

94
00:04:53.930 --> 00:04:58.870
And so open AI separately had, uh, open AI five,

95
00:04:58.871 --> 00:05:03.460
which took on Dota two, Dota two is the computer game based on workcraft three,

96
00:05:03.800 --> 00:05:05.540
that's the most popular eesport game.

97
00:05:06.120 --> 00:05:09.540
And then deep mine took on StarCraft with their alpha star system.

98
00:05:10.120 --> 00:05:14.580
And the key amazing thing is there similar to alpha go and alpha zero that

99
00:05:14.740 --> 00:05:17.300
learned to play go is the mechanism of self play.

100
00:05:17.640 --> 00:05:22.530
That's the exciting mechanism that I think if you can fit out how to have

101
00:05:22.531 --> 00:05:27.210
an impact on more serious problems than games would be transformative. Okay,

102
00:05:27.211 --> 00:05:31.050
what is it it's learning from scratch in a competitive environment.

103
00:05:31.430 --> 00:05:36.210
So thinking of you have two white belts, sorry, go going to Jitsu.

104
00:05:36.211 --> 00:05:36.550
You have,

105
00:05:36.550 --> 00:05:40.330
you have two white belts training against each other and trying to figure out

106
00:05:40.331 --> 00:05:44.160
how to beat each other without ever having blackball supervision and structures

107
00:05:44.161 --> 00:05:46.800
and so on and slowly getting better that way coming up,

108
00:05:46.870 --> 00:05:50.120
inventing new moves that way. And eventually they,

109
00:05:50.430 --> 00:05:53.280
they get better and better by that competitive process.

110
00:05:54.220 --> 00:05:57.080
That's the machine playing itself without human supervision.

111
00:05:57.700 --> 00:06:01.840
The interesting thing is there's a lot of cases in which if you set up the

112
00:06:01.841 --> 00:06:04.720
competitive environment well enough for those two white belts,

113
00:06:05.030 --> 00:06:09.200
they'll learn to be black belts. They'll learn to be not only black belts,

114
00:06:09.201 --> 00:06:13.760
they'll learn to be better than like exactly the kind of evolution that's

115
00:06:13.761 --> 00:06:17.750
happening at MMA right now. If you put that in a digital space and speed it up,

116
00:06:18.050 --> 00:06:20.750
you know, a millionfold it'll continue to.

117
00:06:20.750 --> 00:06:21.210
<v 0>Improve.</v>

118
00:06:21.210 --> 00:06:24.910
Let me pause you here because this is one of the things that I think probably

119
00:06:25.910 --> 00:06:30.630
translates to AI as it does to jujitsu, you need more than one opponent.

120
00:06:31.700 --> 00:06:33.110
Like you can't have one input,

121
00:06:33.850 --> 00:06:38.540
one person training with one person specifically and singularly,

122
00:06:38.880 --> 00:06:43.820
you're not going to develop the type of game that you need to become

123
00:06:43.860 --> 00:06:46.100
a real black belt in. Jusu a hundred percent. Exactly.

124
00:06:46.340 --> 00:06:50.420
<v 2>Yeah. So that's part of the brilliance of this mechanism. So, uh,</v>

125
00:06:50.421 --> 00:06:52.260
imagine you didn't just have white belts,

126
00:06:52.261 --> 00:06:56.780
you had a opportunity to generate a new random white belt, like a,

127
00:06:56.781 --> 00:06:59.530
like a fat big one. Mm-hmm &lt;affirmative&gt; a little one, right?

128
00:06:59.710 --> 00:07:03.010
And all kinds of different one that loves aggress. One named daddy, Bravo,

129
00:07:04.370 --> 00:07:07.450
a passive one, a passive one, and then, and let them play.

130
00:07:07.510 --> 00:07:08.930
And then mm-hmm &lt;affirmative&gt; so it, this,

131
00:07:09.000 --> 00:07:13.810
what you find is like digittsu might be simpler than the general problem sort

132
00:07:13.811 --> 00:07:17.250
of, of different kind of, of like, uh stockcrafts and so on.

133
00:07:18.250 --> 00:07:22.200
There is sets of strategies in this giant space there,

134
00:07:22.290 --> 00:07:24.480
these complex hierarchical strategies,

135
00:07:24.750 --> 00:07:28.320
like high level strategies and then specifics of different moves that emerge

136
00:07:28.550 --> 00:07:31.640
some of which you didn't even realize existed.

137
00:07:32.020 --> 00:07:36.960
And that requires that you start with the huge amounts of random initial states,

138
00:07:37.030 --> 00:07:40.470
like the, the fat person and the skinny person, aggressive person, so on.

139
00:07:40.810 --> 00:07:44.590
And then you also keep injecting randomness in the system.

140
00:07:44.591 --> 00:07:48.230
So you discover new ideas. So even when you reach purple belt,

141
00:07:48.490 --> 00:07:51.830
you don't continue with those same people. You start your own school,

142
00:07:51.831 --> 00:07:55.670
you start like you start expanding to totally random new ideas and expanding

143
00:07:55.671 --> 00:07:56.250
this way.

144
00:07:56.250 --> 00:08:00.540
And what you find out is there's totally surprising to beings like in the game

145
00:08:00.541 --> 00:08:04.620
of chess or in the game of go in the game of StarCraft, these,

146
00:08:05.090 --> 00:08:09.700
this self-play mechanism can do what sort of AI people have dreamed of,

147
00:08:09.750 --> 00:08:13.860
which is be creative, create totally new behaviors, totally new strategies.

148
00:08:14.050 --> 00:08:15.860
That're surprising to human experts.

149
00:08:16.000 --> 00:08:19.140
<v 0>That's why go was so astounding to them, right?</v>

150
00:08:19.141 --> 00:08:21.730
Because it's such a complex game.

151
00:08:21.760 --> 00:08:24.770
<v 2>Such a hard game and, and it's able to, well,</v>

152
00:08:25.030 --> 00:08:28.810
the first astounding thing is able to beat the world champion at yeah.

153
00:08:29.070 --> 00:08:32.650
The second astounding thing about both chess and go is it's able to create

154
00:08:33.240 --> 00:08:35.690
totally new ideas, sort of,

155
00:08:35.790 --> 00:08:39.010
I'm not good enough at Chester go to understand the newness of them,

156
00:08:39.011 --> 00:08:43.720
but grand masters talk about the way alpha, alpha zero, uh,

157
00:08:43.721 --> 00:08:47.880
plays chess. And they say there's a lot of brilliant, interesting ideas there.

158
00:08:47.900 --> 00:08:50.680
Mm like very counterintuitive ideas. And that's such a,

159
00:08:51.380 --> 00:08:55.960
and that's all the first breakthroughs didn't have as much self- play.

160
00:08:56.030 --> 00:08:57.920
They were trained on human experts,

161
00:08:58.340 --> 00:09:02.840
but alpha zero and alpha star and open AI five,

162
00:09:03.090 --> 00:09:07.920
these systems are all fundamentally self-play meaning no human supervision

163
00:09:08.200 --> 00:09:12.240
starting from scratch. So no blackball, instructort you just, you general.

164
00:09:12.660 --> 00:09:15.510
And that means, so they learning from scratch.

165
00:09:15.690 --> 00:09:18.030
That's the that's exceptionally powerful you.

166
00:09:18.370 --> 00:09:20.270
So that that's a process from zero.

167
00:09:20.650 --> 00:09:24.470
You can get the superhuman level intelligence in a particular task

168
00:09:25.530 --> 00:09:30.110
in a matter of days. Mm. Right. That's, that's super powerful, super exciting,

169
00:09:30.640 --> 00:09:34.150
super terrifying. If that's kind of what you think about the,

170
00:09:34.490 --> 00:09:37.740
the channel challenges. We don't know how to do that in the physical space,

171
00:09:38.360 --> 00:09:40.060
in the space of robots,

172
00:09:40.330 --> 00:09:45.180
there's something fundamentally different about being able to perceive,

173
00:09:45.181 --> 00:09:48.260
to understand this environment, to do common sense reasoning.

174
00:09:48.680 --> 00:09:52.100
The thing we really take for granted is our ability to reason about the physics

175
00:09:52.160 --> 00:09:52.993
of the world,

176
00:09:53.310 --> 00:09:57.450
about the fact that things weigh things that you can stack things on top of each

177
00:09:57.451 --> 00:10:00.330
other, the fact that some things are hard, some things are soft,

178
00:10:00.331 --> 00:10:03.930
some things are, are, um, painful when you touch 'em all that,

179
00:10:04.240 --> 00:10:09.170
like there seems to be a giant Wikipedia inside our brain of like common sense,

180
00:10:09.240 --> 00:10:14.170
dumb logic. That's very tough to build up that this,

181
00:10:14.440 --> 00:10:18.120
yeah, that's, that's, it seems to be an exceptionally difficult, um,

182
00:10:19.040 --> 00:10:23.520
learning problem that Boston dynamics will have to solve in order to achieve

183
00:10:23.521 --> 00:10:24.920
even the same kind of, um,

184
00:10:26.800 --> 00:10:31.080
physical movement behavior that we saw in those videos. And then on top of that,

185
00:10:31.340 --> 00:10:34.840
to have the ethical behavior, the, the,

186
00:10:34.841 --> 00:10:36.480
not the ethical sort of the object,

187
00:10:37.770 --> 00:10:42.110
the complex strategies involved in first following orders and then getting

188
00:10:42.111 --> 00:10:44.590
frustrated and then shooting everybody. &lt;laugh&gt;,

189
00:10:45.410 --> 00:10:50.390
that's an exceptionally difficult thing to arrive at because ultimately these

190
00:10:50.391 --> 00:10:52.670
systems operate an on set, a set of objectives.

191
00:10:53.370 --> 00:10:56.430
And what a lot of people that think about artificial general,

192
00:10:56.620 --> 00:11:01.380
inte say the objectives we need to inject in these systems

193
00:11:01.450 --> 00:11:04.620
that they're trained on need to have one uncertainty.

194
00:11:05.040 --> 00:11:06.700
So they should always doubt themselves.

195
00:11:07.050 --> 00:11:08.860
Just like if you want to be a good black belt,

196
00:11:08.920 --> 00:11:13.140
you should always be sort of always open minded, sort of, uh, relax,

197
00:11:13.141 --> 00:11:16.940
always need, learn techniques. It's okay to get submitted. So always, um,

198
00:11:17.000 --> 00:11:20.450
always have a degree of uncertainty about your worldview,

199
00:11:20.870 --> 00:11:24.210
the kind of thing we criticized, uh, Twitter outrage,

200
00:11:24.320 --> 00:11:29.210
mobs for not having so having uncertainty. And the other thing is always have,

201
00:11:29.770 --> 00:11:33.770
uh, a place where there should be human supervision. And I think I just,

202
00:11:33.880 --> 00:11:34.713
there's a,

203
00:11:35.130 --> 00:11:39.600
I think we have good mechanisms for that in place that I think, um,

204
00:11:40.960 --> 00:11:44.760
I, I'm very optimistic about where these kinds of learning systems can take us.

205
00:11:45.020 --> 00:11:49.080
The exciting thing is Boston danielette well terrifying depending on

206
00:11:49.750 --> 00:11:52.680
whether you think I'm a trustworthy human being,

207
00:11:53.020 --> 00:11:56.360
but the Boston dynamics is not opening up their platform.

208
00:11:57.740 --> 00:12:00.600
So they're working with a few people I'm trying to make,

209
00:12:01.020 --> 00:12:03.640
I'm quite busy these days. So I'm trying to make time to make it happen,

210
00:12:04.220 --> 00:12:08.640
to work with them, to build stuff on top of the platform. So, sorry,

211
00:12:08.660 --> 00:12:10.920
I'm referring to spot mini as a platform-hmm &lt;affirmative&gt;.

212
00:12:10.921 --> 00:12:13.950
So this robot is this. It's like a Roomba,

213
00:12:13.951 --> 00:12:17.790
it's a dumb mechanistic thing that can move for you, but you can build,

214
00:12:17.850 --> 00:12:22.230
you can add a brain on top of it, so you can make it learn. You can make it,

215
00:12:22.290 --> 00:12:24.030
see the world. And so on. That's all extra.

216
00:12:24.031 --> 00:12:25.870
That's not what Boston dynamics offers.

217
00:12:26.050 --> 00:12:29.550
So they wanna work with people like me to, to add that kind of capability.

218
00:12:29.551 --> 00:12:33.660
And that's exciting cuz now you can have hundreds of people start to add

219
00:12:34.580 --> 00:12:39.180
interesting learning capabilities. And so I may,

220
00:12:39.580 --> 00:12:44.100
I may have to retract my words about how far away we are with the capabilities

221
00:12:44.101 --> 00:12:46.620
of these robots. Once you now open up to the internet.

222
00:12:46.840 --> 00:12:48.620
So I was speaking to Boston dynamics.

223
00:12:49.100 --> 00:12:51.180
I think they're solving the really hard robotics problem,

224
00:12:51.560 --> 00:12:55.410
but once you open it up to the huge world of researchers that are doing machine

225
00:12:55.570 --> 00:12:59.490
learning and doing computer vision and doing AI research,

226
00:13:00.190 --> 00:13:03.170
the kind of capabilities that might add to these robots might surprise us,

227
00:13:03.171 --> 00:13:03.810
especially, especially.

228
00:13:03.810 --> 00:13:06.810
<v 0>That's where people are concerned, right? The big leaps, the big leaps,</v>

229
00:13:06.870 --> 00:13:10.810
and then sort of just not being aware,

230
00:13:10.811 --> 00:13:13.890
the consequences of these big leaps. And once you let the genie outta,

231
00:13:14.220 --> 00:13:15.160
you can never put it back.

232
00:13:15.810 --> 00:13:16.340
<v 2>Right?</v>

233
00:13:16.340 --> 00:13:21.000
The genie and the self play mechanism where you grow from zero to becoming

234
00:13:21.010 --> 00:13:25.120
world class chess player, that's, that's the genie being out of the bottle.

235
00:13:34.550 --> 00:13:34.550
<v 3>I.</v>

