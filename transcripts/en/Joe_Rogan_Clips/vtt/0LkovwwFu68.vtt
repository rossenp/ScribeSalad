WEBVTT

1
00:00:01.020 --> 00:00:03.700
<v 0>The Joe Rogan experience. My,</v>

2
00:00:03.720 --> 00:00:07.590
my real worry is that it doesn't matter. What we think is right.

3
00:00:08.130 --> 00:00:11.790
That technology always goes towards innovation.

4
00:00:11.820 --> 00:00:14.280
It always goes towards improvements.

5
00:00:14.281 --> 00:00:18.630
It always goes towards technology advancing where it's more

6
00:00:18.631 --> 00:00:22.470
effective, more available, easier, better, cheaper, faster.

7
00:00:22.860 --> 00:00:24.180
This is what we always do.

8
00:00:24.270 --> 00:00:27.150
This is what we've done with every single thing we've ever invented.

9
00:00:27.480 --> 00:00:29.940
And it's got to happen with that as well.

10
00:00:30.710 --> 00:00:34.220
<v 1>But I think the difference between our position is that you think the March of</v>

11
00:00:34.221 --> 00:00:38.690
technology is completely inevitable and there's nothing we can do to kind of

12
00:00:38.810 --> 00:00:43.040
shape it will stop it. It's just going to happen. Whereas I think,

13
00:00:43.430 --> 00:00:47.960
I think none of this is inevitable and I think human beings are capable of, uh,

14
00:00:48.080 --> 00:00:50.600
you know, adapting and changing without technology.

15
00:00:50.870 --> 00:00:52.700
And like this year is a really good example of this,

16
00:00:52.701 --> 00:00:57.380
that we're all waiting for a vaccine. The vaccine has not arrived. And so we've,

17
00:00:57.440 --> 00:01:00.710
we've kind of saved ourselves by changing our behavior and changing our behavior

18
00:01:00.740 --> 00:01:03.320
in a kind of altruistic way by staying at home,

19
00:01:03.321 --> 00:01:07.970
even though like we might not get sick with coronavirus or wearing masks for

20
00:01:07.971 --> 00:01:08.960
other people's benefit.

21
00:01:09.410 --> 00:01:12.980
I think human beings are really adaptable and we can adapt by changing our

22
00:01:12.981 --> 00:01:16.460
behavior rather than relying on technology.

23
00:01:16.490 --> 00:01:18.170
And this March of technology only exists.

24
00:01:18.200 --> 00:01:21.770
If we continue to always think that technology is that is the solution.

25
00:01:21.771 --> 00:01:25.370
People have to make this stuff and people have to buy this stuff in order for it

26
00:01:25.371 --> 00:01:28.580
to March on. And we always have the power to say, you know what?

27
00:01:28.581 --> 00:01:29.414
I don't want it.

28
00:01:29.780 --> 00:01:34.220
<v 0>I think reasonable people like yourself, yes, that's going to happen.</v>

29
00:01:34.221 --> 00:01:38.630
But clearly you've seen videos of spring break and Fort Lauderdale where kids

30
00:01:38.631 --> 00:01:42.590
are making out half naked on the beach.

31
00:01:42.620 --> 00:01:44.360
Nobody gives a about Corona virus.

32
00:01:44.480 --> 00:01:48.590
And then there's a maps that show the spread of them leaving

33
00:01:48.830 --> 00:01:52.610
Florida and going all through the rest of the country and then all these

34
00:01:52.611 --> 00:01:53.444
infections.

35
00:01:54.530 --> 00:01:56.120
<v 1>Totally. But there's a critical,</v>

36
00:01:56.570 --> 00:01:59.480
massive there's enough people that are being reasonable,

37
00:01:59.481 --> 00:02:02.420
that when those things happen, it's really and people get ill,

38
00:02:02.421 --> 00:02:06.380
but it's not the end of the world. That's the point. I think most people are,

39
00:02:06.640 --> 00:02:09.080
are reasonable and are able to behave in a kind of way where,

40
00:02:09.140 --> 00:02:11.600
where the good kind of wins out.

41
00:02:11.930 --> 00:02:14.870
<v 0>I think I agree with you on a lot of these things. However,</v>

42
00:02:14.871 --> 00:02:16.100
when I look at human beings,

43
00:02:16.101 --> 00:02:18.770
I try to look at human beings as if I was from another planet.

44
00:02:19.160 --> 00:02:22.730
If I was an alien and I looked at them without any connection to the way they

45
00:02:22.731 --> 00:02:26.270
think or behave or their culture. And I said, well, what do these things do?

46
00:02:26.630 --> 00:02:28.820
Well, this is what they do. They make technology.

47
00:02:28.850 --> 00:02:32.390
All they do is make technology. They're obsessed with materialism,

48
00:02:32.570 --> 00:02:37.310
which plays into technology. It plays into this want and need for the bigger,

49
00:02:37.311 --> 00:02:40.850
better, faster, greater thing that comes around every year.

50
00:02:40.851 --> 00:02:44.460
And that's what fuels them to work. Every day, they go to work and they,

51
00:02:44.461 --> 00:02:46.700
they toil. And one of the things they,

52
00:02:46.790 --> 00:02:49.670
they reward themselves with is the newest, greatest thing.

53
00:02:50.180 --> 00:02:53.930
And this is the fuel for this technological growth.

54
00:02:53.931 --> 00:02:58.760
And this technological growth appears unstoppable because it seems like

55
00:02:58.761 --> 00:03:03.700
that's the human animal does. If you looked at it from afar objectively,

56
00:03:04.000 --> 00:03:07.930
all I'm seeing is a constant wave of technology.

57
00:03:08.670 --> 00:03:11.700
<v 1>But I don't think that's true because we don't just make technology.</v>

58
00:03:11.701 --> 00:03:15.720
We also talk to each other and we communicate like you and I are now.

59
00:03:15.721 --> 00:03:18.360
And we have discussions and we are capable of incredible change.

60
00:03:18.361 --> 00:03:20.460
And that we could live in a world where, uh, you know,

61
00:03:20.461 --> 00:03:25.440
it was okay to keep slaves and impregnate your wife every year and keep her in

62
00:03:25.441 --> 00:03:28.650
the kitchen. But through having these discussions, we can really,

63
00:03:28.651 --> 00:03:32.520
really change the way we live very drastically from one generation to the next.

64
00:03:32.790 --> 00:03:34.230
It's not just technology. You know,

65
00:03:34.231 --> 00:03:38.760
it's also what defines a human being is that we use technology and that we're

66
00:03:38.761 --> 00:03:41.800
social animals. And those are two different things. And, and the idea that the,

67
00:03:41.910 --> 00:03:44.460
the technological advancement is always going to win out.

68
00:03:44.670 --> 00:03:46.230
Isn't necessarily what I buy.

69
00:03:46.590 --> 00:03:49.920
<v 0>I'm not saying that it's going to win out. I don't think it's going to win out.</v>

70
00:03:49.950 --> 00:03:53.370
I think it's just, it's inevitable. And I think we're going to feel it both.

71
00:03:53.370 --> 00:03:55.410
<v 1>Inevitable. And as a society,</v>

72
00:03:55.411 --> 00:03:59.280
we can make change just as much as we can make change by using technology. Yeah.

73
00:03:59.280 --> 00:04:01.470
<v 0>That is the fascinating balance, right? I mean,</v>

74
00:04:01.471 --> 00:04:04.650
most people were today are aware that they're addicted to their cell phones.

75
00:04:04.651 --> 00:04:06.420
Yet. Most people still use their cell phones.

76
00:04:07.240 --> 00:04:09.720
We were aware that it's harming us,

77
00:04:09.900 --> 00:04:14.520
but yet we still use them because we just go, it's just a phone, no big deal.

78
00:04:14.700 --> 00:04:17.010
But you know, it's a big deal. Everybody. I know it's a big deal.

79
00:04:17.190 --> 00:04:18.780
I know I checked my messages too much,

80
00:04:19.140 --> 00:04:22.620
but yet I still check my messages too much. And I, and I'm aware of it.

81
00:04:22.621 --> 00:04:23.880
And I've read a lot of books about it.

82
00:04:24.030 --> 00:04:26.250
<v 1>But I think if you thought it was harming you enough,</v>

83
00:04:26.550 --> 00:04:30.810
if you thought it was destroying your brain cells, you wouldn't, the point is,

84
00:04:30.900 --> 00:04:34.530
it's about, it's about how you weigh up harm and you think, yeah, you know,

85
00:04:34.531 --> 00:04:37.890
I should probably be doing other things or I shouldn't be constantly checking

86
00:04:37.891 --> 00:04:40.680
the Twitter feed of that person. I hate that's bad for my soul,

87
00:04:41.100 --> 00:04:44.280
but you still do it because it's bad for your soul, but only a little bit.

88
00:04:44.281 --> 00:04:48.900
And if it was really, really corrosive and bad, and then you would stop. I mean,

89
00:04:49.500 --> 00:04:50.190
the blog.

90
00:04:50.190 --> 00:04:51.540
<v 0>If you're a healthy person,</v>

91
00:04:51.570 --> 00:04:54.660
or maybe you're one of those people that like to pick scabs and you just,

92
00:04:54.780 --> 00:04:59.270
you can just keep scratching. That's possible too. I'm,

93
00:04:59.271 --> 00:05:02.190
I'm worried for people I really genuinely am.

94
00:05:02.520 --> 00:05:05.640
And this is as a person who enjoys people. I just,

95
00:05:05.670 --> 00:05:08.550
I don't know how much time we have left as in this forum.

96
00:05:08.670 --> 00:05:11.970
Like when I look at the, um, archetypal alien,

97
00:05:12.240 --> 00:05:16.040
when you see those little gray men with the big heads, I'm,

98
00:05:16.041 --> 00:05:18.600
I'm worried that what that is, is like,

99
00:05:18.601 --> 00:05:21.620
we instinctively know that that's our future. That we're,

100
00:05:21.621 --> 00:05:26.400
we're going to be these genderless weird things that reproduce through some

101
00:05:26.401 --> 00:05:28.800
sort of, uh, you know, some sort of,

102
00:05:28.830 --> 00:05:32.610
some sort of technology instead of these bizarre,

103
00:05:32.611 --> 00:05:36.750
imperfect biological creatures with emotions that we,

104
00:05:36.751 --> 00:05:41.010
you and I both enjoy so much because of all those, all the weirdness.

105
00:05:41.430 --> 00:05:45.630
I mean, my whole business, everything I do is about the weirdness of people,

106
00:05:45.900 --> 00:05:49.200
whether it's standup comedy, whether it's podcasts or even fighting.

107
00:05:49.320 --> 00:05:50.430
When I do commentary on fighting,

108
00:05:50.640 --> 00:05:54.240
that's all the weirdness and imperfect nature of the human animal.

109
00:05:54.390 --> 00:05:57.680
And I think it's awesome. I mean, I love people. Don't get me wrong.

110
00:05:57.681 --> 00:05:59.690
I'm not rooting for technology to do this,

111
00:06:00.140 --> 00:06:03.230
but I see the writing on the wall and it's not pretty.

112
00:06:04.240 --> 00:06:06.820
<v 1>Well. The thing is it's all about the richness of the human experience.</v>

113
00:06:06.821 --> 00:06:08.530
What makes it interesting to be human,

114
00:06:08.531 --> 00:06:12.130
which isn't just the basic functions of our life or, or basic logic. You know,

115
00:06:12.131 --> 00:06:15.370
the fact that we have art galleries everywhere and music music,

116
00:06:15.371 --> 00:06:19.630
which is completely completely illogical it's because there's more to being

117
00:06:19.840 --> 00:06:23.110
human than those basic functions. I mean, when you talk about, you know,

118
00:06:24.460 --> 00:06:26.050
sexless, aliens, reproducing without sex,

119
00:06:26.051 --> 00:06:29.370
like that kind of stuff is going to happen quite soon. I, I, you know, I, I,

120
00:06:29.650 --> 00:06:32.740
I looked into quite a lot of this that we can make like gametes.

121
00:06:32.741 --> 00:06:35.020
We can make cells, they can do this in mice.

122
00:06:35.230 --> 00:06:37.330
You can make sperm and eggs out of cheek cells.

123
00:06:37.331 --> 00:06:40.270
So you could make an egg out of your cheek, cell and sperm.

124
00:06:40.780 --> 00:06:44.110
It there'll be a future where people can make sperm and egg,

125
00:06:44.530 --> 00:06:46.660
whichever one they need for whichever relationship they're in,

126
00:06:46.661 --> 00:06:48.910
and that you can grow a baby outside the human body,

127
00:06:49.150 --> 00:06:52.510
and we will become less and less gendered that is going to happen. You know,

128
00:06:52.511 --> 00:06:57.280
the end of sex for reproduction is quite possible that we will just have sex for

129
00:06:57.290 --> 00:07:01.150
fun. And then we'll do babies in this kind of very controlled way. Um,

130
00:07:01.510 --> 00:07:03.370
but we're always going to be weird human beings.

131
00:07:03.371 --> 00:07:06.520
We're always going to like strange things like dancing around to music,

132
00:07:06.550 --> 00:07:09.670
all the stuff that can't be explained and the drive to be weird.

133
00:07:09.671 --> 00:07:14.380
And the drive to, to, to be illogical is very, very powerful.

134
00:07:14.410 --> 00:07:19.160
And I, I just think, I think we, I'm not so deterministic about stuff. And,

135
00:07:19.270 --> 00:07:21.550
and when I was, when I was like doing all the work for my book,

136
00:07:21.551 --> 00:07:24.640
I was quite worried. It was going to be really depressing because, you know, in,

137
00:07:25.180 --> 00:07:27.550
in a book like mine, like you come, you come to a conclusion where it's like,

138
00:07:27.551 --> 00:07:30.670
well, there's a future where women might be obsolete where we can be replaced by

139
00:07:30.671 --> 00:07:33.940
robots and artificial uteruses and, you know,

140
00:07:35.110 --> 00:07:37.480
misogynist men can live without us, or, uh, you know,

141
00:07:38.140 --> 00:07:41.290
all of these things that are really dark and worrying, but that's,

142
00:07:41.330 --> 00:07:44.500
that's to buy a particular view of human nature as, um,

143
00:07:44.590 --> 00:07:46.990
as being a kind of slave to whatever comes next.

144
00:07:47.020 --> 00:07:51.340
And we're to kind of weird and idiosyncratic, I think,

145
00:07:51.820 --> 00:07:53.200
to be done away with that easily.

146
00:07:54.220 --> 00:07:58.870
<v 0>Episodes of the Joe Rogan experience are now free on Spotify. That's right.</v>

147
00:07:59.110 --> 00:08:02.020
They're free from September 1st to December 1st,

148
00:08:02.021 --> 00:08:04.450
they're going to be available everywhere, but after December 1st,

149
00:08:04.451 --> 00:08:08.140
they will only be available on Spotify, but they will be free.

150
00:08:08.350 --> 00:08:12.160
That includes the video. The video will also be there. It'll also be free.

151
00:08:12.850 --> 00:08:16.960
That's all we're asking. Just go download Spotify much. Buh-bye.

