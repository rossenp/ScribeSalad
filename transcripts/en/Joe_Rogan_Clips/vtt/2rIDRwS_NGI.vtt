WEBVTT

1
00:00:00.990 --> 00:00:05.250
<v 0>The general can experience now that it's done. Uh, and you,</v>

2
00:00:05.280 --> 00:00:08.130
you go back and you look at it and you,

3
00:00:08.150 --> 00:00:10.680
you think about the time that's passed since you released it.

4
00:00:10.740 --> 00:00:12.780
Is there anything that you would have revised?

5
00:00:13.050 --> 00:00:16.080
Is there anything that you wish you would, uh, added?

6
00:00:17.720 --> 00:00:20.180
<v 1>Yeah. Um, I, you know, a lot of it,</v>

7
00:00:20.210 --> 00:00:23.750
I think stands a lot of this stuff is still true. It holds,

8
00:00:23.840 --> 00:00:28.550
holds the same, uh, swipe with me. Uh, I still endorse it.

9
00:00:29.420 --> 00:00:30.950
I really,

10
00:00:30.951 --> 00:00:34.700
really struggled to get behind the curtain of the big tech companies.

11
00:00:34.790 --> 00:00:36.760
And I wanted to write about the business side of,

12
00:00:36.761 --> 00:00:41.150
of what these companies were doing and, um, tried really hard,

13
00:00:41.151 --> 00:00:45.800
but didn't get that far in delving with these companies. Um,

14
00:00:45.860 --> 00:00:47.660
I couldn't get past a lot of the, kind of,

15
00:00:47.661 --> 00:00:50.240
there were some barriers and I knew what I was writing about because I wanted to

16
00:00:50.241 --> 00:00:51.080
be honest about it.

17
00:00:51.081 --> 00:00:54.290
And I couldn't get a lot of the information that I wish I had been able to get.

18
00:00:54.650 --> 00:00:57.830
Now, when I speak about it, I have a lot of that information.

19
00:00:57.831 --> 00:01:01.250
I would have folded it into the book. A lot of it's not in there. I mean,

20
00:01:01.251 --> 00:01:03.950
I still talk about what these companies are doing. Um,

21
00:01:03.970 --> 00:01:06.500
but I would like to have known more about the business side and a lot of that

22
00:01:06.501 --> 00:01:10.370
was hidden from me. So that's a big part of it. Um, there's not,

23
00:01:10.400 --> 00:01:14.480
there's not much else really. I I'm, I have a PhD in psychology.

24
00:01:14.481 --> 00:01:17.720
And so I'm interested in what makes people tick and how they think.

25
00:01:18.290 --> 00:01:21.060
And so the middle big chunk of the book is these,

26
00:01:21.061 --> 00:01:24.140
these different hooks that are embedded in these platforms that make it hard for

27
00:01:24.141 --> 00:01:28.400
us to resist them. And that hasn't changed. Um, that's as true as ever.

28
00:01:28.430 --> 00:01:31.220
And so I don't feel that I would change anything about that part of the book.

29
00:01:31.880 --> 00:01:35.270
<v 0>What about the, the business practices of, uh,</v>

30
00:01:35.300 --> 00:01:40.130
these companies was interesting to you that they are aware of

31
00:01:40.131 --> 00:01:41.780
how addictive all these things are?

32
00:01:43.250 --> 00:01:44.210
<v 1>Yeah. I,</v>

33
00:01:44.380 --> 00:01:49.010
one of the practices I found fascinating was the extent to which these companies

34
00:01:49.011 --> 00:01:53.600
use massive datasets to make their decisions and huge amounts of data.

35
00:01:54.110 --> 00:01:55.150
So, you know, there,

36
00:01:55.160 --> 00:01:57.770
there are two ways to make smart decisions when you're designing a product.

37
00:01:57.800 --> 00:01:58.760
The one way is you,

38
00:01:58.790 --> 00:02:02.510
you speak to smart people who know a lot about humans and what makes them tick

39
00:02:02.600 --> 00:02:05.090
their motivations. And then you,

40
00:02:05.091 --> 00:02:07.940
you take that information and you embedded in the platform that you're

41
00:02:07.941 --> 00:02:08.774
designing,

42
00:02:09.020 --> 00:02:12.050
but that's really hit and miss that's how a lot of video game development

43
00:02:12.410 --> 00:02:15.320
worked. And again, speaking to these video game experts,

44
00:02:15.860 --> 00:02:18.440
who've designed games that have made tons of money who have been very

45
00:02:18.441 --> 00:02:22.220
successful. A lot of them will say, look, I created a lot of games,

46
00:02:22.310 --> 00:02:24.800
but you know, a lot of them missed the Mark.

47
00:02:24.890 --> 00:02:26.630
I had a couple that were great successes,

48
00:02:26.631 --> 00:02:29.180
but for every two that were successful, there were 10 that weren't.

49
00:02:29.540 --> 00:02:31.160
So there's a lot of kind of trial and error.

50
00:02:31.700 --> 00:02:35.720
What the big tech companies do in large part is they avoid the trial and error

51
00:02:35.750 --> 00:02:39.290
by being completely agnostic about the theory of what's going to drive us.

52
00:02:39.291 --> 00:02:40.640
They don't need to know about that.

53
00:02:40.970 --> 00:02:44.030
All they need to do is run a series of kind of trials by combat.

54
00:02:44.360 --> 00:02:46.970
So if you're playing again, world of Warcraft fortnight,

55
00:02:47.300 --> 00:02:51.230
what I do is I throw to two different versions of a particular mission up and

56
00:02:51.231 --> 00:02:52.880
half the players will play one version.

57
00:02:52.881 --> 00:02:56.000
The other half will play the other version that say, one of them is by,

58
00:02:56.110 --> 00:02:59.470
is through a forest. The other one's identical. You have to do the thing,

59
00:02:59.471 --> 00:03:02.980
but you're going by the ocean. The question is, what effect does that happen?

60
00:03:02.981 --> 00:03:06.010
You might discover people will play the mission 10 minutes longer if they're by

61
00:03:06.011 --> 00:03:09.370
the ocean. So then you say, okay, we're going to privilege ocean missions.

62
00:03:09.730 --> 00:03:11.800
So now we have two versions of the ocean mission.

63
00:03:12.010 --> 00:03:13.570
This is round two of the trial.

64
00:03:14.200 --> 00:03:18.040
You can either rescue an artifact or you can rescue a person.

65
00:03:18.460 --> 00:03:21.250
And people are turns out, are more interested in rescuing a person.

66
00:03:21.251 --> 00:03:24.040
So they'll play for an extra 10 minutes. If you do this,

67
00:03:24.100 --> 00:03:27.070
this kind of trial by combat round. After round after round,

68
00:03:27.340 --> 00:03:29.860
you're revolving a weaponized version of the platform.

69
00:03:30.580 --> 00:03:33.790
So you keep selecting the version. That's hardest for us to resist.

70
00:03:34.120 --> 00:03:37.930
And if you do that on mass, it ends up shaping the user experience.

71
00:03:37.960 --> 00:03:41.980
You end up having features on the platform that are designed to be hard for us

72
00:03:41.981 --> 00:03:46.210
to escape from. Um, if you're creating a game, you, you released the version.

73
00:03:46.211 --> 00:03:49.240
That's most difficult for us to resist. Now, of course,

74
00:03:49.810 --> 00:03:54.610
forever people who are writing movies or books or any form of entertainment,

75
00:03:54.940 --> 00:03:58.000
we're trying to do this. They just were much less good at it.

76
00:03:58.420 --> 00:04:02.500
What the tech companies do is they make this kind of a sure thing by having

77
00:04:02.530 --> 00:04:05.410
access to billions and billions of data points and getting real time,

78
00:04:05.411 --> 00:04:06.790
very rapid feedback from us.

79
00:04:07.380 --> 00:04:10.890
<v 0>Isn't it also to compare it to books and movies.</v>

80
00:04:11.250 --> 00:04:15.810
It's not a fair comparison because those things end. Yes,

81
00:04:16.190 --> 00:04:18.840
that's really where the problem lies, right?

82
00:04:18.900 --> 00:04:23.640
Is that a book or a movie is not going to make you eat pizza three times a

83
00:04:23.641 --> 00:04:28.620
day and gained 40 pounds over five weeks because you're trapped in your house

84
00:04:28.890 --> 00:04:32.640
doing nothing but enjoying this book or movie constantly,

85
00:04:32.880 --> 00:04:36.780
because there is no end to it. Like there's something

86
00:04:38.730 --> 00:04:43.650
like, I, I completely understand why they would do that. I mean, it makes sense.

87
00:04:43.651 --> 00:04:47.790
You're engineering a game you would want to make this game the most compelling,

88
00:04:47.940 --> 00:04:51.720
the most entertaining the, the, the, the, the most, uh,

89
00:04:51.930 --> 00:04:53.550
engaging possible.

90
00:04:54.660 --> 00:04:58.980
But do you think that these companies have a social responsibility for

91
00:04:58.981 --> 00:05:02.970
recognizing the fact that they are massively addictive?

92
00:05:04.290 --> 00:05:07.770
<v 1>Do I have an ethical and social responsibility? Yeah, absolutely. Absolutely.</v>

93
00:05:07.800 --> 00:05:10.500
I think they do. I think, I think that the biggest problem,

94
00:05:10.501 --> 00:05:13.890
the most broken part of all of this is, is the incentive model.

95
00:05:14.220 --> 00:05:17.610
So all of these platforms pretty much reliant on,

96
00:05:18.870 --> 00:05:23.640
I'm thinking about Google, Facebook, Instagram,

97
00:05:23.641 --> 00:05:28.320
Twitter, these platforms require your eyeballs for as many minutes of the day as

98
00:05:28.321 --> 00:05:32.370
possible. And every minute that you're not spending on that device,

99
00:05:32.371 --> 00:05:35.160
you're spending minutes doing other things that is a loss.

100
00:05:35.240 --> 00:05:37.350
They conceive of that as a loss.

101
00:05:37.351 --> 00:05:41.040
And it is because it means that less capable of attracting advertising dollars.

102
00:05:41.340 --> 00:05:44.250
And that drives the whole model. That is a broken model.

103
00:05:44.460 --> 00:05:48.840
It's a terrible model because it privileges extracting minutes of time over

104
00:05:48.841 --> 00:05:49.950
delivering well-being. Now,

105
00:05:49.951 --> 00:05:54.240
historically products were largely if I made a great product,

106
00:05:54.270 --> 00:05:58.700
like when you played, um, I think you said it was quite right real quick.

107
00:05:59.330 --> 00:06:00.770
What do you play quake? When I play doom,

108
00:06:01.160 --> 00:06:04.970
when I played super Mario as a younger kid than that, when Nintendo came out,

109
00:06:05.660 --> 00:06:09.290
that was just an incredible product. I think that was just, you know,

110
00:06:09.291 --> 00:06:13.940
there was designed to deliver a phenomenal A-plus top class experience.

111
00:06:13.941 --> 00:06:16.250
And when you speak to the video game developers, there's a,

112
00:06:16.251 --> 00:06:19.470
purism a purity to it. Um, you know, the, the,

113
00:06:19.471 --> 00:06:23.810
the creator of Mario and the creator of Tetris submitted all of these games,

114
00:06:23.811 --> 00:06:26.960
they all talk about the kind of love that went into the creating these games

115
00:06:27.680 --> 00:06:30.410
that's gone. This is not about making us happier,

116
00:06:30.411 --> 00:06:33.290
giving us a good experience and experience that we're willing to part with our

117
00:06:33.291 --> 00:06:37.220
money for it's all one big kind of heist there. They're trying to trick us.

118
00:06:37.580 --> 00:06:40.490
They're trying to basically get us to part with our time and therefore without

119
00:06:40.491 --> 00:06:44.390
money. And yes, there's an ethical responsibility. I mean, if you,

120
00:06:44.391 --> 00:06:48.830
if you see this at an industrial company and this company is making billions of

121
00:06:48.831 --> 00:06:52.730
dollars, but there are major externalities. So negatives that come with that,

122
00:06:52.731 --> 00:06:55.970
let's say the spearing crap into the waterways and into the air.

123
00:06:56.900 --> 00:07:00.380
That's something that, you know, for the last 25, 30 years or so,

124
00:07:00.381 --> 00:07:02.180
the government has said, you know, that's not okay.

125
00:07:02.181 --> 00:07:03.500
We're going to penalize you for that.

126
00:07:04.010 --> 00:07:06.650
I'm not suggesting they do exactly the same thing with tech companies,

127
00:07:06.651 --> 00:07:09.770
but there is an externality. These companies are making billions of dollars.

128
00:07:09.771 --> 00:07:12.710
The externality is not that they're poisoning the waterways and the air,

129
00:07:13.190 --> 00:07:16.220
but they're changing how we live our lives. And I'd argue in many ways,

130
00:07:16.221 --> 00:07:17.054
for the worse.

131
00:07:17.680 --> 00:07:18.850
<v 0>Do you think, uh,</v>

132
00:07:19.060 --> 00:07:23.020
a warning label would have the same sort of effect that a warning label has on

133
00:07:23.021 --> 00:07:25.150
cigarettes? Like it doesn't really matter.

134
00:07:25.410 --> 00:07:29.080
Like when they put those cancer labels on cigarettes,

135
00:07:29.530 --> 00:07:32.080
people that smoke cigarettes already know it causes cancer.

136
00:07:32.170 --> 00:07:35.020
I don't think it stops anything or helps them at all.

137
00:07:35.980 --> 00:07:39.200
<v 1>Warning labels are toothless. They only work. If you don't know, you know,</v>

138
00:07:39.340 --> 00:07:43.000
is they're educating you. And everyone knows, everyone knows about cigarettes.

139
00:07:43.030 --> 00:07:45.790
I mean, fighting, fighting tobacco addiction is really difficult with,

140
00:07:45.840 --> 00:07:48.670
with both with smokers and with young people who are thinking about smoking,

141
00:07:49.090 --> 00:07:53.320
it's going to be the same with these devices. I think no one needs what may be.

142
00:07:53.350 --> 00:07:56.530
Maybe there's slightly more room to educate people about these things with

143
00:07:56.531 --> 00:07:59.860
respect to, to screen time and what we're doing on screens.

144
00:07:59.890 --> 00:08:04.750
But most of us know this stuff and warning labels don't do much.

145
00:08:04.840 --> 00:08:05.673
I agree.

146
00:08:05.770 --> 00:08:06.850
<v 0>So what could they do?</v>

147
00:08:09.970 --> 00:08:13.630
You're not gonna have them hamstring themselves and make a game that's less

148
00:08:13.631 --> 00:08:16.600
addictive. Like if you like, let's propose,

149
00:08:16.601 --> 00:08:20.950
they reverse engineer what they've done and do it the opposite way.

150
00:08:21.100 --> 00:08:25.450
Like it's going towards the ocean, makes people play more.

151
00:08:25.451 --> 00:08:29.200
So we're going to go to the woods, rescuing a person makes you play more.

152
00:08:29.201 --> 00:08:31.780
So you're gonna, you a rescue, a gem, you know,

153
00:08:31.781 --> 00:08:36.370
like they're going to choose the least addictive out of all of these paths.

154
00:08:36.700 --> 00:08:40.330
Then you're going to be non-competitive with the people that are engineering

155
00:08:40.331 --> 00:08:42.970
games that are going to choose the most addictive.

156
00:08:42.971 --> 00:08:47.800
So then it's almost like everyone's agreeing to make the game possible because

157
00:08:47.801 --> 00:08:50.080
that's the only way people can not be addicted.

158
00:08:51.460 --> 00:08:53.570
<v 1>It's true. I mean, there's, there's no way in, uh,</v>

159
00:08:53.571 --> 00:08:56.580
in the arms race for our attention and, uh, you know,

160
00:08:56.640 --> 00:09:00.120
our dollars and all that sort of stuff. No, one's going to buy into this idea.

161
00:09:00.121 --> 00:09:03.810
We should make a version of the product. I think,

162
00:09:05.100 --> 00:09:06.630
as I said, the model is broken.

163
00:09:06.660 --> 00:09:11.190
If the model is about attention and about picking the version of the game,

164
00:09:11.191 --> 00:09:15.330
that's going to extract the most time that's, that's problematic to begin.

165
00:09:16.350 --> 00:09:20.520
Um, it would be better if there were a way to, to basically create a model that,

166
00:09:20.550 --> 00:09:25.440
that prizes consumer welfare, which then translates into people,

167
00:09:25.441 --> 00:09:27.320
wanting to part with their dollars. I don't know,

168
00:09:27.360 --> 00:09:30.600
that's obviously difficult to do in practice, but you know,

169
00:09:30.601 --> 00:09:31.800
a lot of industries work that way.

170
00:09:31.801 --> 00:09:35.220
It just so happens that the model we chose for it in particular social media,

171
00:09:35.221 --> 00:09:39.000
this is not as true for games, but for social media, for sure. Um,

172
00:09:39.030 --> 00:09:41.760
we are the product and our eyeballs are the product. Um,

173
00:09:41.940 --> 00:09:46.440
and the consumer is the big industry of companies that are buying ads on those

174
00:09:46.441 --> 00:09:49.290
platforms. So, you know, these,

175
00:09:49.950 --> 00:09:52.530
the reason they're free is because they need our eyeballs,

176
00:09:53.190 --> 00:09:55.530
but you could imagine an alternate universe where,

177
00:09:55.860 --> 00:09:58.860
where you had to pay a small annual fee to use these products,

178
00:09:59.310 --> 00:10:00.480
but there was no advertising.

179
00:10:00.930 --> 00:10:04.350
And so the money came from revenue from the billions of dollars of revenue that

180
00:10:04.351 --> 00:10:07.680
you got from, from individual users who are paying to use the platform.

181
00:10:08.400 --> 00:10:08.940
And that's,

182
00:10:08.940 --> 00:10:12.270
that's a universe that I think leads to better outcomes for everyone and

183
00:10:12.330 --> 00:10:15.810
designing features based on people, enjoying them,

184
00:10:15.811 --> 00:10:19.950
getting value from them rather than features designed to hook us. But I, I mean,

185
00:10:20.010 --> 00:10:23.820
I, I've been thinking about this for it's now six or seven years,

186
00:10:23.821 --> 00:10:27.960
and I am, I I'm just as exasperated.

187
00:10:27.961 --> 00:10:30.660
And that's why I think a lot of the focus now has to be on the individual

188
00:10:30.661 --> 00:10:33.450
consumer. If you're a consumer who needs help with this,

189
00:10:33.451 --> 00:10:34.650
you spending too much time.

190
00:10:34.651 --> 00:10:37.620
You feel bad about it when let's talk about ways to deal with it.

191
00:10:38.370 --> 00:10:41.910
But working at the level of the, of the tech companies is, is really,

192
00:10:41.911 --> 00:10:42.744
really difficult.

193
00:10:43.580 --> 00:10:48.230
<v 2>Episodes of the Joe Rogan experience are now free on Spotify. That's right.</v>

194
00:10:48.470 --> 00:10:51.380
They're free from September 1st to December 1st,

195
00:10:51.381 --> 00:10:53.810
they're going to be available everywhere, but after December 1st,

196
00:10:53.811 --> 00:10:57.530
they will only be available on Spotify, but they will be free.

197
00:10:57.710 --> 00:11:01.520
That includes the video. The video will also be there. It'll also be free.

198
00:11:02.210 --> 00:11:06.350
That's all we're asking. Just go download Spotify much, Bubba.

