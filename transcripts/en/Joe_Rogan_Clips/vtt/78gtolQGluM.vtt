WEBVTT

1
00:00:00.980 --> 00:00:01.720
<v 0>The Joe Rogan.</v>

2
00:00:01.720 --> 00:00:05.400
<v 1>Experience. It's the same thing with Facebook and Zuckerberg and his like,</v>

3
00:00:05.420 --> 00:00:08.520
you know, his continued position of like, well, you've got a balanced thing.

4
00:00:08.521 --> 00:00:09.880
It's like, it all,

5
00:00:10.500 --> 00:00:14.320
it just comes off like the reaction to Kaepernick or Facebook's reluctance to do

6
00:00:14.480 --> 00:00:16.360
anything. Or even like Facebook's reluctance.

7
00:00:16.360 --> 00:00:17.193
<v 0>To do anything about what.</v>

8
00:00:17.550 --> 00:00:21.110
<v 1>Well, Zuckerberg, you know, is basically saying like, we're not,</v>

9
00:00:21.120 --> 00:00:25.150
we're not here to edit anything. And I'm not saying that I'm for editing,

10
00:00:25.810 --> 00:00:28.870
but it's okay. If you have a, a, if you have,

11
00:00:28.970 --> 00:00:32.950
if you're in charge of a company, the you're the face of the company.

12
00:00:33.490 --> 00:00:38.110
So what you do is a reflection of what you believe in, right?

13
00:00:38.111 --> 00:00:41.540
Mm-hmm &lt;affirmative&gt; so in his particular case, he must believe this,

14
00:00:41.541 --> 00:00:45.460
but he just believes that to say nothing, to do nothing about, uh,

15
00:00:45.640 --> 00:00:48.940
the things that are posted, which is which, you know,

16
00:00:48.941 --> 00:00:50.340
you can argue in court all day,

17
00:00:50.370 --> 00:00:53.100
does it incite violence or is it just someone being, um,

18
00:00:53.170 --> 00:00:56.620
free expressing their free speech or, you know, whatever the deal is.

19
00:00:56.621 --> 00:01:01.340
But if someone's consistently hitting a certain angle and

20
00:01:01.930 --> 00:01:06.170
response is pretty palpable, um, and fairly measurable,

21
00:01:06.470 --> 00:01:10.890
and yet you choose to just allow it to be what it is because, you know,

22
00:01:10.891 --> 00:01:13.690
people figure it out, they'll educate themselves, that type of a thing.

23
00:01:13.690 --> 00:01:17.330
Mm-hmm &lt;affirmative&gt; you have to take some kind of a position from a

24
00:01:17.331 --> 00:01:21.050
humanitarian point of view. And I think that I'm very disappointed in,

25
00:01:22.420 --> 00:01:24.120
in social media, in general, because general,

26
00:01:24.121 --> 00:01:27.280
because they're trying to protect their bottom line and that's really what it

27
00:01:27.281 --> 00:01:32.040
comes off as it doesn't come off as like, well, I wanna protect freerech if it,

28
00:01:32.140 --> 00:01:35.760
it, to me comes across more, like we need to protect our, our bottom line.

29
00:01:35.761 --> 00:01:38.040
Because if we, if we start editing something,

30
00:01:38.070 --> 00:01:41.000
then it's gonna be a huge landslide. Everyone's gonna be like, oh,

31
00:01:41.001 --> 00:01:41.834
we'll screw this,

32
00:01:41.930 --> 00:01:45.030
screw these guys for a stifling free speech and all of that stuff.

33
00:01:45.340 --> 00:01:48.590
When in actuality, it's it only,

34
00:01:48.650 --> 00:01:51.950
the only reason why you would make decisions like that are really just to

35
00:01:52.190 --> 00:01:56.710
protect a bottom line. I don't really understand any other because you, I mean,

36
00:01:56.711 --> 00:02:00.110
even apple takes a position, you know, like Tim cook will issue a letter,

37
00:02:00.290 --> 00:02:04.540
that's then able to be circulated and, and you can read the letter and like, oh,

38
00:02:04.541 --> 00:02:07.060
okay. That's interesting. They're they, they don't believe in this.

39
00:02:07.061 --> 00:02:08.620
And they don't believe in this as a company.

40
00:02:08.760 --> 00:02:12.660
Mm-hmm &lt;affirmative&gt; Zuckerberg is more like, well, I believe in,

41
00:02:13.440 --> 00:02:18.180
in whatever the greater bland generalization is for

42
00:02:18.760 --> 00:02:19.780
my operating system.

43
00:02:20.100 --> 00:02:20.940
<v 0>Existing. Well, first of all,</v>

44
00:02:21.160 --> 00:02:23.380
if we want to talk difference between apple and Facebook,

45
00:02:23.570 --> 00:02:28.370
these differences are gigantic. Apple is a technology company. Yeah.

46
00:02:28.520 --> 00:02:30.890
They are not a social media platform.

47
00:02:31.390 --> 00:02:34.250
The difference between the responsibility of a technology company and the

48
00:02:34.251 --> 00:02:38.570
responsibility of a social media platform is enormous. It's enormous.

49
00:02:38.750 --> 00:02:39.930
The consequences are enormous.

50
00:02:40.100 --> 00:02:43.850
Apple makes phones and computers and they have an app store. And, you know,

51
00:02:44.080 --> 00:02:46.520
they, they, they take down bad apps and, you know,

52
00:02:46.521 --> 00:02:48.880
things that they find that are spying on people and the like,

53
00:02:48.940 --> 00:02:53.240
but they don't really have the same dilemmas that someone like Facebook has.

54
00:02:54.230 --> 00:02:57.840
When you talk about the importance of free speech,

55
00:02:58.510 --> 00:03:02.480
when as soon as you decide, okay, this person can't talk,

56
00:03:02.580 --> 00:03:03.960
but this person can,

57
00:03:04.630 --> 00:03:09.360
what you are essentially saying is my viewpoint is better

58
00:03:09.910 --> 00:03:12.800
than the viewpoint of the person that I disagree with. Now,

59
00:03:12.940 --> 00:03:16.840
if you have very specific things like you can't docs people,

60
00:03:17.220 --> 00:03:18.750
you can't threaten people bull,

61
00:03:19.050 --> 00:03:22.230
you can't say anything racist or sexist or homophobic,

62
00:03:22.231 --> 00:03:25.950
or once you establish those parameters, you know,

63
00:03:26.010 --> 00:03:30.070
if you decide that this is how you're gonna operate, if,

64
00:03:30.090 --> 00:03:31.110
if this is your company,

65
00:03:32.300 --> 00:03:37.270
there's a real good argument that you should be allowed to

66
00:03:37.271 --> 00:03:40.620
do that because it's your company &lt;affirmative&gt;. Mm. But then when it gets,

67
00:03:41.050 --> 00:03:45.060
when the company gets big enough where it's like Facebook or Twitter,

68
00:03:45.770 --> 00:03:47.420
then you get a real argument, like, wow,

69
00:03:48.040 --> 00:03:51.060
the best argument for bad speech,

70
00:03:51.600 --> 00:03:54.180
the best antidote is more speech. It's better speech.

71
00:03:54.700 --> 00:03:56.060
So if someone says something that's wrong,

72
00:03:56.250 --> 00:03:58.420
there's a real education value in being,

73
00:03:58.950 --> 00:04:03.010
being able to correct that and having other people correct it,

74
00:04:03.320 --> 00:04:07.930
like just eliminating it. Yeah. In some ways, strengthens the, resolve,

75
00:04:08.070 --> 00:04:11.090
the people that hold that marginalized idea,

76
00:04:11.120 --> 00:04:15.050
whether it's racism or sexism or whatever, when you just eliminate it,

77
00:04:15.280 --> 00:04:19.570
then they go off and it tends to strengthen their, their resolve. It tends.

78
00:04:19.730 --> 00:04:20.680
Sure. Know what I mean? Sure.

79
00:04:20.900 --> 00:04:23.720
And then particularly when it comes to things like right.

80
00:04:23.750 --> 00:04:26.560
Wing issues or left- wing issues, if you're,

81
00:04:26.580 --> 00:04:29.640
if you're running a there's no right- wing social media site that's as popular

82
00:04:29.700 --> 00:04:31.760
as the left- wing ones. But if there was,

83
00:04:32.540 --> 00:04:36.480
and they just decided we're not gonna tolerate any trans stuff, we're not gonna,

84
00:04:36.481 --> 00:04:40.280
if you started talking about how a, a man who has the sex changes, now, woman,

85
00:04:40.281 --> 00:04:43.070
we're gonna tell you, go yourself. That's not real. We we're,

86
00:04:43.071 --> 00:04:45.630
we're not gonna tolerate abortion. You wanna talk about abortion rights,

87
00:04:45.631 --> 00:04:47.630
you're killing babies, get the off our platform.

88
00:04:47.940 --> 00:04:52.630
Like that's the kind of that right wing zealots would do to people that hold

89
00:04:52.700 --> 00:04:55.670
left wing ideology. Mm-hmm &lt;affirmative&gt; but tr the,

90
00:04:56.120 --> 00:05:00.870
conversely you do see that from people who are left- wing zealots,

91
00:05:01.240 --> 00:05:05.740
who are angry about people who have right- wing ideas and maybe even not.

92
00:05:05.740 --> 00:05:09.060
So right- wing like Megan. So I I'm sorry if you've heard this before,

93
00:05:09.061 --> 00:05:11.500
I use thishmm &lt;affirmative&gt; example all the time. If you're listening,

94
00:05:11.750 --> 00:05:15.460
Megan Murphy, who is a, what you would call a trans exclusion,

95
00:05:16.020 --> 00:05:19.140
exclusionary, radical feminist, they call her a turf.

96
00:05:19.440 --> 00:05:21.500
And what that means is she's a,

97
00:05:21.650 --> 00:05:24.690
a person that's a feminist that doesn't believe that you can just change your

98
00:05:24.710 --> 00:05:28.570
sex. And then you can have these arguments and deal with women's issues.

99
00:05:28.880 --> 00:05:30.330
Like a trans person,

100
00:05:30.590 --> 00:05:33.810
she believes is different than a woman mm-hmm &lt;affirmative&gt; and, and a feminist.

101
00:05:34.510 --> 00:05:39.370
And there was some sort of a debate she was having online where sh with

102
00:05:39.371 --> 00:05:41.730
someone on Twitter and she said, but a man is never a woman.

103
00:05:42.500 --> 00:05:47.280
And so they told her she has to take that down. And so she takes it on,

104
00:05:47.281 --> 00:05:48.280
on what? On, on Twitter. Okay.

105
00:05:48.300 --> 00:05:52.680
So she takes it down and then she makes a screenshot of it and posts that Uh-huh

106
00:05:52.720 --> 00:05:54.400
&lt;laugh&gt;. And so they' banner for life,

107
00:05:55.340 --> 00:05:59.760
for life for saying a man is never a woman. Look, it's one thing.

108
00:05:59.860 --> 00:06:02.280
If you're on someone and you're, you're mad at someone,

109
00:06:02.480 --> 00:06:04.960
and you're saying a man is never a woman, but if you wanna just talk biology,

110
00:06:05.600 --> 00:06:10.280
a man is never a woman. So if you're a person who is a,

111
00:06:10.480 --> 00:06:12.720
a left wing, progressive zealot,

112
00:06:12.721 --> 00:06:17.030
and you don't want anybody that's not adhering or complying at all to the,

113
00:06:17.050 --> 00:06:21.830
to the ideology of progressive people, you ban someone like that.

114
00:06:22.730 --> 00:06:24.670
And so I don't that. Yeah. You know what I'm saying? Yeah.

115
00:06:24.671 --> 00:06:28.310
This is the problem with censorship. It's like, where do you draw the line?

116
00:06:28.650 --> 00:06:31.910
My opinion in that case is you let that woman say that and you let people

117
00:06:31.911 --> 00:06:35.630
correct her and you let people correct the people to correct her. And you, you,

118
00:06:35.870 --> 00:06:40.420
uh, you get a lively debate where people get to discuss whether or not

119
00:06:40.810 --> 00:06:43.020
they are different things. And I,

120
00:06:43.220 --> 00:06:46.740
I think there's a real valid intellectual argument in that there's a,

121
00:06:46.860 --> 00:06:49.220
a valid social argument in that. Yeah. See,

122
00:06:49.221 --> 00:06:51.500
but this is the problem with censorship. Well, and.

123
00:06:51.500 --> 00:06:53.780
<v 1>You know, and my thing is like, I'm not exactly, I'm not saying,</v>

124
00:06:53.880 --> 00:06:57.970
I'm not saying to censor. I'm just saying when in,

125
00:06:57.971 --> 00:07:00.370
on the conversation, so how do you do that though? Well,

126
00:07:00.371 --> 00:07:02.010
you take responsibility for it. It's.

127
00:07:02.010 --> 00:07:03.970
<v 0>Like it's, but what, what specifically are we.</v>

128
00:07:03.970 --> 00:07:06.450
<v 1>Talking about? Well, I'm just saying like, uh, for instance,</v>

129
00:07:06.510 --> 00:07:10.810
if I look at my comments, uh, so say I post something on Twitter and, um,

130
00:07:10.811 --> 00:07:12.650
there's all these comments or whatever. Like,

131
00:07:12.651 --> 00:07:16.570
like a lot of my friends who have Twitter accounts, they may, uh,

132
00:07:16.920 --> 00:07:19.880
they may read the, the comment and be like, oh, that guy's an or whatever,

133
00:07:19.881 --> 00:07:22.560
and never say anything. And there's just like all of these, you know,

134
00:07:22.561 --> 00:07:25.480
comments that are some of just troll people just trying to get reactions and

135
00:07:25.481 --> 00:07:29.800
stuff like that, all that, all of that. I like to personally engage all of that.

136
00:07:30.660 --> 00:07:32.600
And I like to come at them with a conversation.

137
00:07:33.300 --> 00:07:37.200
And the thing that ends up happening with something like Facebook is because

138
00:07:37.520 --> 00:07:42.070
it's, I, I, I'm just a, I guess I'm biased because I don't think,

139
00:07:42.230 --> 00:07:46.030
I don't think very much of Zuckerberg at all. And he's, uh,

140
00:07:46.620 --> 00:07:49.830
just kind of a, a little bit of a thief or a lot, a bit of a thief.

141
00:07:49.900 --> 00:07:52.310
He's a thief and he's not, he's not an innovator in any way,

142
00:07:52.340 --> 00:07:53.230
he's running a company.

143
00:07:53.970 --> 00:07:55.950
<v 0>But, uh, well, when, when you say a thief.</v>

144
00:07:56.300 --> 00:07:58.670
<v 1>Well, cuz he stole the ideas. Uh, right. You know,</v>

145
00:07:58.671 --> 00:08:01.020
I have some free people that were, um,

146
00:08:01.630 --> 00:08:03.820
going to school with him around that time period.

147
00:08:03.880 --> 00:08:07.980
And he just basically stole the initial code for, uh, Facebook,

148
00:08:07.990 --> 00:08:10.660
which was generated by a few different people. Um,

149
00:08:10.661 --> 00:08:13.100
and just kind of made off with it. And he just like, you know, it's like,

150
00:08:13.210 --> 00:08:17.300
it's like how all many companies are formed. It's like someone had an idea.

151
00:08:17.330 --> 00:08:19.300
There's no way for them to protect the idea.

152
00:08:19.570 --> 00:08:21.770
Someone capitalized on the idea of first, how.

153
00:08:21.770 --> 00:08:22.850
<v 0>Come those people can't Sue him?</v>

154
00:08:23.650 --> 00:08:26.210
<v 1>I don't know. I don't know. I think it's because it's arbitrary.</v>

155
00:08:26.410 --> 00:08:27.850
I think it's like where that came from,

156
00:08:27.851 --> 00:08:31.930
where the original code came from and so forth is arbitrary. So, uh,

157
00:08:32.200 --> 00:08:35.650
they must be furious. I, I know that they're furious, you know, and I,

158
00:08:35.651 --> 00:08:39.090
I know that they're furious and I know some other people from startups that also

159
00:08:39.250 --> 00:08:42.600
has he addressed it. No, of course he's not gonna address it. I mean, he may,

160
00:08:42.700 --> 00:08:44.920
may maybe he did. I don't know. I'm not an expert on it.

161
00:08:44.921 --> 00:08:48.240
All I know is that in the beginning there was that. And then in parallel,

162
00:08:48.620 --> 00:08:50.760
as it was growing and as they were making decisions,

163
00:08:50.920 --> 00:08:53.520
I would hear from people that are in his orbit,

164
00:08:53.670 --> 00:08:57.240
that would kind of describe his decision making process processes and so forth.

165
00:08:58.140 --> 00:09:02.200
And I don't get a sense, uh, that he, um, he understands,

166
00:09:03.680 --> 00:09:06.000
uh, his, his responsibb,

167
00:09:06.001 --> 00:09:09.680
his social responsibility or his responsibility to the identity of the company

168
00:09:09.770 --> 00:09:11.560
seems very far removed and,

169
00:09:11.620 --> 00:09:16.430
and his actions kind of dictate that it's like a little bit a fair in a sense

170
00:09:16.460 --> 00:09:20.270
that if, if I have like going back to my comments,

171
00:09:20.570 --> 00:09:23.910
I'm commenting on those things because I'm letting, I'm letting people comment.

172
00:09:24.250 --> 00:09:26.870
Mm-hmm &lt;affirmative&gt;, but I'm engaging in a conversation with,

173
00:09:27.090 --> 00:09:28.430
in hopes that we can talk about.

174
00:09:28.430 --> 00:09:28.671
<v 0>Stuff.</v>

175
00:09:28.671 --> 00:09:32.950
Are you open to anybody being able to com comment back to you and say whatever

176
00:09:32.951 --> 00:09:35.300
they want? Yes, of course. Yeah. But do you know the, the,

177
00:09:36.170 --> 00:09:38.340
what is the explanation that YouTube did for this,

178
00:09:38.341 --> 00:09:42.220
but this is the problem with banning con comments or deleting comments.

179
00:09:42.680 --> 00:09:46.380
It gets that stuff can get co-opted. And there was a,

180
00:09:46.820 --> 00:09:51.100
a situation recently where YouTube was caught deleting comments that were

181
00:09:51.380 --> 00:09:53.020
critical of the Chinese communist party.

182
00:09:54.300 --> 00:09:58.130
And what they said was that it was a software glitch. Oh.

183
00:09:58.130 --> 00:10:00.210
<v 1>Yeah, yeah, no, that's them protecting their bottom line.</v>

184
00:10:00.530 --> 00:10:03.250
<v 0>A hundred percent, right? Yeah. Yeah. That's what I would imagine. Totally.</v>

185
00:10:03.470 --> 00:10:06.290
But I saw that and I said, okay, that, but that's what I'm talking about.

186
00:10:06.360 --> 00:10:09.890
Like that kind of. Like once someone comes in and says, Hey,

187
00:10:10.530 --> 00:10:14.610
we would really like it. If you removed those things that talk about, you know,

188
00:10:14.720 --> 00:10:17.920
some of the mean stuff that we'd do yes. Over here. Yeah. And, uh,

189
00:10:17.921 --> 00:10:21.920
we're willing to do business with you, but we want you to put filters up. Yes.

190
00:10:22.100 --> 00:10:23.520
So they said it was a software glitch.

191
00:10:23.560 --> 00:10:27.040
I don't know how that software glitch is naturally works out in target of the

192
00:10:27.041 --> 00:10:29.000
Chinese communist party. Yeah. Yeah.

193
00:10:29.060 --> 00:10:31.480
<v 1>No, I mean, that's, that's my problem. I mean, I don't have,</v>

194
00:10:31.620 --> 00:10:32.920
I'm not saying get rid of stuff.

195
00:10:33.060 --> 00:10:37.470
I'm just saying be more accountable as the face of a, so what.

196
00:10:37.470 --> 00:10:39.990
<v 0>Would you like him to do differently? Well, I know you don't like him,</v>

197
00:10:39.991 --> 00:10:40.824
but &lt;laugh&gt; like,

198
00:10:41.490 --> 00:10:44.670
so is it just Facebook or do you have this problem with YouTube?

199
00:10:44.730 --> 00:10:46.030
Do you have this problem with Twitter?

200
00:10:46.990 --> 00:10:51.630
<v 1>I mean, here's my problem. Whenever you, whenever power is consolidated. Um,</v>

201
00:10:52.050 --> 00:10:55.030
and, uh, there's, there are always going to be problems cuz there's,

202
00:10:55.430 --> 00:10:58.020
cuz there's gonna be all these different ways that people wish that it were,

203
00:10:58.040 --> 00:11:00.340
and it's not working for them in this way and so forth.

204
00:11:01.400 --> 00:11:05.140
My thing is the future is distributed. Mm-hmm &lt;affirmative&gt;,

205
00:11:05.141 --> 00:11:07.820
it's a distributed network, distributed social networks.

206
00:11:07.900 --> 00:11:11.220
I have my own app WhatsApp that I created. Oh, what's that? Um,

207
00:11:11.250 --> 00:11:15.500
it's just an app. Um, it's uh, yeah, WhatsApp. It's only on iOS.

208
00:11:15.520 --> 00:11:19.290
We can look for it. Where do you do it? Um, it has, it has exclusive content.

209
00:11:19.450 --> 00:11:22.090
I created a bunch of like interviews with Jack White and um,

210
00:11:22.390 --> 00:11:26.130
and Leslie Feist and uh, Fred armisison are on there in this stupid series.

211
00:11:26.250 --> 00:11:28.490
I call drone conversations that shot entirely on drones.

212
00:11:28.810 --> 00:11:31.210
&lt;laugh&gt; and you can't really hear the conversation cause the drones are too

213
00:11:31.211 --> 00:11:35.290
loud. Really? Yeah. It's really stupid. But um, yeah. Check it out, WhatsApp.

214
00:11:35.970 --> 00:11:38.600
Um, it's out there, but it's got livester dreaming.

215
00:11:38.800 --> 00:11:43.600
I have a store that I sell all my old electronics on, but um, you know,

216
00:11:43.601 --> 00:11:45.720
I have other artists that are interested in making an app,

217
00:11:45.721 --> 00:11:49.080
but apps are notoriously co the cost prohibitive.

218
00:11:49.160 --> 00:11:52.320
I means so expensive over hundred, a hundred thousand to create an app. Right.

219
00:11:52.740 --> 00:11:55.800
So I managed to get my app made for a really, really cheap price,

220
00:11:56.040 --> 00:11:59.320
a brilliant guy named Oliver, Klein, Oliver, Thomas klinein, uh,

221
00:11:59.760 --> 00:12:02.920
designed a single handedly, the whole app. It was amazing.

222
00:12:03.300 --> 00:12:05.600
And his aesthetic is awesome. But my thing was,

223
00:12:05.660 --> 00:12:09.320
if I can create a template and keep getting the price down to make an app,

224
00:12:09.340 --> 00:12:12.910
and they're just using the template that I created for other artists to other

225
00:12:12.960 --> 00:12:14.030
bands, uh,

226
00:12:14.031 --> 00:12:18.110
then we can have a distributed network of apps that can intercommunicate with

227
00:12:18.111 --> 00:12:22.630
one another, without the need of, uh, Facebook, Instagram, any of these, um,

228
00:12:22.640 --> 00:12:27.150
these social media platforms. And that way, when a fan comes to visit my site,

229
00:12:27.220 --> 00:12:31.230
they know it's my. It's not being tracked. No one's getting tracked.

230
00:12:31.231 --> 00:12:34.420
There's no social for my, for my app. There's no, um,

231
00:12:34.421 --> 00:12:37.580
there's no social component to it. People can't comment on anything.

232
00:12:37.581 --> 00:12:41.780
There's just content to observe events to behold and

233
00:12:42.450 --> 00:12:46.460
electronics and headphones to be bought. And that's it. So when you go there,

234
00:12:46.461 --> 00:12:47.460
it feels like a safe space.

235
00:12:47.560 --> 00:12:51.820
And so if there's an interconnected network of distributed apps,

236
00:12:52.940 --> 00:12:56.090
um, which essentially are just kind of interactive websites,

237
00:12:56.170 --> 00:12:58.370
I guess that's what an app is. Ultimately.

238
00:12:59.350 --> 00:13:00.530
Now you've got something that's distributed.

239
00:13:00.680 --> 00:13:04.570
Fans can kind of trust that it's a safe space. It's not owned by Facebook.

240
00:13:04.760 --> 00:13:08.090
It's not owned by any of these corporations. So for me,

241
00:13:08.091 --> 00:13:11.770
it's about power consolidation. It's never going to be what,

242
00:13:11.800 --> 00:13:12.890
what you want it to be.

243
00:13:13.220 --> 00:13:17.880
It'll be convenient it and it'll be ever present like Google for whatever

244
00:13:17.881 --> 00:13:22.280
reason, Google, I have a better opinion of than Facebook. Um,

245
00:13:22.420 --> 00:13:26.720
and mainly I will say also the other big factor of Facebook to me is the

246
00:13:26.721 --> 00:13:31.680
aesthetics are piece of. It's a, it's a confusing, terribly designed piece of.

247
00:13:41.350 --> 00:13:41.470
<v 2>I.</v>

