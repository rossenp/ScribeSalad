WEBVTT

1
00:00:01.020 --> 00:00:05.320
<v 0>The Joe Rogan experience. Yes. That's a good point. That's a good point. Um,</v>

2
00:00:06.020 --> 00:00:10.520
so, uh, one of the things I want, I don't know how we, it's not a smooth segue,

3
00:00:10.620 --> 00:00:15.160
but we were talking a bit about technology technology, um, is,

4
00:00:15.920 --> 00:00:19.880
uh, particularly with the 20, 20 election coming up, is this idea of deep fakes,

5
00:00:19.881 --> 00:00:22.430
right? Yes. Yeah, yeah. Fantastic stuff. Um,

6
00:00:23.090 --> 00:00:27.750
and the technology to create this nowadays to create

7
00:00:28.030 --> 00:00:31.350
a deep fake of which essentially just means you're doctoring a,

8
00:00:31.470 --> 00:00:35.430
a photo or video mm-hmm &lt;affirmative&gt; and making it do what you want it to do to

9
00:00:35.431 --> 00:00:39.990
try to convince people of whatever it is. Um, technology is is,

10
00:00:40.130 --> 00:00:43.100
is advancing and, and it's stunning. What can be.

11
00:00:43.100 --> 00:00:44.060
<v 1>Done? Do you know Kyle Dunigan.</v>

12
00:00:44.060 --> 00:00:45.940
<v 0>Is Kyle Dunigan. I should know. I should.</v>

13
00:00:45.940 --> 00:00:47.540
<v 1>Know hilarious standup comedian,</v>

14
00:00:47.760 --> 00:00:52.540
but he shines in doing deep fakes and he's working with this other guy.

15
00:00:52.541 --> 00:00:57.220
I think the guy's called Dr. Fakensstein or the fakconing faken separate guys,

16
00:00:57.221 --> 00:01:00.020
but yeah. Yeah. One of those guys, but go to, go to his, uh,

17
00:01:00.021 --> 00:01:02.450
Instagram and see the new one that he, with Elon Musk,

18
00:01:02.990 --> 00:01:06.610
he was doing him really kind of crudely with like face with, you know, um,

19
00:01:06.800 --> 00:01:08.210
face swap or face. Yeah.

20
00:01:08.211 --> 00:01:11.050
It's like a little filter that you get for Snapchat or something like that or

21
00:01:11.051 --> 00:01:15.930
Instagram, but now he's moved from that to doing this really high end stuff.

22
00:01:15.950 --> 00:01:19.730
Go to the Elon Musk one, look at this, play this, Dr. Fakensstein did this.

23
00:01:19.731 --> 00:01:21.490
Yeah. Okay. Uh, just.

24
00:01:21.490 --> 00:01:25.560
<v 2>Yeah. At teal labs, which is pretty cool. It's pretty cool. But, but,</v>

25
00:01:25.580 --> 00:01:29.840
but we had a little snafu and it looks like time is slowing down and will

26
00:01:29.841 --> 00:01:33.400
eventually start going backwards at, at increasing rate.

27
00:01:33.420 --> 00:01:38.000
So pretty soon you will become a baby again and be sucked back into

28
00:01:38.230 --> 00:01:40.600
your mother's vagina. So yeah.

29
00:01:40.710 --> 00:01:41.001
<v 1>Okay.</v>

30
00:01:41.001 --> 00:01:45.830
Now pause now go to another Kyle Dunigan video so he can tell what Kyle really

31
00:01:45.831 --> 00:01:48.550
looks like. That's him to the right of that. This is what he really looks like.

32
00:01:48.551 --> 00:01:51.230
Yeah. Which is madness. Yeah. You were jazz.

33
00:01:51.230 --> 00:01:52.110
<v 3>Says, oh, you guys.</v>

34
00:01:52.310 --> 00:01:55.590
<v 1>Thought you, the guy's hilarious by the way. He's awesome guy too.</v>

35
00:01:55.850 --> 00:01:57.550
And he's got a, a great Instagram page,

36
00:01:57.650 --> 00:02:01.150
but his Instagram page is mostly him like the gold boom.

37
00:02:01.330 --> 00:02:04.340
So the gold one is chick click on, on that. Cause that's a normal one.

38
00:02:04.450 --> 00:02:07.740
This is one he did with the filters without Dr. Fenstein look at the,

39
00:02:07.760 --> 00:02:10.980
see how it's kind of creepy. Fake. Yeah, yeah. Yeah. But it play that. So.

40
00:02:11.550 --> 00:02:16.180
<v 4>Ellen degenorasa seems friendly, but, but, but, uh,</v>

41
00:02:16.480 --> 00:02:21.180
no, don't get too close to her. She, but your head off, uh, just ask the, uh,

42
00:02:22.210 --> 00:02:23.220
poor, her Raptor.

43
00:02:25.930 --> 00:02:30.890
<v 1>&lt;Laugh&gt; and that's rayta iota is always smoking.</v>

44
00:02:31.080 --> 00:02:31.913
Yeah.

45
00:02:32.410 --> 00:02:33.243
<v 0>Although he gave it up.</v>

46
00:02:33.690 --> 00:02:36.770
<v 1>Remember, but in the videos he's always smoking in this, but look,</v>

47
00:02:36.771 --> 00:02:40.450
it's it's bad enough that it's extra hilarious cuz it's bad.

48
00:02:41.030 --> 00:02:45.160
But the new one that he did with Elon Musk is not it's it's too bad.

49
00:02:45.161 --> 00:02:45.601
It's not bad.

50
00:02:45.601 --> 00:02:48.080
Like look Caitlin general one go to that Calin general one on the far, right.

51
00:02:48.081 --> 00:02:49.960
That's genius. Click on this one.

52
00:02:50.790 --> 00:02:54.200
<v 3>Carefully. Kylie. I have something serious to tell you. Yeah.</v>

53
00:02:54.270 --> 00:02:56.120
When you had your surgery years ago,

54
00:02:56.760 --> 00:03:00.160
I buried your old face in a pet cemetery by accident.

55
00:03:00.340 --> 00:03:03.600
And I'm sorry to say it's back. Yum. Yum. Hey,

56
00:03:03.650 --> 00:03:06.160
cardardish get down Kai. &lt;laugh&gt;.

57
00:03:07.840 --> 00:03:11.480
<v 1>OK. See, but those, those are my favorites.</v>

58
00:03:11.900 --> 00:03:15.520
He has the Kardashians. The only that's the only way they talk, they just say,

59
00:03:15.620 --> 00:03:18.000
yum, yum. And then he knows what they're saying.

60
00:03:18.030 --> 00:03:21.670
Sort of I grew in the guardians of the galaxy. Oh God.

61
00:03:22.190 --> 00:03:26.270
<v 0>I, I dunno how I, I missed these things. I clearly watching the wrong on,</v>

62
00:03:26.450 --> 00:03:27.670
on the internet. Well.

63
00:03:27.670 --> 00:03:31.430
<v 1>You're former CIA guy. I should know this. You're doing important thing.</v>

64
00:03:31.500 --> 00:03:33.390
It's enough time for Kyle Don. Yeah. Well.

65
00:03:33.390 --> 00:03:38.150
<v 0>But this, but what you just shown. I mean, people look at that and I go, okay.</v>

66
00:03:38.310 --> 00:03:41.220
And then, but you're right. The lot Mustang is getting closer too. One's.

67
00:03:41.220 --> 00:03:42.460
<v 1>Creepy. That could be a real guy,</v>

68
00:03:42.640 --> 00:03:46.700
but you could have someone like that say give me a million dollars or I'll bull

69
00:03:46.701 --> 00:03:46.900
your.

70
00:03:46.900 --> 00:03:51.060
<v 0>House up or just come on. Yeah. And imagine if he gave, uh, you know,</v>

71
00:03:51.061 --> 00:03:55.540
some off the cuff, um, financial data on, on tesla-hmm &lt;affirmative&gt;, you know,

72
00:03:55.541 --> 00:03:58.780
talked about it as if he'd just come out of a shareholder call and now he was

73
00:03:58.781 --> 00:04:01.010
releasing some inform. I mean, think about what that means to the,

74
00:04:01.030 --> 00:04:04.010
all of a sudden, the stock price of, of a company. Yes. If, if that happens.

75
00:04:04.070 --> 00:04:08.290
But, um, the quality is, is so far beyond,

76
00:04:08.291 --> 00:04:12.690
even that now that can be done by, and we're talking mostly state actors like,

77
00:04:12.691 --> 00:04:16.570
like Russia. And so the, the, the problem we're facing now is it's not just,

78
00:04:16.720 --> 00:04:19.610
everybody's kind of, kind of aware of, you know, the,

79
00:04:19.630 --> 00:04:23.440
the is sort of the tweetverse or whatever, the Twitter and, um,

80
00:04:23.500 --> 00:04:27.080
the trolls that exist on there and the bots and all of that. But it's the video,

81
00:04:27.180 --> 00:04:29.840
the ability to do the video mm-hmm they, they released one, uh,

82
00:04:29.841 --> 00:04:33.680
one was done not too long ago with Nancy Pelosi. And it,

83
00:04:33.740 --> 00:04:37.120
all it did was slow down her speech just slightly,

84
00:04:37.220 --> 00:04:40.480
but just enough to make it sound as if she was slurring her war.

85
00:04:40.800 --> 00:04:44.550
Maybe she'd had a couple of drinks and that thing was blasted all over social

86
00:04:44.551 --> 00:04:47.470
media and people to this day still think, and they still talk about it. Like,

87
00:04:47.471 --> 00:04:51.070
you know, she's kind of losing it a little bit and right. And that like.

88
00:04:51.070 --> 00:04:52.990
<v 1>Her more, by the way, if she did that. Yeah. I.</v>

89
00:04:52.990 --> 00:04:54.870
<v 0>Think she might, might make a little more sense. Yeah. Um,</v>

90
00:04:55.290 --> 00:04:56.030
get a little lightened.

91
00:04:56.030 --> 00:04:56.790
<v 1>Up lady. Yeah.</v>

92
00:04:56.790 --> 00:05:00.030
You worth the a hundred million dollars and no one knows why you should have be

93
00:05:00.190 --> 00:05:01.700
half their partying. I'm sure it was.

94
00:05:01.700 --> 00:05:02.620
<v 0>All. Oh.</v>

95
00:05:02.680 --> 00:05:07.180
<v 1>So legit. Yeah. Yeah. She earned that a hundred million dollars. Mm, for sure.</v>

96
00:05:07.330 --> 00:05:09.860
There's definitely no shenanigans, no legal.

97
00:05:10.290 --> 00:05:13.780
<v 0>Shenanigans. No, there's nothing like that happening up on Capitol hill. Um,</v>

98
00:05:14.680 --> 00:05:18.020
but it, so this, this is a, it's something that people should watch.

99
00:05:18.090 --> 00:05:20.460
It's something that people should, you know, read up on a little bit,

100
00:05:20.461 --> 00:05:24.410
look at it because cuz the technology is advancing so quickly that the effort to

101
00:05:24.411 --> 00:05:27.250
combat it, the effort to detect it. And there's some companies out there and,

102
00:05:27.450 --> 00:05:29.410
and, and certainly the, the, the government is,

103
00:05:29.470 --> 00:05:32.050
is working to do that DARPA and some others are working,

104
00:05:32.190 --> 00:05:36.810
but the effort to try to identify doctored videos,

105
00:05:36.860 --> 00:05:40.690
right. Particularly when you're talking about elections campaigns mm. Um,

106
00:05:41.670 --> 00:05:43.760
is a, is it it's going to be, uh,

107
00:05:43.780 --> 00:05:47.200
an increasing problem that we're not really discussing that much. Right.

108
00:05:47.600 --> 00:05:52.160
Congress is paying a little bit of attention to it right now. Um, but it's, uh,

109
00:05:52.430 --> 00:05:54.960
it's really problematic. And there's, there's things that,

110
00:05:55.510 --> 00:06:00.160
that you used to be able to look for, right. Lighting and, and, and noise,

111
00:06:00.580 --> 00:06:03.080
and just sort of the movements of the face, uh,

112
00:06:03.310 --> 00:06:07.080
what they call micro heartbeats and, and, and all the little things is the,

113
00:06:07.081 --> 00:06:10.320
is the subject in the video blinking, for instance, when your doctor, it,

114
00:06:10.321 --> 00:06:14.560
sometimes the, the blinking wouldn't be there. And that was a tell, but the,

115
00:06:14.561 --> 00:06:18.710
the people involved in all of this and these deep fakes are working, um,

116
00:06:19.570 --> 00:06:23.870
you know, at such a pace that they're getting ahead of that. So, uh, it's,

117
00:06:23.950 --> 00:06:24.990
I mean, it's fascinating. So anyway,

118
00:06:24.991 --> 00:06:27.190
they're coming up with ways to try to counter it. But I guess the,

119
00:06:27.191 --> 00:06:28.230
the biggest point is it,

120
00:06:28.231 --> 00:06:31.870
it sounds like a public service announcement is people need to be aware of it

121
00:06:32.410 --> 00:06:35.750
and they need to be smart about, of course they won't be,

122
00:06:35.751 --> 00:06:38.500
everybody goes to the internet and they lose their minds and they believe

123
00:06:38.740 --> 00:06:41.180
whatever it is that they read that agrees with their opinion. Sure.

124
00:06:41.280 --> 00:06:44.300
And there's no bothering of, uh, checking, you know, uh,

125
00:06:44.301 --> 00:06:48.740
whether anything is actually legit anymore or not. But if you know,

126
00:06:48.741 --> 00:06:51.980
that would be my one piece of advice going into 2020,

127
00:06:51.981 --> 00:06:56.140
starting now pay attention. Don't believe anything you see until you prove it.

128
00:06:56.141 --> 00:06:58.090
And that's part of the problem too. Right. You know, if I,

129
00:06:58.110 --> 00:07:00.170
we stop believing anything we see, right. But if.

130
00:07:00.170 --> 00:07:04.690
<v 1>I was a skeptical person, right. If I was a, uh, conspiracy minded individual,</v>

131
00:07:04.790 --> 00:07:05.110
I'd say,

132
00:07:05.110 --> 00:07:09.010
but you're not this guy who used to work for the CIA is telling us not to

133
00:07:09.011 --> 00:07:11.290
believe the news. Wait, I see what you're saying.

134
00:07:11.320 --> 00:07:13.730
What I'm saying is you are setting us up.

135
00:07:14.680 --> 00:07:17.730
<v 0>Okay. Well, it's time for me to go. &lt;laugh&gt; uh, look at that.</v>

136
00:07:18.400 --> 00:07:21.280
<v 1>Wouldn't, wouldn't a normal skeptical person want to think, like,</v>

137
00:07:21.281 --> 00:07:22.120
why is he telling us that.

138
00:07:22.440 --> 00:07:24.840
<v 0>I guess, I guess I'm saying, I'm saying it wrong, cuz you're right.</v>

139
00:07:24.880 --> 00:07:29.080
I don't mean to say, I don't mean to imply, I guess what I'm saying is trust.

140
00:07:29.760 --> 00:07:32.320
Uh, but verify right. When, when, when you're looking at,

141
00:07:32.340 --> 00:07:35.360
at video of a candidate or you're looking at anything really on the internet now

142
00:07:35.630 --> 00:07:38.480
just be aware of the capability.

143
00:07:38.640 --> 00:07:41.710
Maybe that's a better way of putting all of this because, uh you're right.

144
00:07:41.711 --> 00:07:42.950
You don't want the part of the problem.

145
00:07:42.970 --> 00:07:44.830
And one of the things that Russia does and,

146
00:07:44.831 --> 00:07:48.270
and others who are involved in this whole propaganda effort, um,

147
00:07:48.570 --> 00:07:51.430
one of the things they do wanna do is undermine our confidence obviously in

148
00:07:51.431 --> 00:07:54.430
media. Right? So, you know, by me saying, don't believe what you see,

149
00:07:54.530 --> 00:07:56.350
I'm kind of feeding into that. So you're right. I shouldn't,

150
00:07:56.390 --> 00:08:01.300
I shouldn't go that route, be aware of what the capabilities are, pay attention.

151
00:08:01.301 --> 00:08:04.140
Everybody should just be a little bit smarter about what they're doing.

152
00:08:04.160 --> 00:08:05.300
That's all I'm saying. So.

153
00:08:05.640 --> 00:08:10.460
<v 1>And also what we're looking at now is so much more powerful</v>

154
00:08:10.610 --> 00:08:13.060
than what we had three or four years ago. Mm-hmm &lt;affirmative&gt;, I mean,

155
00:08:13.061 --> 00:08:15.780
three or four years ago, this technology was not available for the consumer,

156
00:08:16.200 --> 00:08:17.033
but now it is.

157
00:08:17.130 --> 00:08:19.100
<v 0>Well, there, there was, I mean to think about it,</v>

158
00:08:19.340 --> 00:08:23.010
if you &lt;affirmative&gt; not to get too deep. Uh, but if you think about the,

159
00:08:23.030 --> 00:08:24.730
the photography,

160
00:08:24.731 --> 00:08:27.730
how long has photography been around there have been efforts to manipulate

161
00:08:27.731 --> 00:08:28.690
photography. Right. So,

162
00:08:29.110 --> 00:08:31.850
so altering photographs has been around almost as long as the, the,

163
00:08:31.851 --> 00:08:36.730
the medium itself. Um, you go to, uh, Photoshop,

164
00:08:37.370 --> 00:08:41.760
um, that kind of put it all in the hands of, of the consumer, you know, mm-hmm,

165
00:08:41.800 --> 00:08:45.640
&lt;affirmative&gt; um, what you were talking about face, uh, swap, uh,

166
00:08:45.700 --> 00:08:49.880
the new face app to age people. Yeah. Um, all these things make it easier for,

167
00:08:49.881 --> 00:08:52.760
whoever's got a smartphone to try to do this, but what you really, and,

168
00:08:52.761 --> 00:08:53.800
and that's a problem as well.

169
00:08:54.140 --> 00:08:56.360
But one of the things that you really have to worry about is, again,

170
00:08:56.361 --> 00:08:59.680
sort of the state actors, like a Russia. I mean, well, Russia.

171
00:08:59.740 --> 00:09:02.560
<v 1>Was behind the face at swap thing. Well, yeah.</v>

172
00:09:02.560 --> 00:09:03.920
<v 0>And that's a good point faceap thing, right?</v>

173
00:09:03.921 --> 00:09:06.760
There are Russian companies that are, uh,

174
00:09:06.761 --> 00:09:10.040
pushing this technology out there and what are they doing? You know,

175
00:09:10.050 --> 00:09:13.120
every time you do that, it's recording data about you. Well.

176
00:09:13.120 --> 00:09:16.910
<v 1>Not only that you have to give your name and your email, right.</v>

177
00:09:17.050 --> 00:09:19.030
To get that application. Right.

178
00:09:19.050 --> 00:09:22.190
And then they have a photo of your face that correlates with your name and your

179
00:09:22.191 --> 00:09:22.890
email. Yeah.

180
00:09:22.890 --> 00:09:27.630
So what they've done is they've gathered up more than 150 million emails

181
00:09:28.290 --> 00:09:32.830
and faces. Yeah. And they have data on people. Yeah. That is,

182
00:09:32.970 --> 00:09:36.740
that's pretty powerful stuff. Like if you think about what Facebook has done,

183
00:09:36.741 --> 00:09:36.981
right.

184
00:09:36.981 --> 00:09:40.860
What Facebook has made billions and billions of dollars by essentially mining

185
00:09:41.010 --> 00:09:43.740
data. Right. That's what they're about. Right. Google's the same thing.

186
00:09:43.741 --> 00:09:45.620
They're mining data. Well,

187
00:09:45.880 --> 00:09:49.500
Russia managed to do that with 150 million people in a very,

188
00:09:49.501 --> 00:09:52.420
very short amount of time just by making something cute. Oh,

189
00:09:52.421 --> 00:09:54.220
let's see what that look like when I'm a hundred right.

190
00:09:54.320 --> 00:09:55.460
<v 0>Now, what do you think they're doing with that down?</v>

191
00:09:55.720 --> 00:09:57.370
They're they're slicing and dicing this,

192
00:09:57.371 --> 00:09:59.890
trying to understand the American electorate, right? Yeah. They're gonna,

193
00:09:59.891 --> 00:10:03.010
they're not gonna stop doing what they did. And they've been doing this forever.

194
00:10:03.030 --> 00:10:06.010
We talked about this before. They've been doing this since 1940s. Right.

195
00:10:06.011 --> 00:10:09.730
Mm-hmm &lt;affirmative&gt; busy trying to keep the us out of world war II before they

196
00:10:09.731 --> 00:10:13.650
broke up with the Nazis. It was, it was a, it was a serious breakup. Uh,

197
00:10:13.670 --> 00:10:14.970
but when they were still aligned,

198
00:10:14.971 --> 00:10:18.440
they were busy paying off journalists and buying trade unions and all the rest

199
00:10:18.441 --> 00:10:19.920
of it. So they're not,

200
00:10:19.921 --> 00:10:22.840
they're never gonna stop what they do because it's worked for them and it's just

201
00:10:22.841 --> 00:10:23.674
kind of in their DNA.

202
00:10:24.100 --> 00:10:26.760
<v 1>Why? But isn't that also what the United States does as well. I mean,</v>

203
00:10:26.761 --> 00:10:31.000
there's gotta be some sort of counterintelligentlligence stuff that we do that

204
00:10:31.180 --> 00:10:33.640
is sort of shadyding well, I don't.

205
00:10:33.640 --> 00:10:35.480
<v 0>Know about shady, but yeah.</v>

206
00:10:35.750 --> 00:10:37.550
<v 1>Justifiably shady. How about that?</v>

207
00:10:38.030 --> 00:10:40.350
<v 0>I like that. Okay. That's a good term. Yeah, of course there is.</v>

208
00:10:40.370 --> 00:10:42.190
And people always do that. People every, every, you know, when I,

209
00:10:42.191 --> 00:10:44.670
when I'm talking about, if I, if I'm given a talk about, uh,

210
00:10:45.260 --> 00:10:48.310
Chinese government's, uh, constant theft of intellectual property,

211
00:10:48.311 --> 00:10:49.144
mm-hmm &lt;affirmative&gt;, um,

212
00:10:49.510 --> 00:10:52.270
somebody inevitably will come up afterwards and they will kind of roll their

213
00:10:52.271 --> 00:10:55.430
eyes and go, well, we do it. It's not like it's just them.

214
00:10:55.490 --> 00:10:58.980
The us is guilty of it too. What you well, better hope we are. Right.

215
00:10:59.130 --> 00:11:02.460
Because if we backed off and said, you know what, uh, just, you know,

216
00:11:02.461 --> 00:11:05.340
for the sake of being a righteous individual, we're not gonna do any of this.

217
00:11:07.000 --> 00:11:09.460
You, you would have to be either willfully ignorant, naive,

218
00:11:09.461 --> 00:11:11.940
or just stupid to think that Russia, China,

219
00:11:11.941 --> 00:11:14.660
these other actors out there are gonna stop also. Right.

220
00:11:14.680 --> 00:11:17.260
And we're all gonna hold hands and unicorns gonna fly out of our,

221
00:11:17.670 --> 00:11:20.050
not gonna happen. So, yeah. I mean,

222
00:11:20.051 --> 00:11:22.490
I guess the answer to that is always the same, which is, yeah,

223
00:11:22.491 --> 00:11:24.530
you better hope we do it and we better hope we do it. Well.

224
00:11:24.800 --> 00:11:26.930
<v 1>Yeah. But people are nervous about that. Right?</v>

225
00:11:26.931 --> 00:11:29.010
Like this is my point about the military budget.

226
00:11:29.120 --> 00:11:31.570
Like if you just cut the military entirely, well,

227
00:11:31.571 --> 00:11:34.810
we're all gonna start speaking Chinese, cuz some gonna go down.

228
00:11:35.160 --> 00:11:39.160
Like you can't just cut the military budget. You, you can't right.

229
00:11:39.680 --> 00:11:42.720
I mean just cut it out one. No, no military at all.

230
00:11:42.930 --> 00:11:46.240
We're gonna focus on ourselves. Yeah. Well, good luck with that.

231
00:11:46.241 --> 00:11:46.841
That doesn't work.

232
00:11:46.841 --> 00:11:49.640
So the question is like how much money should you spend on the military?

233
00:11:49.660 --> 00:11:51.960
How much money should you spend on counterintelligence?

234
00:11:51.961 --> 00:11:55.360
How much money should you spend on propaganda? I mean,

235
00:11:55.370 --> 00:11:58.880
there should be some money spent on propaganda overseas. Right, right.

236
00:11:59.160 --> 00:11:59.441
Because we're,

237
00:11:59.441 --> 00:12:02.040
we're trying to manipulate them the way they're trying to manipulate us.

238
00:12:02.220 --> 00:12:06.600
The idea though, is that we're America. We're nice. We're the good guys.

239
00:12:06.850 --> 00:12:09.160
We're doing it the right way. Supposedly. Yeah.

240
00:12:09.190 --> 00:12:12.400
<v 0>Well there is that right there is that. And there's and you know what, honestly,</v>

241
00:12:12.780 --> 00:12:17.230
I'll be honest with you. I I've always, you know, maybe I'm naive or whatever,

242
00:12:17.231 --> 00:12:19.710
but that was always my thought process. Me too. Send it to, you know,

243
00:12:19.711 --> 00:12:21.790
when we're out there in the operational world and you think, you know what,

244
00:12:21.820 --> 00:12:22.950
okay, we're doing this,

245
00:12:22.951 --> 00:12:26.190
but we're doing it for the right reason and see this people laugh at that or

246
00:12:26.350 --> 00:12:27.183
whatever. But.

247
00:12:27.290 --> 00:12:31.870
<v 1>You know, this is my phone. I look at that. See that flag that long may wave.</v>

248
00:12:32.050 --> 00:12:35.660
That's how I, uh, when I open up my phone, the flag waves at me. Yeah.

249
00:12:35.780 --> 00:12:38.140
I got a flag behind me. I'm a hundred percent. Pro- America.

