WEBVTT

1
00:00:00.990 --> 00:00:02.700
<v 0>The Joe Rogan experience.</v>

2
00:00:02.910 --> 00:00:07.280
<v 2>I think you said it also very, very good point, which is who,</v>

3
00:00:07.281 --> 00:00:09.840
who has the time? That's a big one. I mean,

4
00:00:09.841 --> 00:00:11.910
because it does take me three times longer to read,

5
00:00:11.970 --> 00:00:16.590
to read a news article because I got a vet. I don't have to,

6
00:00:16.591 --> 00:00:19.410
I could be like a lot of other, probably most people,

7
00:00:19.411 --> 00:00:23.640
but they're counting on it. If I, if I read this county, doesn't fly with me,

8
00:00:23.641 --> 00:00:25.920
I sit there and I go look up and I grew research. I mean,

9
00:00:25.921 --> 00:00:28.350
we don't all have a Jamie right next to us as, you know,

10
00:00:29.190 --> 00:00:32.580
checking everything that we say and calling us out if I was wrong,

11
00:00:32.610 --> 00:00:34.830
it's like the idea that forever for this whole time,

12
00:00:34.831 --> 00:00:39.330
I thought that Jay Z said that quote. Right. And then, then I was like, well,

13
00:00:39.720 --> 00:00:43.260
I don't know, maybe I'm wrong, but you know, and so, but it's like,

14
00:00:43.290 --> 00:00:45.450
but we don't have most people don't take that time.

15
00:00:46.350 --> 00:00:50.250
Like if somebody else would have corrected me on the, on the, on the bus,

16
00:00:50.320 --> 00:00:53.400
I don't know if anybody would have taken the time to Google that and make sure.

17
00:00:53.640 --> 00:00:55.440
<v 0>Well, that's not even important. Right?</v>

18
00:00:55.470 --> 00:00:58.230
<v 1>Not even important. Right. [inaudible].</v>

19
00:00:58.320 --> 00:01:00.630
<v 0>Yeah. Have to look up and try to figure out, like,</v>

20
00:01:00.631 --> 00:01:03.210
why are we in Afghanistan or why is this happening?

21
00:01:03.211 --> 00:01:07.440
Or why is that important and why is this lobbying passed? Or what's, you know,

22
00:01:07.441 --> 00:01:11.580
what's the real motivation behind this drug being pushed? Like what,

23
00:01:11.610 --> 00:01:14.130
what the is going on with that guy?

24
00:01:14.160 --> 00:01:18.930
Who's and that there's so much of that in this world that you could

25
00:01:18.931 --> 00:01:19.980
lose yourself.

26
00:01:20.250 --> 00:01:24.660
Like if you didn't have a job and your entire day was

27
00:01:24.661 --> 00:01:28.620
sifting through the news and trying to find truthful narratives versus

28
00:01:28.621 --> 00:01:30.960
propaganda, you would lose your mom.

29
00:01:31.410 --> 00:01:34.590
<v 1>How much did you think is that because how much you think right now, the,</v>

30
00:01:34.690 --> 00:01:36.780
the exaggeration of it is because of that,

31
00:01:36.810 --> 00:01:40.740
because that people have a chance to now consume so much

32
00:01:41.520 --> 00:01:43.560
of this information. I think that, you know,

33
00:01:43.620 --> 00:01:46.230
locking people in their house where they just have access to the internet.

34
00:01:47.270 --> 00:01:51.000
I think I thought about it this way. When I remember we were in, um,

35
00:01:51.940 --> 00:01:55.350
the beginnings of our first quarantine tent, a lockdown thing, and I was like,

36
00:01:55.590 --> 00:02:00.420
I still had Netflix and I still had FaceTime and I still

37
00:02:00.421 --> 00:02:03.510
had, I mean, it didn't, I was like, this is fine. Like, I really,

38
00:02:03.511 --> 00:02:06.900
it wasn't that bad. I wasn't going crazy. But I was like,

39
00:02:06.930 --> 00:02:11.130
imagine if this happened in 1985, right, right. I mean, and you,

40
00:02:11.170 --> 00:02:14.910
and you had to wait until the next morning to get a newspaper. Well,

41
00:02:14.911 --> 00:02:16.860
maybe the newspaper wouldn't even be printed because nobody worked in the

42
00:02:16.950 --> 00:02:17.940
newspaper when you literally.

43
00:02:18.000 --> 00:02:22.360
<v 0>And imagine if the newspaper was as full of as CNN is, and then you got,</v>

44
00:02:22.660 --> 00:02:26.580
you you're lost. You really don't know what's true. Or what's, what's lies.

45
00:02:26.850 --> 00:02:30.750
<v 1>What's propaganda have that one thing. And so I was thinking like, man, how,</v>

46
00:02:31.440 --> 00:02:34.110
how difficult would it have been?

47
00:02:34.111 --> 00:02:38.250
How much more isolated would it have been if we just can only get the

48
00:02:38.251 --> 00:02:41.070
information twice a day, once a day.

49
00:02:41.400 --> 00:02:44.820
And at one channel to two or three channels,

50
00:02:44.821 --> 00:02:48.180
local news or whatever it was, you know, we didn't even have that guy, you know,

51
00:02:48.181 --> 00:02:48.960
whatever.

52
00:02:48.960 --> 00:02:52.440
<v 0>So it was so much propaganda back then. They just slipped through the cracks.</v>

53
00:02:52.470 --> 00:02:57.330
It took forever before something can hit the light of day.

54
00:02:57.510 --> 00:03:02.080
Right, right. Where something was an obvious, like especial at government,

55
00:03:02.500 --> 00:03:05.320
like the alpha Tonkin incident that led us into Vietnam.

56
00:03:05.321 --> 00:03:08.320
And there's a bunch of those yeah. Instances where,

57
00:03:09.460 --> 00:03:13.240
oh my God. And there was agreements with the news,

58
00:03:13.241 --> 00:03:17.770
the news had agreements with politicians and, and government agencies and they,

59
00:03:18.040 --> 00:03:20.080
you know, they followed the narrative.

60
00:03:20.800 --> 00:03:22.240
<v 1>And I just, yeah.</v>

61
00:03:22.270 --> 00:03:26.950
So I think that maybe us now with access to all this information and all this

62
00:03:27.010 --> 00:03:29.740
content and all this data and all these people,

63
00:03:29.770 --> 00:03:32.170
all these voices of somebody that used to two,

64
00:03:32.171 --> 00:03:35.620
10 minutes of Twitter now doing four hours of Twitter and just sit there and

65
00:03:35.621 --> 00:03:38.560
getting in these little rabbit holes. I mean, it's gotta be damaging. I got to,

66
00:03:38.860 --> 00:03:41.650
like we said, a lot of it is junk food. I'd treated a lot of it, like junk food.

67
00:03:41.830 --> 00:03:43.360
Like, you know, I live with potato chips every once in a while,

68
00:03:43.361 --> 00:03:44.710
but if I ate it for eight hours a day,

69
00:03:44.711 --> 00:03:46.060
I think it would probably be pretty unhealthy.

70
00:03:46.510 --> 00:03:48.610
And so it's like consuming this kind of garbage.

71
00:03:48.760 --> 00:03:52.240
<v 0>Yeah. There's a guy named Alan [inaudible] he's, uh, he's,</v>

72
00:03:52.930 --> 00:03:57.550
he's looked at it in the same way. Look at process food.

73
00:03:57.940 --> 00:04:00.630
That's how he described it. He's like, you, you,

74
00:04:00.631 --> 00:04:05.290
you can't eat all processed food and you can't eat all processed information.

75
00:04:05.890 --> 00:04:06.671
And that's what it is.

76
00:04:06.671 --> 00:04:11.530
It's like this social media version of information is just processed

77
00:04:11.531 --> 00:04:15.520
information. Right. And you're getting it and these weird sort of bursts,

78
00:04:15.521 --> 00:04:20.200
and it's all boiled down with preservatives on it and filled with nonsense.

79
00:04:20.470 --> 00:04:22.990
<v 1>And it has an agenda. And it's like, you know,</v>

80
00:04:22.991 --> 00:04:27.910
I think that there's a monetization of, of human suffering,

81
00:04:27.940 --> 00:04:31.300
I think is difficult. You know, anytime you have that opportunity to where,

82
00:04:31.750 --> 00:04:33.820
because it's more interesting and it's more,

83
00:04:33.821 --> 00:04:36.950
you want eyeballs onto your content. So you just, it's,

84
00:04:36.951 --> 00:04:40.060
it's a very simple algorithm. It's just, we just need eyeballs.

85
00:04:40.150 --> 00:04:41.590
So whatever got people to watch it,

86
00:04:41.650 --> 00:04:45.790
and then let's get more of that instead of stuff. That's not interesting,

87
00:04:45.910 --> 00:04:49.030
you know, that's might be just very boring data, you know?

88
00:04:49.031 --> 00:04:51.880
And so I think you just tend to lean towards that kind of stuff a little bit.

89
00:04:51.970 --> 00:04:54.700
And I think it's tough. Yeah. I, I just that's,

90
00:04:54.910 --> 00:04:56.920
that's the stuff that always fascinates me a little bit.

91
00:04:57.040 --> 00:04:58.660
It's just because I think, I think it takes us.

92
00:04:58.930 --> 00:05:01.420
I don't think we have a lot of people have that kind of thing.

93
00:05:01.450 --> 00:05:03.010
I think that a lot of people were just like, oh, I don't,

94
00:05:03.011 --> 00:05:05.350
I don't bother with that. I don't, I don't take the time to.

95
00:05:05.500 --> 00:05:07.540
<v 0>No, they don't have the time. They don't take the time.</v>

96
00:05:07.600 --> 00:05:12.460
And that's oddly enough where podcasts have sort of come in to fill

97
00:05:12.461 --> 00:05:16.540
that void because in podcasts you can have two intelligent people just sitting

98
00:05:16.541 --> 00:05:20.110
down talking about stuff in a way like, well, maybe that's not true.

99
00:05:20.111 --> 00:05:21.040
Maybe this is true.

100
00:05:21.041 --> 00:05:25.300
Let's find out let's discuss this and let's figure out why people are saying

101
00:05:25.301 --> 00:05:30.100
this thing that is clearly untrue and saying it across multiple platforms.

102
00:05:30.101 --> 00:05:32.170
Like what's the motivation behind this? Like, yep.

103
00:05:32.380 --> 00:05:36.760
That's a thing that didn't exist before. Because first of all, in the past,

104
00:05:36.850 --> 00:05:40.120
we didn't think of the news as being this thing that was lying to us.

105
00:05:40.750 --> 00:05:42.550
And that's, that's a real recent thing.

106
00:05:42.551 --> 00:05:46.360
And I think a lot of that was exacerbated during the time that Trump was

107
00:05:46.361 --> 00:05:51.190
president, because the media was so upset that Trump had become the president.

108
00:05:51.190 --> 00:05:52.960
And so upset that this,

109
00:05:53.080 --> 00:05:57.410
what they thought this con man was now running the entire government that is

110
00:05:57.411 --> 00:05:59.000
time to fight fire with fire.

111
00:05:59.360 --> 00:06:03.650
And so they started attacking in the same way that they felt like he was

112
00:06:03.651 --> 00:06:08.300
attacking the way he would, you know, call people by a nickname, you know,

113
00:06:08.810 --> 00:06:13.560
lion Ted, or, you know, lion Hillary or crooked Hillary, or, you know,

114
00:06:13.740 --> 00:06:17.840
you have all these nicknames for people call the news, the fake news. And like,

115
00:06:17.841 --> 00:06:20.330
God, we have to fight fire with fire.

116
00:06:20.331 --> 00:06:22.550
We have to tack the same way he's attacking,

117
00:06:22.880 --> 00:06:26.360
but in doing so they've undermined their credibility to an almost

118
00:06:27.470 --> 00:06:32.000
irreparable way. Right. And that's, what's scary. What's scary.

119
00:06:32.001 --> 00:06:35.120
Is that the amount of people that actually trust the news now is lower. Yeah.

120
00:06:35.660 --> 00:06:38.120
<v 1>Lower than ever. And I think it's because we all believed they'd be,</v>

121
00:06:38.200 --> 00:06:40.400
we'll have an agenda, even, even with science,

122
00:06:40.401 --> 00:06:45.080
people think we're so used to people having an agenda that people think that

123
00:06:45.140 --> 00:06:47.940
there's an agenda with everything. Yeah. And there might be, I mean,

124
00:06:48.080 --> 00:06:49.040
there's not to say that there isn't.

125
00:06:49.041 --> 00:06:52.640
I think that that's the balance of it all to sit there and say, I'm, again,

126
00:06:52.700 --> 00:06:54.920
I'm even victim of what we're talking about right now,

127
00:06:54.921 --> 00:06:58.940
which is to say that while I believe that we probably lean this way.

128
00:06:59.400 --> 00:07:01.600
We're not to say that it's a purified like that.

129
00:07:01.760 --> 00:07:04.760
There's no such thing that it's not possible that there's some puppet master out

130
00:07:04.761 --> 00:07:08.270
there. That's really kind of affecting this this way. What is that the third,

131
00:07:08.570 --> 00:07:12.140
but I'm just saying that at the end of the day, um,

132
00:07:12.290 --> 00:07:17.030
not everything has such a mastermind of full type of

133
00:07:17.031 --> 00:07:21.020
thought process behind it. I think some of it is a lot more, um,

134
00:07:21.530 --> 00:07:23.570
simple. I think there's a lot simpler. Sometimes.

135
00:07:23.571 --> 00:07:25.640
It's about just money sometimes. It's about just.

136
00:07:26.030 --> 00:07:27.170
<v 0>It's about money. Yeah.</v>

137
00:07:27.260 --> 00:07:31.250
That's most of it's about narratives narratives that are set up in order to have

138
00:07:31.251 --> 00:07:34.100
people extract money from a system. And that's,

139
00:07:34.101 --> 00:07:38.240
what's really scary is that you follow the money and it's right there.

140
00:07:38.630 --> 00:07:39.290
And you know,

141
00:07:39.290 --> 00:07:43.850
many people will talk for years about getting money out of politics and getting

142
00:07:43.851 --> 00:07:48.470
money out of [inaudible] to make it so that these people that make these

143
00:07:48.890 --> 00:07:50.060
huge decisions,

144
00:07:50.480 --> 00:07:54.710
that affect policy affect the way we're allowed to live our lives,

145
00:07:55.100 --> 00:07:59.140
that there should be no money being exchanged in these decisions.

146
00:07:59.390 --> 00:08:03.650
There should be no motivation, no one should profit from these things. No one,

147
00:08:04.280 --> 00:08:08.330
no one who wants to be a politician should ever get

148
00:08:08.510 --> 00:08:11.150
exorbitantly wealthy from being a politician.

149
00:08:11.151 --> 00:08:15.830
But yet that's the case over and over and over again. And that's dirty. That's,

150
00:08:15.890 --> 00:08:19.010
that's dirty. And that is what affects these people.

151
00:08:19.220 --> 00:08:22.040
And that's what affects the way they behave and the way they communicate and the

152
00:08:22.041 --> 00:08:24.650
things they talk about and the things they won't talk about.

153
00:08:25.250 --> 00:08:30.020
Maybe sometimes there is as important watch the entire episode for free

154
00:08:30.080 --> 00:08:31.400
only on Spotify.

