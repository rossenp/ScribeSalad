WEBVTT

1
00:00:00.960 --> 00:00:05.340
<v 0>The Joe Rogan experience. I think that's one of the weirdest things about today,</v>

2
00:00:05.400 --> 00:00:10.200
right? Is that we're faced with these unparalleled

3
00:00:10.380 --> 00:00:14.730
crisises where we really, we don't have anything to go off of.

4
00:00:14.731 --> 00:00:18.210
We don't have a similar situation that happened, you know,

5
00:00:18.211 --> 00:00:22.950
in 1985 where we are today with the Corona virus and then

6
00:00:22.980 --> 00:00:27.300
with the subsequent lockdown of the economy where everyone's terrified,

7
00:00:27.301 --> 00:00:29.070
and then you have the George Floyd murder,

8
00:00:29.280 --> 00:00:32.730
and then you have the looting and the riots and the chaos and the protest.

9
00:00:32.731 --> 00:00:35.040
And then you have the coronavirus kicks in again.

10
00:00:35.400 --> 00:00:39.640
And our leaders look impotent and we,

11
00:00:39.641 --> 00:00:43.380
we can't look to what I mean when you have a guy like Donald Trump in office

12
00:00:43.620 --> 00:00:45.210
already, you have a situation like Jesus,

13
00:00:45.211 --> 00:00:47.250
I hope the cabinet can keep this thing together.

14
00:00:47.460 --> 00:00:50.460
I hope the Senate can hold this. And this is madness.

15
00:00:50.461 --> 00:00:53.190
We had a reality show host, who's the president,

16
00:00:53.700 --> 00:00:57.990
but then all the mayors are up all the governor.

17
00:00:57.990 --> 00:01:02.700
No one it's not even that they're up is that no one is equipped to handle this.

18
00:01:03.120 --> 00:01:07.950
So you see unprecedented anger, particularly online where, you know,

19
00:01:07.951 --> 00:01:09.620
you're, you're dealing with people. And this is one,

20
00:01:09.621 --> 00:01:13.830
one of the things that drew me to you is one of the tweets that you made about

21
00:01:14.130 --> 00:01:15.720
processed information,

22
00:01:16.080 --> 00:01:19.410
that online information is essentially processed information.

23
00:01:19.411 --> 00:01:23.880
When you're dealing with like social media versus like actual communication like

24
00:01:23.881 --> 00:01:26.730
you and I are having right now, which is what resonates with people.

25
00:01:26.850 --> 00:01:28.980
I think it's one of the things that resonates with podcasts.

26
00:01:28.981 --> 00:01:31.260
It's one of the reasons why I prefer to do them in person.

27
00:01:31.261 --> 00:01:34.140
It's the closest thing to a real conversation with a real person.

28
00:01:34.590 --> 00:01:39.090
Whereas this viewing of text white on

29
00:01:39.091 --> 00:01:41.220
black, you know, white letters. In my case,

30
00:01:41.221 --> 00:01:46.080
I use the night mode on a black screen. It's so weird.

31
00:01:46.110 --> 00:01:50.070
Like you, you, you have to interpret intent. You have to try to get,

32
00:01:50.071 --> 00:01:53.640
and then you're not getting any social cues from the person you're not,

33
00:01:53.670 --> 00:01:56.400
there's not a back and forth. It's just, you spit something out.

34
00:01:56.401 --> 00:01:59.190
They spit something back. And it's, you're trying to

35
00:02:01.320 --> 00:02:05.940
approximate what it's like to actually talk to a person it's very

36
00:02:05.941 --> 00:02:08.340
processed. I thought, I thought that was the way you described.

37
00:02:08.341 --> 00:02:12.690
It was really the perfect definition of what ails us were.

38
00:02:12.691 --> 00:02:15.240
So many people today are communicating in this way.

39
00:02:15.660 --> 00:02:20.580
And it's very similar to people surviving of a processed food

40
00:02:20.610 --> 00:02:21.780
and becoming sick.

41
00:02:23.300 --> 00:02:28.010
<v 1>So if you think about, if you think about how processed food was was created,</v>

42
00:02:28.640 --> 00:02:31.550
basically, and I mean, modern ultra processed food,

43
00:02:31.551 --> 00:02:34.220
because these terms are all really slippery, right? Just like the term natural.

44
00:02:34.221 --> 00:02:35.510
So this is on a spectrum, right?

45
00:02:35.511 --> 00:02:38.390
The history of cooking is a history of processing food, right? You like to cook.

46
00:02:38.420 --> 00:02:40.670
I like to cook that's processing food.

47
00:02:41.600 --> 00:02:44.450
Dessert is a kind of food that's been made to be highly palatable. You know?

48
00:02:44.451 --> 00:02:47.090
So it's not about processing being intrinsically evil,

49
00:02:47.091 --> 00:02:48.500
but with ultra processed foods,

50
00:02:48.501 --> 00:02:52.100
what you've got is you've got a bunch of companies that are like, all right,

51
00:02:52.400 --> 00:02:56.390
what can we exploit about human appetites to make

52
00:02:56.630 --> 00:03:01.480
foods as compulsively, eatable as possible? Right? It's terrifying. You've got,

53
00:03:01.481 --> 00:03:02.291
I think Coca Cola.

54
00:03:02.291 --> 00:03:05.590
I think it was said something like we have to conquer stomach share.

55
00:03:05.620 --> 00:03:09.710
This is a term they use. Yeah. So like, there's a, if you think about,

56
00:03:09.730 --> 00:03:12.010
you have a hundred things of the stomach, right? Like, okay,

57
00:03:12.011 --> 00:03:13.180
so we got a hundred percent of the stomach,

58
00:03:13.181 --> 00:03:18.010
like how can Coca-Cola fill the maximum amount of

59
00:03:18.011 --> 00:03:20.740
stomach share in, in the humans of the world.

60
00:03:20.770 --> 00:03:23.620
<v 2>Wow. What a bizarre way of looking at people. It's.</v>

61
00:03:23.680 --> 00:03:24.880
<v 1>Terrifying. Right. And so then,</v>

62
00:03:24.881 --> 00:03:27.490
and they did it because they got the smartest people, you know,

63
00:03:27.491 --> 00:03:30.340
they've got great chemists and biologists working, you know,

64
00:03:30.370 --> 00:03:35.200
day and night to figure out how to conquer stomach share. And they did it right.

65
00:03:35.201 --> 00:03:37.720
And one of the ways they did it also was make it cheap and accessible.

66
00:03:37.750 --> 00:03:40.090
There's vending machines in every school. I mean, think for a second,

67
00:03:40.091 --> 00:03:41.320
how crazy that is,

68
00:03:41.530 --> 00:03:46.480
that there are vending machines with just Coca-Cola and candy bars and stuff in

69
00:03:46.481 --> 00:03:50.920
every single school we have, you know, it's that, but, but it happened right.

70
00:03:50.921 --> 00:03:54.670
And so now we live in a world in which extremely cheap,

71
00:03:54.820 --> 00:03:59.530
highly palatable and very accessible food is

72
00:03:59.531 --> 00:04:00.364
everywhere.

73
00:04:00.610 --> 00:04:05.560
No wonder we have a problem with our diets and that's exactly

74
00:04:05.561 --> 00:04:10.240
what's happening with information right now. So I, as, as I understand it,

75
00:04:10.750 --> 00:04:12.670
the way in which Twitter was designed, for example,

76
00:04:12.671 --> 00:04:17.230
they consulted with people who wanted to figure out how to keep you compulsively

77
00:04:17.231 --> 00:04:19.060
coming back. So like slot machines, right.

78
00:04:19.090 --> 00:04:23.500
They consulted with people who build slot machines to figure out, okay,

79
00:04:23.501 --> 00:04:25.510
what P what keeps people pulling the lever, right?

80
00:04:25.511 --> 00:04:28.960
So they could just have it refresh. You just have your tweets at the top,

81
00:04:28.961 --> 00:04:31.630
but instead there's a little alert button, right? You pull down,

82
00:04:31.660 --> 00:04:34.540
there's a little noise, like, or whatever the noise is when you,

83
00:04:34.600 --> 00:04:39.490
when you pull down on it, you know? And so they've made it compulsive.

84
00:04:40.210 --> 00:04:43.390
They've made it highly palatable, right? You want to,

85
00:04:43.391 --> 00:04:44.680
you want to keep coming back.

86
00:04:45.610 --> 00:04:50.320
And the thing is the difference between ultra processed information and ultra

87
00:04:50.321 --> 00:04:53.620
processed food is that I think we're, we're, we're the companies now.

88
00:04:53.920 --> 00:04:56.770
And that really freaks me out the consumers.

89
00:04:57.280 --> 00:05:01.870
We're also the manufacturers. And we're also the distributors.

90
00:05:01.930 --> 00:05:03.190
We make the meme.

91
00:05:03.191 --> 00:05:08.080
Someone is going to take some cut of this show and turn it

92
00:05:08.081 --> 00:05:09.160
into a sound bite.

93
00:05:09.400 --> 00:05:13.840
That's highly palatable in the way that that information becomes highly

94
00:05:13.841 --> 00:05:15.760
palatable. It's going to be oversimplified, right?

95
00:05:16.030 --> 00:05:19.480
It's going to have heroes and villains. It's going to have a,

96
00:05:19.510 --> 00:05:22.960
this is going to demonize someone and it's going to be something that gives you

97
00:05:22.961 --> 00:05:23.800
a sense of belonging.

98
00:05:23.801 --> 00:05:27.850
Those are the three things I think that make information highly processed and

99
00:05:27.851 --> 00:05:30.610
highly palatable. We want a hit of information.

100
00:05:30.611 --> 00:05:33.910
That's easy to understand that demonizes someone.

101
00:05:34.780 --> 00:05:36.460
And that gives us a sense of belonging.

102
00:05:36.461 --> 00:05:39.430
And that's just like exploding what humans want. Right? You're saying, you know,

103
00:05:39.431 --> 00:05:41.500
we're creatures that want to love each other. We want to belong, right.

104
00:05:41.530 --> 00:05:44.320
It's just the same way we want to taste salt, sugar, and fat.

105
00:05:44.830 --> 00:05:49.480
We want to feel these things and the information that we have around us now,

106
00:05:50.320 --> 00:05:53.920
it's the, it's the same thing as a Snickers bar,

107
00:05:53.921 --> 00:05:57.590
except the differences were Snickers. We're making it.

108
00:05:58.400 --> 00:06:03.380
<v 0>And we're behaving like junkies, like rabid junkies. If you look at,</v>

109
00:06:04.070 --> 00:06:08.360
I don't know what percentage of Twitter discourse ends in people being angry

110
00:06:08.361 --> 00:06:12.020
with each other, but it seems like it's half at least. I mean, it's just,

111
00:06:12.050 --> 00:06:16.850
there's so much rabid discourse does just people

112
00:06:17.210 --> 00:06:18.860
at each other and insulting each other.

113
00:06:18.861 --> 00:06:22.190
And it's so unlike anywhere else in the world,

114
00:06:22.340 --> 00:06:25.590
and unless you're in a war zone, like the way people talk to each other,

115
00:06:25.670 --> 00:06:30.380
if people talked to each other in real life, the way they talked in on Twitter,

116
00:06:30.650 --> 00:06:35.450
the emergency ward would be filled with people with broken faces and

117
00:06:35.451 --> 00:06:38.000
shattered eye sockets. It'd be chaos.

118
00:06:38.800 --> 00:06:40.510
<v 1>It's road rage. It's how you treat people.</v>

119
00:06:40.511 --> 00:06:42.130
It's how you treat the person in the other car.

120
00:06:42.131 --> 00:06:44.650
That's cut you off because they're not, they've been dehumanized.

121
00:06:44.680 --> 00:06:45.760
They're isolated, right?

122
00:06:45.761 --> 00:06:50.140
It's like Twitter just allows you to end social media in certain ways,

123
00:06:50.141 --> 00:06:53.290
facilitates being angry in the way that you get angry at other car,

124
00:06:53.291 --> 00:06:57.350
you like honking. You're like, you, man. I hate you. It like, you know.

125
00:06:57.480 --> 00:06:59.920
<v 0>What also causes that, the reason why people do that in road rage,</v>

126
00:07:00.520 --> 00:07:03.040
it's because your sensors are heightened because you're moving so fast. Yeah.

127
00:07:03.610 --> 00:07:03.851
Because you're,

128
00:07:03.851 --> 00:07:08.290
you're aware that split-second decision-making is it's important to

129
00:07:08.291 --> 00:07:11.050
survival. So when you're going 65 miles an hour,

130
00:07:11.051 --> 00:07:12.820
and you're looking around at everybody in this guy gets it frigging,

131
00:07:13.720 --> 00:07:15.670
like you're already at seven or eight.

132
00:07:16.090 --> 00:07:18.550
And I think this is also a part of the problem today,

133
00:07:18.610 --> 00:07:23.500
online because of the coronavirus and because of the lockdown and

134
00:07:23.501 --> 00:07:27.850
economic instability. And when we're at unprecedented joblessness right now,

135
00:07:27.910 --> 00:07:31.270
I mean, people are really hopeless. There's a lot of people that,

136
00:07:31.530 --> 00:07:35.860
that we got one $1,200 check from the government and then that's it.

137
00:07:36.100 --> 00:07:37.030
And then you, you know,

138
00:07:37.031 --> 00:07:41.440
you hear that Kanye west got this giant loan and Judd Apatow got this giant

139
00:07:41.441 --> 00:07:44.140
love. These really wealthy people are getting all this money. But meanwhile,

140
00:07:44.141 --> 00:07:45.850
salon owners, small business owners,

141
00:07:45.851 --> 00:07:50.740
didn't a lot of people are just furious at everything because it's

142
00:07:50.741 --> 00:07:53.950
like driving a car you're, you're already heightened.

143
00:07:54.160 --> 00:07:56.230
So this information that comes at you,

144
00:07:56.890 --> 00:08:00.160
maybe wouldn't have you off under normal circumstances, but now you're.

145
00:08:01.330 --> 00:08:03.490
<v 1>Right. It's like stress eating or something. So we have this,</v>

146
00:08:03.491 --> 00:08:05.320
I hadn't really thought about that with, uh, with road rage,

147
00:08:05.350 --> 00:08:08.530
but it does make sense. Right. So when you're, when you're already at that,

148
00:08:08.680 --> 00:08:09.700
when you're already at that level,

149
00:08:09.701 --> 00:08:13.810
then you're going to be even more likely to need that kind of information,

150
00:08:13.960 --> 00:08:17.380
want to participate in that kind of dialogue. You're a dialogue, but no,

151
00:08:17.381 --> 00:08:21.670
it's not it's. Yeah. Yeah. It's I, and there's ways we can,

152
00:08:21.730 --> 00:08:22.720
we can stop it.

153
00:08:23.050 --> 00:08:27.460
I really think we can stop it by

154
00:08:27.520 --> 00:08:31.900
focusing on problems with the system and problems with ourselves. Right.

155
00:08:31.901 --> 00:08:32.560
It's both of us.

156
00:08:32.560 --> 00:08:36.760
Cause we're the ones manufacturing it and we're the ones consuming it so we can

157
00:08:36.761 --> 00:08:39.220
do things about it. And it ranges from, you know, I mean,

158
00:08:39.221 --> 00:08:41.380
I don't like I don't have, I don't want to still don't have a smart,

159
00:08:42.010 --> 00:08:43.510
you don't know, flip phone.

160
00:08:44.350 --> 00:08:46.930
<v 3>With wow. Purpose. Yeah.</v>

161
00:08:47.500 --> 00:08:49.030
<v 1>Um, I mean, in part, not because you tweet.</v>

162
00:08:49.030 --> 00:08:51.730
<v 0>A lot. I do so well.</v>

163
00:08:52.360 --> 00:08:53.440
<v 1>It is. I know it's compulsive.</v>

164
00:08:53.441 --> 00:08:55.590
I think the reason I don't have it is because if I had a smartphone, man,

165
00:08:55.591 --> 00:08:59.250
it'd be all over. I be on it all the time. Um, I mean, when I'm at home,

166
00:08:59.251 --> 00:09:01.710
cause I, you know, because I work from home, sometimes my wife has,

167
00:09:02.040 --> 00:09:05.430
my wife has a smartphone. Um, and so I'll always be like using her folks.

168
00:09:06.230 --> 00:09:08.280
Like if you don't have a phone, you can't just go use my phone. Right.

169
00:09:08.281 --> 00:09:10.470
And then I'm installing things on my computer, like freedom,

170
00:09:10.471 --> 00:09:14.730
which is this app that blocks you from, I mean, it's literally like, you know,

171
00:09:14.731 --> 00:09:16.890
with food, right. People have those logs that only open.

172
00:09:16.950 --> 00:09:19.800
So I have an app that like locks me out of these sites. I have.

173
00:09:20.190 --> 00:09:24.890
<v 0>A folder on my desktop, um, or on my, uh, I guess yeah,</v>

174
00:09:24.920 --> 00:09:29.600
my desktop of my phone, um, that says junkie and, uh,

175
00:09:29.920 --> 00:09:34.370
that's all of my, uh, Instagram and Twitter and all that stuff.

176
00:09:34.470 --> 00:09:35.303
I'm to show it to you, but.

177
00:09:35.780 --> 00:09:37.520
<v 1>It's important that, that kind of thing. So we need,</v>

178
00:09:37.760 --> 00:09:40.100
I think we all need to collectively take steps in that way,

179
00:09:40.130 --> 00:09:42.770
but also we need to realize, and this is really important, right?

180
00:09:42.771 --> 00:09:45.500
It's not just about natural unnatural. It's not just about technology.

181
00:09:46.040 --> 00:09:50.930
We've had this kind of junk food information around forever.

182
00:09:50.931 --> 00:09:54.440
And this is where I think for me is, uh, as a scholar of religious studies,

183
00:09:54.441 --> 00:09:58.730
right? If you look at myths and folktales and fairytales,

184
00:09:59.180 --> 00:10:02.030
and if you look at the structure of religions,

185
00:10:02.270 --> 00:10:06.800
there are ways to tell stories, to get people heightened.

186
00:10:07.100 --> 00:10:10.010
There are ways to tell stories, to make people feel belonging.

187
00:10:10.130 --> 00:10:12.740
There are ways to tell stories to demonize people, right?

188
00:10:12.741 --> 00:10:16.280
These tropes have been alive. They've been around forever. Right?

189
00:10:16.281 --> 00:10:18.590
What do you do? You create a villain?

190
00:10:19.070 --> 00:10:23.930
You tell a story about redemption. You tell a story about a fall.

191
00:10:24.200 --> 00:10:29.090
You tell a story in which the people who are hearing the story just

192
00:10:29.091 --> 00:10:31.790
by hearing it become heroes, right? These are,

193
00:10:31.791 --> 00:10:35.810
these are things that have been around for a long time in the same way that if

194
00:10:35.811 --> 00:10:36.860
you go back 2000 years,

195
00:10:36.861 --> 00:10:41.480
if you were super rich and had access to lots of delicious salty, sugary,

196
00:10:41.481 --> 00:10:46.160
fatty food, you could get fat. It was just a lot harder back then.

197
00:10:46.190 --> 00:10:47.210
And in the same way,

198
00:10:47.750 --> 00:10:51.950
now we facilitated the manufacturer of this kind of these,

199
00:10:51.980 --> 00:10:55.460
these junk narratives that in small doses, I think are fine.

200
00:10:55.640 --> 00:11:00.170
But if it's all we're consuming, it's a, it's a disaster.

201
00:11:00.171 --> 00:11:02.330
And we're going to end up, I think, with some kind of,

202
00:11:02.630 --> 00:11:06.230
with some problems that are analogous to the health problems that we're seeing

203
00:11:06.231 --> 00:11:09.200
because of what we eat, except they're going to be problems in our soul. Right.

204
00:11:09.201 --> 00:11:13.550
I mean your mental diabetes. Yeah. I mean, it's, I, I feel like it's, uh,

205
00:11:14.210 --> 00:11:14.870
I mean, I'm not,

206
00:11:14.870 --> 00:11:18.320
I'm not like a sort of organized religious religion person myself,

207
00:11:18.350 --> 00:11:20.650
but I would say it's not just mental. It's like our souls,

208
00:11:20.700 --> 00:11:25.700
there's something deeply corrupting of our humanity

209
00:11:25.730 --> 00:11:28.190
and I, and I catch myself doing it. So like,

210
00:11:28.340 --> 00:11:31.100
so that tweet that you were talking about, I had,

211
00:11:31.130 --> 00:11:35.720
I had written a piece a week before that, about Trump visiting, um,

212
00:11:36.200 --> 00:11:38.090
what's that, you know, visiting the church and holding up the Bible,

213
00:11:38.720 --> 00:11:40.700
it was this really angry piece. And I was like, I'm gonna, you know,

214
00:11:40.701 --> 00:11:43.820
I'm going to, I'm going to write about how terrible this is. Um, and,

215
00:11:43.940 --> 00:11:44.930
and put this out there, right?

216
00:11:45.500 --> 00:11:49.120
<v 0>The way he set it up to like tear gas and all the protesters to clear the air.</v>

217
00:11:49.310 --> 00:11:49.710
I was like, what.

218
00:11:49.710 --> 00:11:50.660
<v 1>A, what a horrible thing. Right.</v>

219
00:11:50.661 --> 00:11:52.970
I'm going to tell everybody how horrible this is. I'm going to get my anger out.

220
00:11:52.990 --> 00:11:54.670
And then I, and then when the article came out,

221
00:11:54.671 --> 00:11:58.840
I just realized that I was just sending it into the machine. Right.

222
00:11:58.841 --> 00:12:02.140
And it was going to get ground up. And the people who already agreed with it,

223
00:12:02.170 --> 00:12:04.600
we're going to read it and be like, yeah, it's terrible.

224
00:12:04.601 --> 00:12:08.020
And the people that disagreed with it are either never going to read it or

225
00:12:08.021 --> 00:12:09.310
they're going to see it. And they're going to be like,

226
00:12:09.311 --> 00:12:12.640
see people keep attacking Trump. Like, they're all crazy. And, and it,

227
00:12:13.280 --> 00:12:15.070
it was sort of like a Chrysler. She was like, I don't want, wanna.

228
00:12:15.460 --> 00:12:17.530
<v 3>I don't want to be doing, I don't want to be putting.</v>

229
00:12:17.770 --> 00:12:21.610
<v 1>Anything into this machine if it's just going to get</v>

230
00:12:21.910 --> 00:12:26.780
processed into junk information so that we can feed our

231
00:12:27.240 --> 00:12:27.900
habit.

232
00:12:27.900 --> 00:12:30.750
<v 0>And this is a habit that we really don't know how to navigate.</v>

233
00:12:30.840 --> 00:12:35.430
We've only been dealing with this habit for when to Twitter get invented 2007.

234
00:12:35.730 --> 00:12:36.810
It was very recent. Yeah.

235
00:12:36.840 --> 00:12:39.870
That's not enough time for us to figure out how to do it. Right. I mean,

236
00:12:39.950 --> 00:12:43.410
do you remember, like during the, uh, I'm 52?

237
00:12:43.440 --> 00:12:48.060
So when I was a kid watching television for,

238
00:12:48.061 --> 00:12:51.150
for kids all day was fairly new, right.

239
00:12:51.240 --> 00:12:53.160
It only been like a generation or two that,

240
00:12:53.161 --> 00:12:56.640
that was even possible to just watch TV all the time. Right.

241
00:12:56.910 --> 00:13:00.600
And it was constantly thought of as the corrupting thing, like get out,

242
00:13:00.630 --> 00:13:04.050
get away from the TV. You're all you do is watch TV, get up, get outside.

243
00:13:04.350 --> 00:13:08.000
And that was sort of the first indication that there's,

244
00:13:08.001 --> 00:13:12.120
there's a potential for an unhealthy relationship with technology and with

245
00:13:12.121 --> 00:13:13.890
distributed content. Right.

246
00:13:14.250 --> 00:13:19.200
But I think Twitter is far more toxic than that because you're actually

247
00:13:19.201 --> 00:13:23.070
putting the content out yourself and then you're waiting to see how people

248
00:13:23.071 --> 00:13:27.900
respond and you shift the way you interact with people based on

249
00:13:28.350 --> 00:13:32.730
how they respond to your tweets. Right. It's the belonging. Yes.

250
00:13:32.731 --> 00:13:34.830
Or your Facebook posts or what have you.

251
00:13:35.130 --> 00:13:36.900
<v 1>It, it, it created, I mean, it's interesting, you say that,</v>

252
00:13:36.901 --> 00:13:38.070
like thinking again about food.

253
00:13:38.190 --> 00:13:41.220
Cause I'm obsessed with like the first book I wrote was about food. Um,

254
00:13:41.280 --> 00:13:45.500
and like how we came to fear, certain foods like fat or salt or sugar and,

255
00:13:45.501 --> 00:13:46.890
and thinking about it in this way, right.

256
00:13:46.980 --> 00:13:50.520
You need a technology to be able to process something,

257
00:13:50.730 --> 00:13:54.180
to get it cheap enough so that it can be widely consumed. Right.

258
00:13:54.181 --> 00:13:58.260
So information that allows you to belong right. For a long time,

259
00:13:58.590 --> 00:14:00.420
only certain people. I mean, for, for a while, right.

260
00:14:00.421 --> 00:14:02.250
It's only people who could read and write, right. So that's,

261
00:14:02.280 --> 00:14:04.230
that's all you've got. Those are the only people who could prove set.

262
00:14:04.231 --> 00:14:06.660
And then now every,

263
00:14:06.661 --> 00:14:11.550
every it's so cheap to produce information that makes you a part of a community

264
00:14:11.551 --> 00:14:15.840
it's free. Right. When you do it, we do it all the time. And like you said,

265
00:14:16.680 --> 00:14:19.650
we haven't figured out how to navigate it. And that's another confusion.

266
00:14:19.651 --> 00:14:21.660
I think that people have with natural versus unnatural,

267
00:14:21.661 --> 00:14:25.350
which is that we also just have problems with novelty as human beings, right.

268
00:14:25.560 --> 00:14:26.460
Something new comes up. We don't,

269
00:14:26.550 --> 00:14:28.410
we still don't know how to navigate our food system. Right.

270
00:14:28.440 --> 00:14:32.880
We still don't know how to stop people from eating too much.

271
00:14:33.300 --> 00:14:36.300
We don't, we don't know how to do it collectively as a society,

272
00:14:36.301 --> 00:14:37.980
we clearly have not solved this problem.

273
00:14:37.981 --> 00:14:40.770
And yet it's important to remember that for most of the world,

274
00:14:41.160 --> 00:14:43.050
the problem is still not having enough. Right.

275
00:14:43.051 --> 00:14:46.890
So there was a time when the problem was, people had no information,

276
00:14:47.340 --> 00:14:51.380
you just didn't know anything. You knew nothing. And that sucked. Right.

277
00:14:51.381 --> 00:14:54.230
So it's great that we have the internet that was far worse. Yeah.

278
00:14:54.260 --> 00:14:57.770
That was far worse. Um, or at least not, I'm gonna remember,

279
00:14:57.800 --> 00:14:58.970
like it was Def it was,

280
00:14:59.000 --> 00:15:01.820
it was really bad and it was bad in a profoundly different way. I mean,

281
00:15:01.821 --> 00:15:04.760
this goes back to like the, with the hunter gatherer thing, right?

282
00:15:04.761 --> 00:15:06.980
Whether it was better in a state of nature. I often hear people.

283
00:15:06.981 --> 00:15:09.830
There's a great book called against the grain written by, uh, um,

284
00:15:10.340 --> 00:15:13.340
by a guy who is he's at Yale.

285
00:15:13.341 --> 00:15:16.790
And he thinks that we need to be easier on the past and harder on the president

286
00:15:16.880 --> 00:15:19.130
in this book. And one of the things he points out is like, oh,

287
00:15:19.160 --> 00:15:21.280
people these days like humans, modern humans United,

288
00:15:21.281 --> 00:15:22.640
we go out and we don't know what a plant is,

289
00:15:22.641 --> 00:15:25.130
or we don't know what an animal is and he's right, right. We don't,

290
00:15:25.610 --> 00:15:27.710
most people don't have, uh,

291
00:15:27.830 --> 00:15:31.520
have the knowledge of the natural world that hunter gatherers do.

292
00:15:31.730 --> 00:15:34.070
But at the same time, they don't know about the germ theory of disease.

293
00:15:34.550 --> 00:15:37.820
They don't know about, you know, planetary cycles.

294
00:15:37.940 --> 00:15:41.060
And so it's always important for me,

295
00:15:41.061 --> 00:15:44.390
at least as soon as I start to get sucked into one of these binaries, right.

296
00:15:44.391 --> 00:15:45.920
It was so bad. It's so bad.

297
00:15:45.921 --> 00:15:49.790
Now today to remember that it was also bad,

298
00:15:50.100 --> 00:15:52.010
bad in different ways in the past.

299
00:15:52.011 --> 00:15:56.390
And we can't make the mistake of thinking that the problem with information in

300
00:15:56.391 --> 00:15:57.950
our, in our consuming of it today,

301
00:15:58.880 --> 00:16:03.860
we can't make the mistake of thinking that that the evil is in the form. It,

302
00:16:03.920 --> 00:16:07.970
we can make it good. We can make it better. We can learn how to deal with this.

303
00:16:08.180 --> 00:16:11.270
I think, um, I hope as long as we're conscious of that,

