WEBVTT

1
00:00:00.960 --> 00:00:05.880
<v 0>The Joe Rogan experience. Televangelists are one of the very weirdest, uh,</v>

2
00:00:06.300 --> 00:00:10.920
elements of society, where we are. We're allowing people to just lie,

3
00:00:11.130 --> 00:00:12.390
like clearly lie,

4
00:00:12.570 --> 00:00:17.490
but we feel like the lie is so obvious that you have to be so dumb to

5
00:00:17.491 --> 00:00:21.630
believe them. I can't help you. And this is, I made this analogy recently,

6
00:00:21.780 --> 00:00:25.260
cause I was talking about YouTube censorship and how YouTube has decided that

7
00:00:25.261 --> 00:00:30.120
they're going to pull down videos from doctors who have different

8
00:00:30.121 --> 00:00:34.770
opinions on how to handle the coronavirus and criticisms of how things are.

9
00:00:35.190 --> 00:00:38.010
And I'm like, it's really interesting that they make that line.

10
00:00:38.130 --> 00:00:42.240
That that's the line that doctors practicing physicians they'll pull their video

11
00:00:42.241 --> 00:00:46.610
down, but people talk about the flat earth to leave that up. Cause it's, it's,

12
00:00:46.760 --> 00:00:50.880
it's like, it's so dumb. It's like, ah, you can leave that up. That one's,

13
00:00:50.881 --> 00:00:51.750
that one's so dumb.

14
00:00:51.750 --> 00:00:54.720
You have to be a moron to think the earth is hollow and that there's aliens

15
00:00:54.721 --> 00:00:56.760
living inside it, traveling around on laser beams.

16
00:00:56.880 --> 00:01:00.660
There's videos that say that they'll leave those up and they'll leave

17
00:01:00.661 --> 00:01:05.520
televangelists up. But then it gets to these doctors that are saying,

18
00:01:05.580 --> 00:01:09.840
we're looking at the statistics, this is the deaths. This is the deaths, uh,

19
00:01:09.850 --> 00:01:11.160
in terms of age groups.

20
00:01:11.400 --> 00:01:14.070
And this is why it's not nearly as dangerous as we thought it was.

21
00:01:14.250 --> 00:01:17.670
And these quarantines are not the best way to handle it.

22
00:01:17.760 --> 00:01:19.950
We think there's better way. They'll take that video down.

23
00:01:20.040 --> 00:01:23.670
Even if it's someone who's saying rational things. And I,

24
00:01:24.150 --> 00:01:28.710
I don't think that's smart. I don't think that's a healthy way to handle things.

25
00:01:28.711 --> 00:01:30.720
I don't think it's good for the debate. I think in fact,

26
00:01:31.020 --> 00:01:34.200
it strengthens the resolve of the people on the other side that watch those

27
00:01:34.201 --> 00:01:37.020
videos and some of those points resonate with those people.

28
00:01:37.230 --> 00:01:39.840
I think that's not the way to handle it.

29
00:01:39.870 --> 00:01:42.180
I don't think removing those videos is the way to handle it.

30
00:01:42.181 --> 00:01:45.780
I think the way to handle it is let other people with opposing points of view,

31
00:01:45.990 --> 00:01:50.760
put their videos up and let people discuss and debate and

32
00:01:50.850 --> 00:01:52.590
see which one makes more sense to you.

33
00:01:52.591 --> 00:01:55.830
And usually the weight of the information overwhelms the.

34
00:01:56.670 --> 00:01:58.650
And at least with most people,

35
00:01:58.890 --> 00:02:03.450
I don't understand why it's okay to leave some obviously full of

36
00:02:03.840 --> 00:02:07.710
videos up, but take down things that are very,

37
00:02:07.740 --> 00:02:09.810
very controversial, but debatable.

38
00:02:10.460 --> 00:02:11.900
<v 1>Okay. So this,</v>

39
00:02:11.901 --> 00:02:16.370
this now gets into that part of your episode with Bridget from over the weekend

40
00:02:16.371 --> 00:02:20.000
that I saw where you basically accurately characterize the, the,

41
00:02:20.001 --> 00:02:22.970
the view that I had last time I was on with you about the regulation of social

42
00:02:22.971 --> 00:02:24.290
media. Um,

43
00:02:24.320 --> 00:02:28.070
so first just to play devil's advocate just for a second on,

44
00:02:28.071 --> 00:02:32.510
why do you leave up flat earth, but take down, um, the, you know,

45
00:02:32.511 --> 00:02:34.370
coronavirus videos that you tuber,

46
00:02:34.371 --> 00:02:39.230
whoever disagrees with one can make an argument that there is no real

47
00:02:39.231 --> 00:02:42.620
action someone would take because they believe the earth is flat.

48
00:02:42.920 --> 00:02:44.660
That would endanger others. I mean,

49
00:02:44.661 --> 00:02:48.200
I guess you might try to go to the edge and see if you fall off or something,

50
00:02:48.201 --> 00:02:48.800
right? Like,

51
00:02:48.800 --> 00:02:53.720
but there's no actionable thing for the most part that flat earth belief,

52
00:02:54.680 --> 00:02:58.220
because that's a good point. Whereas if this disinformation about,

53
00:02:58.221 --> 00:02:59.051
so like I'll give you one, I,

54
00:02:59.051 --> 00:03:02.080
there was a video I saw about coronavirus where there was a doctor saying,

55
00:03:02.650 --> 00:03:03.280
you know,

56
00:03:03.280 --> 00:03:08.230
these quarantines are dangerous because if you're not exposed

57
00:03:08.380 --> 00:03:11.590
to bacteria, your um,

58
00:03:11.650 --> 00:03:15.580
immune system will be out of practice essentially. And it's not,

59
00:03:15.610 --> 00:03:17.650
it's going to shut down. It's not going to work as well.

60
00:03:18.040 --> 00:03:21.670
And then another doctor, another YouTube guy who has a YouTube channel,

61
00:03:21.700 --> 00:03:26.320
did a counterpoint where he said, he's talking about the hygienic theory,

62
00:03:26.350 --> 00:03:27.820
but he has it backwards.

63
00:03:27.880 --> 00:03:32.860
It is true that if you were never exposed to dirt and bacteria and

64
00:03:32.861 --> 00:03:34.990
whatever it will impact your immune system,

65
00:03:34.991 --> 00:03:36.850
but it's actually the opposite is what happens.

66
00:03:36.851 --> 00:03:39.580
It's that because you're not regularly exposed to things,

67
00:03:39.940 --> 00:03:43.690
your immune system will overreact and it'll start attacking things that aren't

68
00:03:43.691 --> 00:03:47.350
really a threat. Okay. So what's the harm, I guess. Right?

69
00:03:47.351 --> 00:03:51.130
Like there was a video where these doctors identified what they think is the

70
00:03:51.131 --> 00:03:53.860
problem with the quarantine and then another time approximately.

71
00:03:54.330 --> 00:03:55.560
<v 0>Secondary. I think it's both things though.</v>

72
00:03:55.561 --> 00:03:57.420
I think it's actually been proven that yeah,

73
00:03:57.421 --> 00:04:01.320
that does happen where your immune system overreacts to people that don't get

74
00:04:01.321 --> 00:04:03.390
exposed to enough. But I think there's also,

75
00:04:03.391 --> 00:04:07.110
it's also been proven that people that are around a lot of different people and

76
00:04:07.111 --> 00:04:11.310
constantly exposed to people have stronger immune systems because of that,

77
00:04:11.730 --> 00:04:16.380
that it does get practice and it does get strengthened by exposure. Oh.

78
00:04:16.380 --> 00:04:19.110
<v 1>Yeah, no, I think that's what the sort of fact-check was saying,</v>

79
00:04:19.111 --> 00:04:22.650
which is it's completely true that exposing kids, you know,

80
00:04:22.651 --> 00:04:24.780
to the world out there is good,

81
00:04:25.020 --> 00:04:29.830
but that what is being asserted will happen from staying home for two months is,

82
00:04:29.831 --> 00:04:32.130
is both wrong. And it wouldn't happen in two months.

83
00:04:32.850 --> 00:04:34.980
<v 0>Sit like the idea that a, we can see me and say, I, yeah,</v>

84
00:04:34.981 --> 00:04:35.970
I was wondering about that.

85
00:04:35.971 --> 00:04:38.520
Whether or not it was like a cardiovascular system like that,

86
00:04:38.521 --> 00:04:43.200
it only responds to the level of, you know, work that it needs to do,

87
00:04:43.530 --> 00:04:46.230
like your, your cardiovascular system. You know, you've, if you run,

88
00:04:46.290 --> 00:04:49.170
if you take some time off, but it slacks off really quickly,

89
00:04:49.530 --> 00:04:51.990
it will be a real shame. If that was the case with the immune system.

90
00:04:52.200 --> 00:04:53.640
I don't think it is. But I mean.

91
00:04:55.020 --> 00:04:58.680
<v 1>I guess the point I was trying to make was if you,</v>

92
00:04:58.710 --> 00:05:02.310
there are a lot of people who are understandably frustrated by what's going on

93
00:05:02.730 --> 00:05:07.380
and they're looking for any excuse to just let it rip so to

94
00:05:07.381 --> 00:05:11.370
speak and go and do whatever. And so I think that the play devil's advocate,

95
00:05:11.400 --> 00:05:15.210
there is a different level of risk from allowing some of this disinformation to

96
00:05:15.211 --> 00:05:19.110
be propagated that doesn't exist with leaving flat earth up.

97
00:05:19.380 --> 00:05:22.680
That's a very good point, very good point. But, but that being said, you know,

98
00:05:22.681 --> 00:05:25.710
we, last time we talked, we had this conversation about like, okay,

99
00:05:26.070 --> 00:05:28.440
if a platform gets to a certain size,

100
00:05:29.280 --> 00:05:34.260
does it not kind of enter some new space where you need someone to

101
00:05:34.290 --> 00:05:36.600
establish some guidelines for some pauses?

102
00:05:36.710 --> 00:05:40.050
<v 0>Can you real quick, what are the problems with this argument though?</v>

103
00:05:40.080 --> 00:05:43.260
Is that particularly like, did those doctors in Bakersfield,

104
00:05:43.560 --> 00:05:45.210
they weren't spreading disinformation.

105
00:05:45.990 --> 00:05:50.970
They were basically spreading the actual facts of fatalities and age groups

106
00:05:51.230 --> 00:05:55.080
and, and, you know, they just had a different perspective. Well,

107
00:05:55.140 --> 00:05:56.850
not even the different interpretation,

108
00:05:57.000 --> 00:05:58.760
cause basically just going over the statistics,

109
00:05:58.761 --> 00:06:02.570
but they had a different viewpoint of how they should move forward.

110
00:06:02.600 --> 00:06:06.230
And they were also discussing things like furlough doctors and nurses,

111
00:06:06.231 --> 00:06:09.050
because hospitals are no longer doing elective surgery.

112
00:06:09.051 --> 00:06:12.980
So in many hospitals are in the verge of bankruptcy, which apparently is true.

113
00:06:13.680 --> 00:06:16.880
The problem is that's not disinformation.

114
00:06:17.150 --> 00:06:18.920
And so if you're saying that,

115
00:06:19.400 --> 00:06:22.700
if giving people this information makes them make poor choices and they could be

116
00:06:22.701 --> 00:06:26.720
putting themselves at risk or putting loved ones at risk because of that. Yes.

117
00:06:26.750 --> 00:06:30.080
Okay. I'm with you. Yeah, I agree. But this isn't disinformation,

118
00:06:30.290 --> 00:06:31.970
this is actual information.

119
00:06:32.210 --> 00:06:35.330
It's just information with a different perspective other than the,

120
00:06:35.331 --> 00:06:36.230
what we're getting,

121
00:06:36.560 --> 00:06:39.770
which has only one point of view from the world health organization and people

122
00:06:39.771 --> 00:06:43.910
who subscribed to those ideas. So it's not a lie, but I think your point of,

123
00:06:44.060 --> 00:06:47.000
if someone believes in the flat earth, there's no harm in that. That's true.

124
00:06:47.210 --> 00:06:50.660
So if someone believes in pizza gate and they think that there's kids being held

125
00:06:50.661 --> 00:06:53.210
in a basement somewhere and they go and shoot up the store,

126
00:06:53.480 --> 00:06:57.380
then it is a problem right now that kind of a video I can understand where

127
00:06:57.381 --> 00:07:00.440
someone would say, Hey, you know that shouldn't be up there because this is.

128
00:07:00.980 --> 00:07:02.720
And this is, this is what gets caused from that.

129
00:07:02.900 --> 00:07:06.980
I don't think it's the same argument when we're all trying to figure out what's

130
00:07:06.981 --> 00:07:11.420
going on with a medical situation and to practicing

131
00:07:11.421 --> 00:07:12.201
physicians,

132
00:07:12.201 --> 00:07:17.090
to actual medical doctors are talking about their perspective on this virus.

133
00:07:17.240 --> 00:07:20.150
So, no, I don't think they're really on the same line.

134
00:07:20.560 --> 00:07:24.760
<v 1>Yeah, totally. I totally agree that these are not all equivalent situations. Um,</v>

135
00:07:25.060 --> 00:07:28.660
but for the purposes of, you know, our conversation about like who,

136
00:07:28.720 --> 00:07:31.630
what regulations should be in place, right.

137
00:07:31.690 --> 00:07:34.930
Who gets to regulate or this sort of thing. The,

138
00:07:35.200 --> 00:07:39.370
the point that I had made last time we talked about this was not

139
00:07:39.371 --> 00:07:44.080
necessarily that I'm in favor or against having some kind of infrastructure that

140
00:07:44.081 --> 00:07:47.530
says here's how a social network has to operate YouTube, Twitter, whatever.

141
00:07:47.890 --> 00:07:52.180
We can talk about that. And I'm glad to my argument last time we talked was,

142
00:07:52.780 --> 00:07:55.720
I don't know what the legal case is.

143
00:07:55.721 --> 00:07:59.920
How do you define legally what it is that is supposed to happen?

144
00:08:00.280 --> 00:08:03.040
Is it like what, what would be the legal framework for that?

145
00:08:03.070 --> 00:08:06.880
And there's also a double standard element of it because there's a lot of

146
00:08:06.881 --> 00:08:07.391
really,

147
00:08:07.391 --> 00:08:11.980
really loud right-wingers who are saying the left is being

148
00:08:11.981 --> 00:08:15.940
propped up on social media and the right is being suppressed to put it very

149
00:08:15.941 --> 00:08:19.540
simply, right? And they're calling for regulation,

150
00:08:20.200 --> 00:08:22.600
they're against new regulation on gun safety.

151
00:08:23.110 --> 00:08:27.220
They're against business regulation. They're against stay at home order,

152
00:08:27.250 --> 00:08:30.100
et cetera. Now they want to regulate tweets.

153
00:08:30.101 --> 00:08:32.170
Like that's where now they want regulation.

154
00:08:32.200 --> 00:08:35.350
That seems extremely cynical and hypocritical to me,

155
00:08:35.860 --> 00:08:39.220
but we don't even necessarily have to dig into that to think about like, okay,

156
00:08:39.380 --> 00:08:41.230
if, if we regulate it, how do we regulate it?

157
00:08:41.231 --> 00:08:42.850
Who gets to decide is where you start.

158
00:08:42.910 --> 00:08:44.560
<v 0>I think we're dealing with the thing.</v>

159
00:08:44.561 --> 00:08:46.270
That's very similar to what we talked about earlier.

160
00:08:46.271 --> 00:08:51.070
The founding fathers who set up this country in the 17 hundreds had no idea what

161
00:08:51.071 --> 00:08:55.830
2020 was going to be like. And I think when you're talking about freedom speech,

162
00:08:56.220 --> 00:08:57.930
it's like, do you still have freedom of speech?

163
00:08:57.931 --> 00:09:01.470
If you could just talk and you can't tweet, well, I guess you do, right.

164
00:09:01.650 --> 00:09:05.490
Do you have still have freedom to get the word out? Well, you do,

165
00:09:05.491 --> 00:09:08.640
but you don't have freedom like you or I do where you could tweet,

166
00:09:08.641 --> 00:09:12.240
or you can make a YouTube video and who gets to have that.

167
00:09:12.241 --> 00:09:14.970
And is that an essential service?

168
00:09:14.971 --> 00:09:18.240
Is that a thing like the post office or a thing?

169
00:09:18.241 --> 00:09:22.860
Like the electricity and the utilities? Is it essential?

170
00:09:23.010 --> 00:09:26.910
An essential thing? I think one could make the argument that in 2020,

171
00:09:27.240 --> 00:09:30.450
it's used by so many people to convey so much information.

172
00:09:30.450 --> 00:09:33.360
And it's so significant that I believe it is an essential thing.

173
00:09:33.690 --> 00:09:37.560
And I think that just banning someone because you don't like what they say or

174
00:09:37.561 --> 00:09:39.360
you don't like how they say it.

175
00:09:39.600 --> 00:09:44.040
I don't think that's a solution nor do I think there's a clear solution because

176
00:09:44.041 --> 00:09:47.310
I think that if you have someone who is hateful and is doxing people and

177
00:09:47.550 --> 00:09:51.000
insulting people and stalking people online and saying horrible things,

178
00:09:51.300 --> 00:09:55.230
that's not good either. Right? There's there's laws about that in person,

179
00:09:55.410 --> 00:09:59.340
you can't harass people in person. Why can you harass people online?

180
00:09:59.341 --> 00:10:02.940
Why can you put up your address and have a bunch of people send terrible things

181
00:10:02.941 --> 00:10:06.090
to your house? Like what, why is that? Okay, well, it shouldn't be okay either.

182
00:10:06.240 --> 00:10:08.490
We need to figure out what's okay and what's not okay.

183
00:10:08.670 --> 00:10:12.870
And I think one of the problems with isolating tech,

184
00:10:12.900 --> 00:10:16.740
I think tech people and people that whether it's Google or apple,

185
00:10:16.741 --> 00:10:21.270
and you've made a really good argument that they may appear left socially,

186
00:10:21.271 --> 00:10:26.100
but they absolutely operate right when it comes to finance when it comes to

187
00:10:26.130 --> 00:10:28.620
their business. And I think that is true.

188
00:10:28.770 --> 00:10:33.300
But I think that when you're dealing with the ability to discuss things,

189
00:10:33.690 --> 00:10:37.920
and you might say that your perspective is the one that you want to hear because

190
00:10:37.921 --> 00:10:40.050
you're a left wing person and these are your beliefs,

191
00:10:40.530 --> 00:10:44.340
but you're isolating the whole other team from being a part of that

192
00:10:44.341 --> 00:10:45.174
conversation.

193
00:10:45.210 --> 00:10:48.240
And maybe they have something you want to hear and maybe they don't have

194
00:10:48.241 --> 00:10:52.800
anything you want to hear, but to not allow them to communicate,

195
00:10:52.801 --> 00:10:56.700
you are alienating a giant chunk of the population.

196
00:10:56.850 --> 00:10:59.610
And if someone gets to a prominent level where they're,

197
00:10:59.640 --> 00:11:01.320
they're communicating a certain way,

198
00:11:01.470 --> 00:11:05.310
and you just decide that that certain way is unacceptable and you kick them off,

199
00:11:05.490 --> 00:11:07.350
you don't just kick them off.

200
00:11:07.530 --> 00:11:12.240
You also silence all the other people that are along or aligned with

201
00:11:12.241 --> 00:11:15.420
them because they have similar ideas and they didn't want to speak out either.

202
00:11:15.420 --> 00:11:19.440
When you, when you band James Woods, you don't just ban James Woods,

203
00:11:19.441 --> 00:11:23.640
you ban a lot of other people from saying something they might be furious about,

204
00:11:24.210 --> 00:11:25.940
you know, the, the Russia investigation,

205
00:11:25.960 --> 00:11:29.490
whatever they want to express themselves. And they, they, they, they panic.

206
00:11:29.520 --> 00:11:32.970
They get scared. They worry that they're going to get that censorship.

207
00:11:33.000 --> 00:11:36.150
That's a form of censorship. And I think these companies,

208
00:11:36.690 --> 00:11:41.130
I don't blame them because I don't think they had any idea what they were going

209
00:11:41.131 --> 00:11:43.740
to become. And I think they're all adjusting along the way.

210
00:11:43.920 --> 00:11:46.530
I think when Twitter was first, when Twitter first came out,

211
00:11:46.590 --> 00:11:47.250
do you remember that,

212
00:11:47.250 --> 00:11:51.120
like you would write at David PackMan is going to the movies. You like you like,

213
00:11:51.450 --> 00:11:54.850
you know, Joe Rogan just had a great pizza. That's what you did. I mean, it,

214
00:11:54.851 --> 00:11:59.290
wasn't this thing where you got to express yourself and 240 whatever characters

215
00:11:59.291 --> 00:12:02.080
and we're in a different world now.

216
00:12:02.230 --> 00:12:05.980
And I think this different world needs some different examination about what the

217
00:12:05.981 --> 00:12:08.470
ability to communicate online is. And this is, uh,

218
00:12:09.100 --> 00:12:11.890
an important point because Alex Jones made some crazy video after our

219
00:12:11.891 --> 00:12:13.600
conversation that I had with him yesterday,

220
00:12:14.060 --> 00:12:17.290
where he was saying that I'm going to war against censorship in a war against

221
00:12:17.291 --> 00:12:21.640
YouTube. That's, I'm not doing any of those things. Uh, I made this deal.

222
00:12:21.640 --> 00:12:24.610
<v 1>With Spotify, Spotify. I made the deal with.</v>

223
00:12:24.610 --> 00:12:28.240
<v 0>Spotify because it's a great company and it's a great deal.</v>

224
00:12:28.241 --> 00:12:32.260
And I'm excited to be in a partnership with a company as opposed to like a

225
00:12:32.261 --> 00:12:34.870
company that I just put my stuff up on their platform,

226
00:12:34.871 --> 00:12:39.430
whether it's apple or YouTube. I don't like that. YouTube sensors things.

227
00:12:39.431 --> 00:12:43.180
I don't like that. They do that like with those doctors in Bakersfield. Uh,

228
00:12:43.200 --> 00:12:46.090
but I'm not at war with them and not a war with anybody and I'm not okay.

229
00:12:46.150 --> 00:12:49.750
I don't, I don't envy them their position.

230
00:12:49.900 --> 00:12:54.880
I don't think it's smart to censor practicing doctors when they have differing

231
00:12:54.881 --> 00:12:57.310
opinions. I think we need to find out who's right.

232
00:12:57.520 --> 00:12:59.350
And I think the way you find out who's right,

233
00:12:59.351 --> 00:13:01.570
is you get people who are experts and they disagree.

234
00:13:01.571 --> 00:13:03.520
There's Nobel laureates out there. And I've, I've,

235
00:13:03.521 --> 00:13:07.690
I've watched several videos that are talking about this lockdown and that it's

236
00:13:07.691 --> 00:13:08.260
not a good idea.

237
00:13:08.260 --> 00:13:12.700
There's people that believe in herd mentality versus immunizations and or

238
00:13:12.701 --> 00:13:14.530
vaccines. And I don't know who's right.

239
00:13:14.531 --> 00:13:18.700
And I would like them to all be able to discuss it equally and openly that said,

240
00:13:19.270 --> 00:13:24.010
I don't envy Twitter. I don't envy YouTube. I don't envy any of these people.

241
00:13:24.130 --> 00:13:27.400
The idea of trying to manage this in real time,

242
00:13:27.520 --> 00:13:31.870
while it explodes and takes over the way human beings communicate over a period

243
00:13:31.871 --> 00:13:33.550
of a decade, just like that.

244
00:13:33.910 --> 00:13:37.900
That's so instantaneous and mistakes have been made. And in my opinion,

245
00:13:37.901 --> 00:13:42.700
when it comes to the way things are censored and the way it's made

246
00:13:42.701 --> 00:13:47.040
these mistakes, particularly on Twitter far favor the left and they're,

247
00:13:47.080 --> 00:13:48.160
they're not balanced.

248
00:13:48.280 --> 00:13:51.730
And like some horrible things that people on the left say about people on the

249
00:13:51.731 --> 00:13:54.520
right. And it's nothing. It gets just gets washed away.

250
00:13:54.850 --> 00:13:57.490
But when the people do it, who are on the right about people on the left,

251
00:13:57.520 --> 00:14:00.580
they get banned. It's not fair. And when things aren't fair,

252
00:14:00.700 --> 00:14:04.540
one side has a better argument that they're being censored and that there's some

253
00:14:04.541 --> 00:14:07.390
sort of a conspiracy and it divides people even more.

254
00:14:07.540 --> 00:14:12.460
It strengthens the hate instead of, instead of like, I think most people,

255
00:14:12.700 --> 00:14:14.050
the vast majority, 70,

256
00:14:14.051 --> 00:14:16.930
80% are reasonable people that you could have a conversation with.

257
00:14:16.960 --> 00:14:17.651
If you were in front of them,

258
00:14:17.651 --> 00:14:21.280
one-on-one when they don't feel like they're a part of the conversation or when

259
00:14:21.281 --> 00:14:25.780
they speak their side and their stuff gets deleted or removed or put into some,

260
00:14:25.810 --> 00:14:30.670
you know, some shadow banned category. It's, it's infuriating for people.

261
00:14:30.760 --> 00:14:33.850
And it's not good for all of us as a community.

262
00:14:34.120 --> 00:14:38.290
And I think that is the burden that these places like YouTube or, or,

263
00:14:38.291 --> 00:14:42.280
or Twitter, they have to shoulder this burden. And, um,

264
00:14:42.340 --> 00:14:44.200
I don't know how to do it. I don't know. I mean,

265
00:14:44.860 --> 00:14:46.330
Republicans have one perspective.

266
00:14:46.540 --> 00:14:49.120
There's many people like yourself that have the perspective, like, listen,

267
00:14:49.140 --> 00:14:52.340
it's their company should not, they be able to make their own rules.

268
00:14:52.700 --> 00:14:55.670
I think they're too big. I think they're too big for that now.

269
00:14:55.671 --> 00:14:56.411
And I think that it's,

270
00:14:56.411 --> 00:15:01.130
it's in this position where it literally is a part of who we are

271
00:15:01.190 --> 00:15:02.840
as, as human beings,

272
00:15:03.020 --> 00:15:07.220
the ability to express ideas and communicate is so critical right now.

273
00:15:07.400 --> 00:15:09.990
And as we're evolving and as we're are, we're,

274
00:15:09.991 --> 00:15:14.960
we're evolving our culture and our civilization discourse is so

275
00:15:14.990 --> 00:15:19.490
important. It's, it's, it's, it's a giant part of being a human being in 2020.

276
00:15:19.610 --> 00:15:22.550
And I don't think it should be just flippantly removed from people.

277
00:15:23.350 --> 00:15:27.790
<v 1>So my personal view is very similar to yours in terms of, you know,</v>

278
00:15:27.791 --> 00:15:31.780
short of like illegal content and really very specific things.

279
00:15:31.781 --> 00:15:35.890
My instinct is leave it up and let the, the sort of, uh,

280
00:15:35.920 --> 00:15:40.250
let people evaluate it, let people publish counter points. That's my,

281
00:15:40.420 --> 00:15:45.010
my personal view. Now the, the conservative view on this is,

282
00:15:45.280 --> 00:15:46.570
you know, if you,

283
00:15:46.630 --> 00:15:51.130
if this cake baker doesn't want to bake a cake because of who you want to marry,

284
00:15:51.640 --> 00:15:54.820
you don't do anything to the baker. You just go and, you know, the market will,

285
00:15:54.821 --> 00:15:58.990
if there is a demand for those types of cakes, for those types of weddings,

286
00:15:59.710 --> 00:16:01.360
bakers will enter the market. And that's it.

287
00:16:01.720 --> 00:16:04.840
If you apply that here and we'll get to the differences in a second,

288
00:16:05.110 --> 00:16:07.570
if you apply that here, if the James Woods is,

289
00:16:07.571 --> 00:16:11.530
want to say stuff and a whole bunch of people want to hear that stuff,

290
00:16:12.310 --> 00:16:15.460
why don't they just go and make their platform and bring everybody over?

291
00:16:15.461 --> 00:16:17.350
It sounds like a great business, right? Yeah.

292
00:16:17.380 --> 00:16:18.460
<v 0>It does sound a great business.</v>

293
00:16:19.030 --> 00:16:23.020
It's way harder to do way harder to do than just do it. I mean, to say,

294
00:16:23.021 --> 00:16:25.900
why don't you make another Twitter? Well, there would be a thousand Twitters.

295
00:16:26.170 --> 00:16:28.690
It's obviously very difficult. No one's ever been able to do it.

296
00:16:28.750 --> 00:16:31.500
It's not something that's, it's, you're,

297
00:16:31.501 --> 00:16:34.510
you're talking about something that takes an enormous amount of resources. It's,

298
00:16:34.520 --> 00:16:37.630
it's not that it's not that simple.

299
00:16:38.840 --> 00:16:39.640
<v 1>And everybody already.</v>

300
00:16:39.640 --> 00:16:42.250
<v 0>Does, but everybody already does use Twitter.</v>

301
00:16:42.640 --> 00:16:47.500
So I think the question really is does Twitter have a responsibility for

302
00:16:47.501 --> 00:16:51.640
fair and even treatment? You know, and I I'm sure you've seen some of those, uh,

303
00:16:52.030 --> 00:16:56.590
James Veritas, uh, James O'Keefe for other project Veritas videos where they,

304
00:16:56.860 --> 00:16:59.350
uh, secret cameras, filming executives,

305
00:16:59.351 --> 00:17:02.190
talking about how to censor conservative people. Um, I.

306
00:17:02.190 --> 00:17:06.580
<v 1>I've seen a little bit of it. What, what I do remember is from the, um, uh,</v>

307
00:17:06.581 --> 00:17:08.140
planned parenthood era,

308
00:17:08.141 --> 00:17:12.100
where what they published was pretty dramatically dishonest from what I recall,

309
00:17:12.101 --> 00:17:15.010
but I've not seen the one you're referring to specifically. That was a long.

310
00:17:15.010 --> 00:17:18.490
<v 0>Time ago. It wasn't. How long ago was that? The planned parenthood stuff?</v>

311
00:17:18.970 --> 00:17:23.550
Was it five years? Are you talking about the acorn stuff? The, uh,

312
00:17:23.551 --> 00:17:24.850
the stuff where the,

313
00:17:24.880 --> 00:17:29.860
they brought in a pimp to try to get money for opening up a brothel.

314
00:17:30.190 --> 00:17:33.790
<v 1>It's been so long that the details escape me, but I remember that there,</v>

315
00:17:33.880 --> 00:17:35.080
I remember that incident.

316
00:17:35.081 --> 00:17:37.360
I've not really seen anything recently that they've done it. You have.

317
00:17:37.360 --> 00:17:41.110
<v 0>Deceptive editing, you know, the problem is even if in the future you're don't,</v>

318
00:17:41.140 --> 00:17:42.910
you don't do that anymore. It's like,

319
00:17:42.970 --> 00:17:46.060
everyone's always going to remember that you did do something. Yes.

320
00:17:46.120 --> 00:17:50.550
You did do something that wasn't straightforward. Cut dry, no emotion,

321
00:17:50.580 --> 00:17:53.070
journalism just here are the facts, uh,

322
00:17:53.100 --> 00:17:57.180
planned parenthood awarded $2 million in lawsuit over secret videos.

323
00:17:57.570 --> 00:17:58.830
Interesting. That's not good.

324
00:17:59.420 --> 00:18:00.950
<v 1>Yeah, that was, that was that's. That's my,</v>

325
00:18:00.951 --> 00:18:04.370
a big memory when you mentioned that, that, uh, that organization. But,

326
00:18:04.550 --> 00:18:09.170
so I think that let's say we agree about something needs to be done once you're

327
00:18:09.171 --> 00:18:09.921
at a certain level,

328
00:18:09.921 --> 00:18:12.920
you enter a new category and some kind of regulation has to be done.

329
00:18:13.310 --> 00:18:17.240
Who does the regulation? When you look at, uh, redistricting, for example,

330
00:18:17.540 --> 00:18:21.390
this has been like a multi-decade thing where when Republicans are empowered,

331
00:18:21.391 --> 00:18:23.900
they draw the districts in a way that's favorable to them.

332
00:18:24.230 --> 00:18:25.550
Democrats are in power.

333
00:18:25.760 --> 00:18:29.450
They take the opportunity to redraw districts that are favorable to them.

334
00:18:29.780 --> 00:18:31.400
You have these ideas of, okay,

335
00:18:31.401 --> 00:18:34.400
we'll have a commission with three Democrats and three Republicans,

336
00:18:34.401 --> 00:18:37.910
and together they'll figure out how the districts could be drawn fairly.

337
00:18:38.850 --> 00:18:41.810
How do you apply that at what? The lesson from that?

338
00:18:41.811 --> 00:18:46.400
How do you apply it to there's the Trump administration decide what kind of

339
00:18:46.401 --> 00:18:49.760
content must be left up versus what can be removed,

340
00:18:49.850 --> 00:18:54.080
but then that administration gets replaced. Now, the next administration says,

341
00:18:54.380 --> 00:18:57.290
here's how Twitter is supposed to operate. Like, how do you do it?

342
00:18:58.130 --> 00:19:00.890
<v 0>A really good question. And it's a really hard question. That's what I'm saying.</v>

343
00:19:00.891 --> 00:19:03.410
I don't, I don't envy those people. Um, you know,

344
00:19:03.411 --> 00:19:06.740
I really liked Jack Dorsey as a person. I really enjoy talking to him.

345
00:19:06.741 --> 00:19:11.120
I think he's a very thoughtful guy. And in, in discussing this with him,

346
00:19:11.510 --> 00:19:15.320
both on the show and off the show, you know, they,

347
00:19:15.650 --> 00:19:18.920
they don't really know exactly how to handle these things.

348
00:19:19.060 --> 00:19:22.220
So they don't really know what the perfect solution is.

349
00:19:22.221 --> 00:19:24.890
And he's even proposed a wild west Twitter,

350
00:19:25.250 --> 00:19:29.450
and then a Twitter that's under some sort of moderation.

351
00:19:30.290 --> 00:19:33.470
Um, and I don't know where they stand on that right now,

352
00:19:33.471 --> 00:19:37.100
but that was something that they were, he was actively bringing up. Like,

353
00:19:37.310 --> 00:19:38.780
let's have a Twitter where anything goes,

354
00:19:39.020 --> 00:19:41.090
you could like read it in the early days.

355
00:19:41.091 --> 00:19:44.810
You could do whatever the you wanted versus what they're, what they have now.

356
00:19:45.350 --> 00:19:49.580
Um, but here's another example when, when you, when a person gets so big,

357
00:19:49.581 --> 00:19:52.700
like Trump, you can get away, you could do on Twitter.

358
00:19:53.030 --> 00:19:55.820
That there's no way you could do, right? Like,

359
00:19:55.940 --> 00:19:59.840
have you seen the recent thing where he's accusing Joe Scarborough of, uh,

360
00:19:59.900 --> 00:20:03.020
possibly being a part of a murder or something like that?

361
00:20:03.110 --> 00:20:05.930
I saw that he's bringing up. I mean, apparently totally.

362
00:20:05.960 --> 00:20:10.010
I don't know the exact details of the story, but it been investigated.

363
00:20:10.011 --> 00:20:13.180
It had nothing to do with it. It was just so many worked with, and,

364
00:20:13.181 --> 00:20:14.014
and Trump is,

365
00:20:14.780 --> 00:20:19.610
he's putting out this thing particularly just to try to target Joe

366
00:20:19.611 --> 00:20:23.660
Scarborough, get his fans to go nutty and with him, you know?

367
00:20:23.661 --> 00:20:25.940
And that's a weird way of that.

368
00:20:25.941 --> 00:20:30.470
That that's a right wing guy who is literally the top right-wing guy. Right.

369
00:20:30.620 --> 00:20:35.090
So, yeah, right-wing bias. Doesn't seem to apply totally, uh, you know,

370
00:20:35.091 --> 00:20:38.120
negative bias when it, when it comes to the president and the president,

371
00:20:38.121 --> 00:20:41.030
when you get to a certain level, like you could just do like that.

372
00:20:41.031 --> 00:20:44.360
Like you could just threaten North Korea. Like you could say,

373
00:20:44.361 --> 00:20:49.030
we have the best muscles, we'll you up. Like he can tweet that he could tweet,

374
00:20:49.031 --> 00:20:52.900
Hey, Hey buddy, I'm glad you fake your death. And I know you're still alive,

375
00:20:52.901 --> 00:20:55.150
but I just want you to know we got the best muscles and we'll you up.

376
00:20:55.490 --> 00:20:58.440
Have he tweeted that like, whoa, but this is not.

377
00:20:58.440 --> 00:20:59.550
<v 1>Really a unique,</v>

378
00:20:59.580 --> 00:21:02.310
the Twitter in the sense that if you look at our justice system,

379
00:21:02.730 --> 00:21:05.640
there's sort of like the justice system for the elites.

380
00:21:05.700 --> 00:21:07.080
And then for other people,

381
00:21:07.081 --> 00:21:10.530
the focus on street crime instead of white collar crime, I mean, this,

382
00:21:10.770 --> 00:21:12.360
this exists in a lot of different places.

383
00:21:12.361 --> 00:21:15.990
What kind of really big business get away with versus what can a small business

384
00:21:16.620 --> 00:21:18.450
get away. So I don't think that's different.

385
00:21:19.290 --> 00:21:24.000
One of the things I'm thinking about is what's the main point of Twitter,

386
00:21:24.001 --> 00:21:27.060
like Twitter is a publicly traded corporation. So at this point,

387
00:21:27.061 --> 00:21:30.990
is it fair to say that the main point of Twitter is to be profitable and,

388
00:21:31.250 --> 00:21:33.690
and deliver a return to shareholders?

389
00:21:33.691 --> 00:21:36.360
Because if it is all the stuff we're talking about,

390
00:21:36.361 --> 00:21:39.300
about how we would like to see it operate is sort of irrelevant because they now

391
00:21:39.301 --> 00:21:41.870
have this fiduciary responsibility to just make money.

392
00:21:42.030 --> 00:21:45.570
<v 0>Right? What do you think Twitter's worth? Like, like if someone,</v>

393
00:21:45.900 --> 00:21:47.430
if someone wanted to come over and buy it,

394
00:21:48.570 --> 00:21:51.990
what if the government bought Twitter and just applied the first amendment to

395
00:21:51.991 --> 00:21:55.950
Twitter? What if the government said, listen, you guys are kicking, great job.

396
00:21:56.070 --> 00:21:59.520
However, you're basically a public utility for communication of ideas.

397
00:21:59.550 --> 00:22:04.290
And it's imperative that for Liberty and for the ability for people to have free

398
00:22:04.291 --> 00:22:06.540
speech, everyone has to have access to this.

399
00:22:06.870 --> 00:22:09.120
And so when you go to maybe it's like one of those things,

400
00:22:09.270 --> 00:22:12.090
if you go to jail for a horrible felony, you lose your ability to vote.

401
00:22:12.390 --> 00:22:15.570
Maybe you go to jail for something you lose your ability to tweet. You know,

402
00:22:15.660 --> 00:22:16.493
I mean.

403
00:22:16.590 --> 00:22:18.870
<v 1>Could it be 300 billion? I have no idea.</v>

404
00:22:19.620 --> 00:22:20.790
<v 0>I wonder how much it is. I mean,</v>

405
00:22:20.820 --> 00:22:23.340
how much are they spending on these stimulus packages?

406
00:22:24.060 --> 00:22:27.480
I wonder if they probably buy it cheap right now, to me,

407
00:22:27.510 --> 00:22:31.020
I don't think Twitter really makes money either. I don't think it makes money.

408
00:22:31.500 --> 00:22:31.771
You know,

409
00:22:31.771 --> 00:22:35.310
I think Twitter is when those weird situations where it's worth something.

410
00:22:35.311 --> 00:22:38.180
But I don't, I don't know if it actually does. I don't,

411
00:22:38.181 --> 00:22:42.810
I don't think it's in the, in the profitable area. Right. I don't think it's,

412
00:22:42.990 --> 00:22:46.040
I don't think it's making, is it didn't you when we talked,

413
00:22:46.050 --> 00:22:50.310
Jamie and I talked about this fairly recently. Yeah. It's complicated. You know,

414
00:22:50.311 --> 00:22:53.760
some things make sense, like Google makes sense, right? They use Google ads.

415
00:22:53.761 --> 00:22:56.100
They make a load of money. YouTube makes sense. It's profitable.

416
00:22:56.130 --> 00:22:58.050
It all makes sense. Twitter's like, where are you at?

417
00:22:58.080 --> 00:23:01.420
Where's the money coming from? Like, it's so valuable, but, and it's,

418
00:23:01.650 --> 00:23:04.890
so it's such a useful tool, but how does, how do they make money?

419
00:23:05.430 --> 00:23:10.050
<v 1>That means so literally there are ads on Twitter as well, right? Boosted posts,</v>

420
00:23:10.500 --> 00:23:11.370
promoted advertisements, et cetera.

421
00:23:11.400 --> 00:23:14.550
I have no idea how much money they're making from that versus what is the value

422
00:23:14.551 --> 00:23:16.350
of the user base? Wasn't there.

423
00:23:16.980 --> 00:23:18.600
<v 0>Point recently where a very,</v>

424
00:23:18.660 --> 00:23:23.370
very conservative investor bought a giant chunk of Twitter and was thinking

425
00:23:23.371 --> 00:23:24.840
about kicking out Jack Dorsey.

426
00:23:24.841 --> 00:23:27.240
Wasn't that something that was brought up really recently? No,

427
00:23:27.241 --> 00:23:30.510
I don't know about that. You remember that? Jamie? That was a,

428
00:23:31.770 --> 00:23:34.410
there was a situation. Right. But I don't know if that's how it went down.

429
00:23:34.440 --> 00:23:35.550
Like fairly recently,

430
00:23:35.551 --> 00:23:38.850
someone just bought a controlling stake or a large stake look, man.

431
00:23:39.090 --> 00:23:39.781
<v 1>I just think, is there,</v>

432
00:23:39.781 --> 00:23:43.500
is there anyone you would trust to regulate Twitter and YouTube and Facebook?

433
00:23:43.501 --> 00:23:45.000
Like who would you, who would do it? Ooh.

434
00:23:45.050 --> 00:23:47.510
<v 0>That's a good question. I don't think it should be one person either.</v>

435
00:23:47.511 --> 00:23:50.540
I think it's also like president, like being president.

436
00:23:50.541 --> 00:23:52.280
I don't think she should be the president of Twitter.

437
00:23:52.940 --> 00:23:57.620
I really think it might be wise for all of us to consider it like a

438
00:23:57.621 --> 00:24:01.460
public utility. You would socialize Twitter. Yeah.

439
00:24:01.790 --> 00:24:02.750
I'd give it to Bernie.

440
00:24:03.530 --> 00:24:04.363
<v 2>It's incredible.</v>

441
00:24:05.420 --> 00:24:09.680
<v 0>I think something that has that kind of power,</v>

442
00:24:09.710 --> 00:24:14.600
when it comes to expression, it's a, it's valuable for human beings.

443
00:24:14.670 --> 00:24:17.240
I would never want to take it away from the people that own it obviously.

444
00:24:17.630 --> 00:24:22.490
But I just think as a concept that we should consider that

445
00:24:22.520 --> 00:24:25.100
what we have here with something like Twitter,

446
00:24:25.280 --> 00:24:30.140
or even maybe there's a good argument for YouTube as well, that what these,

447
00:24:30.170 --> 00:24:34.670
these new abilities to express yourself are

448
00:24:36.020 --> 00:24:39.500
there they're incredibly important in terms of the process of our culture,

449
00:24:39.650 --> 00:24:42.830
the process of going over ideas and evolving those ideas.

450
00:24:43.100 --> 00:24:45.500
There's no better way to do that than open communication.

451
00:24:45.530 --> 00:24:48.110
There's no better open communication than Twitter and YouTube.

452
00:24:48.410 --> 00:24:49.790
Like in terms of regular people,

453
00:24:49.910 --> 00:24:52.220
you can start a YouTube video right now on your phone.

454
00:24:52.221 --> 00:24:53.600
I can just set the phone up here,

455
00:24:53.780 --> 00:24:57.200
press record and start talking and then upload it. And bam,

456
00:24:57.201 --> 00:25:01.760
my thoughts could be available to anybody. And I think that's so valuable.

457
00:25:02.000 --> 00:25:06.170
It's so it's so important in terms of our ability to go back and forth with

458
00:25:06.171 --> 00:25:09.160
ideas and we're changing those ideas.

459
00:25:09.260 --> 00:25:12.950
Obviously the way we thought about life in 1960 is very different than the way

460
00:25:12.951 --> 00:25:15.860
we think about life today. And a lot of that comes from discourse.

461
00:25:15.861 --> 00:25:19.130
A lot of that comes from discussion and the evolution of these ideas.

462
00:25:19.190 --> 00:25:20.130
Jamie has something hold on.

463
00:25:20.900 --> 00:25:23.690
<v 2>I think there was a potential corporate takeover that tried,</v>

464
00:25:23.900 --> 00:25:25.580
that maybe happen with them in an agreement.

465
00:25:26.030 --> 00:25:29.360
<v 0>Uh, Twitter reaches deal with activist fund that wanted Jack Dorsey out.</v>

466
00:25:29.930 --> 00:25:32.600
They made a deal. They met on island.

467
00:25:32.930 --> 00:25:34.310
<v 2>And they all, uh, no.</v>

468
00:25:35.620 --> 00:25:36.071
<v 1>Listen. I mean, I,</v>

469
00:25:36.071 --> 00:25:40.180
I couldn't agree more strongly with you about the importance of these platforms.

470
00:25:40.181 --> 00:25:42.040
My entire business is built on them. I mean,

471
00:25:42.041 --> 00:25:44.740
I have no business if it weren't for this. I think,

472
00:25:45.040 --> 00:25:48.010
I think the difficulties are what, what are,

473
00:25:48.030 --> 00:25:51.040
what are the standards that are applied? And I also like,

474
00:25:51.070 --> 00:25:54.160
I don't want to sound like one of these free market right-wingers,

475
00:25:54.161 --> 00:25:58.720
but what's the legal bit. You would have to first establish a legal basis.

476
00:25:58.721 --> 00:26:00.820
You would have to establish law that says,

477
00:26:01.120 --> 00:26:04.540
once you have this number of users or this number of page views or whatever,

478
00:26:04.780 --> 00:26:09.070
you now are bound by this new set of, of laws.

479
00:26:09.100 --> 00:26:11.980
And that is complex to say the least it's very.

480
00:26:11.980 --> 00:26:15.790
<v 0>Complex. It's very complex. And I don't, I don't, I have no idea how it would,</v>

481
00:26:15.791 --> 00:26:20.170
one would even begin and how long the process of figuring out what the rules

482
00:26:20.171 --> 00:26:24.280
should be, how long it would take before we all agreed on that. But I, and I,

483
00:26:24.281 --> 00:26:28.660
and I think that would be another great argument for the ability to express

484
00:26:28.661 --> 00:26:31.870
yourself because informing these laws,

485
00:26:32.020 --> 00:26:34.180
we would want to hear all perspectives,

486
00:26:34.480 --> 00:26:38.590
perspectives from people that have been harmed by social media and you know,

487
00:26:38.591 --> 00:26:42.040
and Twitter mobs and like that. And what should be done about that?

488
00:26:42.250 --> 00:26:45.330
And the same could be said about YouTube as well. I think,

489
00:26:45.720 --> 00:26:50.100
but one thing that no one can deny is how significant these,

490
00:26:50.700 --> 00:26:54.300
these tools are, whether it's Twitter or YouTube or, you know,

491
00:26:54.301 --> 00:26:57.360
any new one that comes out, whether it's tick-tock or whatever, they're,

492
00:26:57.540 --> 00:27:00.510
they're really powerful. There's, there's something to them.

493
00:27:00.511 --> 00:27:04.410
That's unprecedented in the history of humanity, you know,

494
00:27:04.411 --> 00:27:08.700
and we can't just apply the old rules to them. Just doesn't make sense.

495
00:27:08.730 --> 00:27:10.530
I don't think it's good for us. What,

496
00:27:10.950 --> 00:27:15.720
when I have talked to conservative people about this, there,

497
00:27:15.890 --> 00:27:17.670
if you're not accustomed to it,

498
00:27:17.700 --> 00:27:21.420
if you're not accustomed to feeling like you're censored and you're angry,

499
00:27:21.630 --> 00:27:24.630
you don't know what it's like until you're around these people. And then you,

500
00:27:24.631 --> 00:27:29.260
you see their frustration and their anger and their, their fury at Twitter for,

501
00:27:29.310 --> 00:27:30.660
for doing that. And for,

502
00:27:30.870 --> 00:27:34.140
for censoring voices that are similar to their perspectives,

503
00:27:34.320 --> 00:27:37.800
instead of just letting the process take place, like it's always has been,

504
00:27:37.950 --> 00:27:41.700
it's just in a different form. The process of being able to talk through ideas.

505
00:27:42.380 --> 00:27:42.590
One.

506
00:27:42.590 --> 00:27:47.570
<v 1>Of the risks of this is that once you assert a right to</v>

507
00:27:47.930 --> 00:27:52.490
a platform to exist on a platform that supersedes Twitter or

508
00:27:52.491 --> 00:27:55.430
YouTube, his ability to say for whatever reason,

509
00:27:55.431 --> 00:27:57.980
because they're a company that can have terms and conditions and they say,

510
00:27:57.981 --> 00:27:59.240
we just don't want this. If,

511
00:27:59.360 --> 00:28:04.190
if YouTube was determined that they don't want gardening content on YouTube,

512
00:28:04.730 --> 00:28:09.110
I can't think of a legal reason why they can't say no gardening content. I mean,

513
00:28:09.330 --> 00:28:13.250
as long as they're not by virtue of banning gardening content, you know,

514
00:28:13.280 --> 00:28:17.120
banning people on the basis of membership in some protected class or something

515
00:28:17.121 --> 00:28:21.230
like that, right? Like if you are, if all gardeners were of a certain race,

516
00:28:21.560 --> 00:28:24.950
you could make the case that by proxy, by banning gardening content,

517
00:28:24.951 --> 00:28:27.020
they're banning people of a certain race. I don't.

518
00:28:27.020 --> 00:28:28.850
<v 2>Know how you.</v>

519
00:28:29.540 --> 00:28:32.390
<v 1>Prevent that from then being applied elsewhere.</v>

520
00:28:32.391 --> 00:28:35.570
Like what other platforms would people have a right to?

521
00:28:35.571 --> 00:28:40.520
And this gets to speakers who say I was censored because a certain

522
00:28:40.521 --> 00:28:43.250
school wouldn't have me to speak there. It's like, well, hold on,

523
00:28:43.670 --> 00:28:46.610
you don't have a right to speak at any particular schools.

524
00:28:46.611 --> 00:28:50.840
Schools can make decisions about what they want and what they don't want.

525
00:28:50.841 --> 00:28:53.870
As long as you're not being discriminated against, based on your identity.

526
00:28:54.320 --> 00:28:57.200
Is it not sort of the same thing with YouTube? Like what,

527
00:28:57.320 --> 00:29:01.070
what is the legal basis for saying they can no longer make these decisions?

528
00:29:01.130 --> 00:29:01.430
Well.

529
00:29:01.430 --> 00:29:03.470
<v 0>It's a big, there's a big difference. First of all,</v>

530
00:29:03.471 --> 00:29:06.830
a school is a single destination. That's a physical place, right?

531
00:29:06.831 --> 00:29:09.380
So you can decide, you know, this is a conservative school.

532
00:29:09.381 --> 00:29:11.870
We don't want people coming over here and talking about this,

533
00:29:11.871 --> 00:29:14.480
or this is a very progressive school.

534
00:29:14.690 --> 00:29:16.940
We don't want to have someone from the KKK,

535
00:29:16.941 --> 00:29:19.160
come here and tell us how all races are not equal.

536
00:29:19.450 --> 00:29:21.560
That's a very different thing. When you're,

537
00:29:21.920 --> 00:29:24.530
when you're doing something like YouTube, the real question is,

538
00:29:25.400 --> 00:29:28.280
is it just a business? Is it just a business it's owned by people?

539
00:29:28.281 --> 00:29:32.700
And they have the right to do whatever they want or is at least, I mean, well,

540
00:29:32.701 --> 00:29:35.660
you know, you're on YouTube, you're, you're called a partner, right.

541
00:29:35.750 --> 00:29:39.290
They refer to you as a partner. David PackMan is a YouTube partner. Right.

542
00:29:39.291 --> 00:29:42.790
But you, you know, and in some ways you are right,

543
00:29:42.970 --> 00:29:45.070
cause you put out a lot of content. You're huge.

544
00:29:45.460 --> 00:29:49.810
You can put out a lot of content and that content is an integral part of like,

545
00:29:49.811 --> 00:29:51.580
look, they have a, uh,

546
00:29:51.610 --> 00:29:55.330
progressive news sort of empire,

547
00:29:55.450 --> 00:29:59.890
really when you really stop and look about and homemade shows like yours,

548
00:30:00.760 --> 00:30:02.740
um, you know, like, uh, there's, there's many,

549
00:30:02.741 --> 00:30:05.860
many of them that you could watch, uh, Kyle Kalinsky, um,

550
00:30:05.890 --> 00:30:09.610
and Jimmy Dore and all these folks are doing these shows, uh,

551
00:30:09.700 --> 00:30:12.010
basically from scratch, right?

552
00:30:12.011 --> 00:30:16.120
There's no large production company behind it or any of the things that,

553
00:30:16.240 --> 00:30:20.050
so they've, they've, they've got this whole empire of,

554
00:30:20.260 --> 00:30:23.350
you're a part of it. You're part of this whole news empire,

555
00:30:23.440 --> 00:30:25.450
and there's many categories, but

556
00:30:27.340 --> 00:30:31.210
what they are is not as simple as just a business,

557
00:30:31.300 --> 00:30:32.470
they are a business,

558
00:30:32.740 --> 00:30:36.910
but what they all are as well with all the executives,

559
00:30:36.911 --> 00:30:40.930
all the people that YouTube as an entity is one of the most powerful tools for

560
00:30:40.931 --> 00:30:43.600
expression the world's ever known.

561
00:30:43.840 --> 00:30:47.260
So if you have this incredibly powerful tool for expression,

562
00:30:48.460 --> 00:30:52.170
at what point in time, when you, when you able to deny people,

563
00:30:52.270 --> 00:30:57.100
the use of that thing and why, and what is freedom of expression,

564
00:30:57.101 --> 00:31:00.700
if it doesn't apply to these new tools, what is the first amendment?

565
00:31:00.730 --> 00:31:03.520
If it doesn't apply to these new tools, if someone can come along and say, Hey,

566
00:31:03.670 --> 00:31:06.550
I know you're a doctor and a practicing physician, but I'm 28.

567
00:31:06.551 --> 00:31:08.470
And I live in Palo Alto and I say, you,

568
00:31:08.471 --> 00:31:10.810
because I believe in the WHL and I don't believe in you,

569
00:31:10.990 --> 00:31:12.400
and I'm just going to delete your video.

570
00:31:12.401 --> 00:31:16.510
And it seems to me that I followed the rules that YouTube has set forth about.

571
00:31:16.720 --> 00:31:18.880
Uh, you know, if you don't agree with the who,

572
00:31:18.881 --> 00:31:22.600
and you're giving some sort of contrary coronavirus information deli,

573
00:31:23.080 --> 00:31:26.440
and I don't, I don't think that's wise. I don't think that's wise.

574
00:31:26.441 --> 00:31:27.370
I think this is a very,

575
00:31:27.371 --> 00:31:32.140
very complicated issue that should be debated publicly and discuss publicly

576
00:31:32.141 --> 00:31:35.380
whether or not these people have the right to be heard.

577
00:31:35.590 --> 00:31:37.750
And this is just one example that we keep bringing up,

578
00:31:37.751 --> 00:31:41.560
but there's many different kinds of things that fit along those lines. You know,

579
00:31:41.561 --> 00:31:46.420
when you just want to ban all conspiracy theories, air quotes,

580
00:31:46.660 --> 00:31:49.060
the problem with conspiracy theories is first of all,

581
00:31:49.061 --> 00:31:53.260
the word as a pejorative was created to try to steer people away from the

582
00:31:53.261 --> 00:31:54.370
Kennedy assassination,

583
00:31:54.400 --> 00:31:58.150
which is like one of the greatest conspiracies of all time. Some,

584
00:31:58.630 --> 00:32:02.170
some people did that, whether it was Lee Harvey Oswald by himself.

585
00:32:02.770 --> 00:32:05.350
I highly doubt it. I think there's probably other people involved.

586
00:32:05.351 --> 00:32:07.060
I think it was a conspiracy so called.

587
00:32:07.960 --> 00:32:10.510
<v 1>Conspiracy. And I know too much about it. I know too much.</v>

588
00:32:10.510 --> 00:32:14.500
<v 0>About it. We could spend the rest of the day discussing that and let's not. But.</v>

589
00:32:15.330 --> 00:32:16.320
<v 1>The first amendment though,</v>

590
00:32:16.321 --> 00:32:18.930
I don't think the first amendment is in play here because you're not talking

591
00:32:18.931 --> 00:32:20.610
about the government. When you talk about YouTube.

592
00:32:20.910 --> 00:32:23.610
<v 0>I think we should revise the first amendment. This is what I'm saying.</v>

593
00:32:23.820 --> 00:32:26.820
I think freedom of expression used to be you.

594
00:32:26.821 --> 00:32:29.280
I can't infringe upon your right to express yourself,

595
00:32:29.370 --> 00:32:33.330
but that was like yelling on a apple box. You know, like w when,

596
00:32:33.331 --> 00:32:34.230
when that was created,

597
00:32:34.500 --> 00:32:37.320
the really other than writing something in print or yelling,

598
00:32:37.321 --> 00:32:41.870
something in a public square, the weren't a lot of ways to express yourself.

599
00:32:42.080 --> 00:32:42.680
Now,

600
00:32:42.680 --> 00:32:47.240
the most powerful way the world has ever known has come along to express

601
00:32:47.241 --> 00:32:50.360
yourself. And that's social media, that's YouTube and Twitter.

602
00:32:50.630 --> 00:32:55.400
And what are those things and how much of a responsibility do the

603
00:32:55.401 --> 00:33:00.320
people who own those things have to adhere to the fundamental ideas that

604
00:33:00.321 --> 00:33:02.420
got us to this Republic in the first place.

605
00:33:02.750 --> 00:33:07.160
And I think there's a real good argument that they're more powerful than simply

606
00:33:07.161 --> 00:33:11.600
just a company that they have this amazing ability to get information out.

607
00:33:11.990 --> 00:33:13.910
And that this is, I mean,

608
00:33:13.970 --> 00:33:17.660
it should certainly be profitable and I don't deny them their profitability.

609
00:33:18.050 --> 00:33:19.460
I mean, they've made an amazing thing.

610
00:33:19.461 --> 00:33:21.230
They've created something that we all benefit from.

611
00:33:21.231 --> 00:33:22.310
They should make a load of money,

612
00:33:22.670 --> 00:33:27.590
but I think we should really be careful about who gets to use this and

613
00:33:27.591 --> 00:33:30.740
who doesn't get to use this just because someone says something that you

614
00:33:30.741 --> 00:33:33.320
disagree with it get other people to also agree with them.

615
00:33:33.680 --> 00:33:38.030
Doesn't mean they should be shut down if you don't agree with what they're

616
00:33:38.031 --> 00:33:39.320
saying, if you don't like what they're saying,

617
00:33:39.321 --> 00:33:43.160
you probably shouldn't view it or listen to it or read it.

618
00:33:43.370 --> 00:33:48.170
You should probably find something else too, or examine why you don't like it.

619
00:33:48.171 --> 00:33:49.400
And this is where thinking comes in.

620
00:33:49.401 --> 00:33:51.680
This is where critical thinking and discussion comes in.

621
00:33:51.830 --> 00:33:56.360
And this is a huge part of managing a community of managing a

622
00:33:56.361 --> 00:34:00.860
civilization. So the, one of the biggest parts of managing this civilization,

623
00:34:00.920 --> 00:34:05.690
this kind of discourse is limited and it's limited in censored and people can

624
00:34:05.691 --> 00:34:08.330
arbitrarily decide to just remove you from.

