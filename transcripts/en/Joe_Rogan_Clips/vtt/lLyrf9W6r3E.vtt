WEBVTT

1
00:00:00.980 --> 00:00:04.520
<v 0>The Joe Rogan experience. People think about overpopulation.</v>

2
00:00:04.580 --> 00:00:09.480
One things that you should take into consideration is that as populations, uh,

3
00:00:09.960 --> 00:00:14.280
increase in places urbanize, the actual birth rate goes down. That's right.

4
00:00:14.340 --> 00:00:15.840
To the point where places like Japan,

5
00:00:15.841 --> 00:00:18.320
there's actually a concern that they're not having enough children.

6
00:00:18.760 --> 00:00:19.030
That's right.

7
00:00:19.030 --> 00:00:22.070
<v 1>Yeah. And of course it is driven by prosperity. Yes. And, you know,</v>

8
00:00:22.071 --> 00:00:24.470
female education and emancipation and so on. Mm-hmm &lt;affirmative&gt;. Yes.

9
00:00:24.471 --> 00:00:27.190
So at this point, if you look at the largest countries in the world,

10
00:00:27.191 --> 00:00:32.150
the largest dozen countries in the world, the only one that has a really high,

11
00:00:32.870 --> 00:00:35.550
um, fertil fraternity rate still is Nigeria. You know,

12
00:00:35.570 --> 00:00:39.390
if you exclude Subha in Africa, it's basically a completely solved problem.

13
00:00:40.410 --> 00:00:41.200
Really?

14
00:00:41.200 --> 00:00:43.260
<v 0>Mm-hmm &lt;affirmative&gt; Nigeria is the only one. Yeah.</v>

15
00:00:43.261 --> 00:00:44.460
If you look at the big countries.

16
00:00:44.460 --> 00:00:47.540
<v 1>You would not expect like Bangladesh or Pakistan or India, you know,</v>

17
00:00:47.600 --> 00:00:50.820
the fratern rate is down below three now. Really? Yeah.

18
00:00:51.360 --> 00:00:52.193
<v 0>That's interesting.</v>

19
00:00:52.200 --> 00:00:55.180
So their population will level out over the next few decades.

20
00:00:55.450 --> 00:00:58.500
<v 1>Well, it has, yeah. It's getting people. I mean, it's still declining, you know,</v>

21
00:00:58.501 --> 00:01:01.460
it plummeting, you know, people often used to say that the,

22
00:01:01.630 --> 00:01:06.330
any reason why China's fertility raise low is because of the one child policy,

23
00:01:06.331 --> 00:01:10.090
which of course they have now discontinued precisely because of problems like

24
00:01:10.091 --> 00:01:11.890
this. Mm-hmm &lt;affirmative&gt;. Um, but it's not true. I mean,

25
00:01:11.891 --> 00:01:14.770
other countries were a little bit behind the one child policy did certainly

26
00:01:14.900 --> 00:01:15.930
accelerate the process.

27
00:01:16.550 --> 00:01:19.370
But if you look at Brazil or Indonesia or any of these countries,

28
00:01:19.371 --> 00:01:21.890
you'll see exactly the same phenomenon plummeting.

29
00:01:22.470 --> 00:01:26.320
<v 0>Have you thought about what the future looks like when people lived to be four</v>

30
00:01:26.321 --> 00:01:31.000
or 500 years old? Like how, first of all, how wise will people be?

31
00:01:31.001 --> 00:01:32.960
Mm-hmm &lt;affirmative&gt; that's what's really interesting cuz so.

32
00:01:33.390 --> 00:01:34.161
<v 1>Okay. So here's,</v>

33
00:01:34.161 --> 00:01:38.800
here's a really important thing that I wanna get across when we think

34
00:01:39.010 --> 00:01:43.670
about longevity. Well,

35
00:01:43.870 --> 00:01:45.750
actually three things I wanna say, first of all,

36
00:01:45.751 --> 00:01:50.430
longevity is a side effect of health. Right? Right. So, you know,

37
00:01:50.710 --> 00:01:54.510
a huge amount of the so-called debate that goes on about the desirability of all

38
00:01:54.511 --> 00:01:56.030
of this just goes away.

39
00:01:56.031 --> 00:01:58.030
When you remember that people actually quite like being healthy,

40
00:01:58.970 --> 00:02:01.870
but in terms of how the world will be, which is a question you asked,

41
00:02:01.900 --> 00:02:05.860
there's two questions here. It, one question is how will the world actually be?

42
00:02:05.920 --> 00:02:10.140
And the second question is how will people in the near term expect the world to

43
00:02:10.141 --> 00:02:12.980
be? And the reason why those two questions are,

44
00:02:13.560 --> 00:02:16.620
are important to distinguish is because the question of how the world will

45
00:02:16.820 --> 00:02:20.380
actually be, is very obviously completely unanswerable.

46
00:02:20.381 --> 00:02:24.250
Even if we look 50 years in the future. I mean, if you look 50 years ago, right?

47
00:02:24.310 --> 00:02:27.730
How much of what we have today would've been predicted, right? Yeah.

48
00:02:27.750 --> 00:02:32.210
It world completely different. And certainly internal longevity, you know,

49
00:02:32.260 --> 00:02:34.290
we're only gonna be getting older at one year per year.

50
00:02:34.640 --> 00:02:38.650
That won't actually be any 500 year old people for another 400 years. Right?

51
00:02:38.670 --> 00:02:40.690
Oh really? Well, yeah. I mean.

52
00:02:41.470 --> 00:02:43.690
<v 0>Oh no, I don't know what you're gonna be able to do.</v>

53
00:02:45.500 --> 00:02:48.000
<v 1>You, we're not gonna be able to change the PA change.</v>

54
00:02:48.100 --> 00:02:51.640
The rate of the passage of time is my point. Right?

55
00:02:52.000 --> 00:02:53.640
<v 0>I understand what you're saying. Right. But.</v>

56
00:02:54.390 --> 00:02:57.520
<v 1>Expectation is a completely different thing. And here's why that matters.</v>

57
00:02:58.230 --> 00:02:59.680
There's gonna become a point.

58
00:02:59.830 --> 00:03:02.840
There's gonna come a point where people in general,

59
00:03:03.020 --> 00:03:07.800
the general man in the street starts to realize that they're

60
00:03:08.000 --> 00:03:11.360
probably going to live an awfully long time because they're not gonna just get

61
00:03:11.640 --> 00:03:15.720
progressively sicker as they get older. And you know,

62
00:03:15.790 --> 00:03:18.160
lots of other reasons are gonna exist. Why they're gonna live a long time.

63
00:03:18.161 --> 00:03:21.390
Like I have self-driving cars that pretty much eliminate, you know,

64
00:03:21.420 --> 00:03:22.550
road accidents and so on.

65
00:03:24.410 --> 00:03:28.830
So they're going to want a lot of different things

66
00:03:29.740 --> 00:03:33.070
than what they wanted when they thought they were gonna live only slightly

67
00:03:33.071 --> 00:03:36.790
longer than their parents. They're gonna want very different pension plans,

68
00:03:36.980 --> 00:03:41.180
very different life insurance health, I very different inheritance arrangements.

69
00:03:41.640 --> 00:03:44.260
And these are huge big ticket items, right?

70
00:03:44.261 --> 00:03:46.540
They basically drive the global economy.

71
00:03:47.440 --> 00:03:51.460
So policy makers and decision makers around the world had well better be ready

72
00:03:52.200 --> 00:03:56.940
for that shift in public expectation of how long they're gonna

73
00:03:56.970 --> 00:03:58.940
live. Right? Yes.

74
00:03:59.910 --> 00:04:04.650
Now therefore it is absolutely critical to

75
00:04:06.050 --> 00:04:10.610
estimate and to communicate the estimate of how soon

76
00:04:11.440 --> 00:04:14.970
that shift in public expectation is going to occur,

77
00:04:15.860 --> 00:04:19.610
which means how well, what events have to happen,

78
00:04:19.611 --> 00:04:23.680
how much progress needs to happen in order for that in order to,

79
00:04:23.681 --> 00:04:27.840
in order to cause that shift. Now, this is where I am terrified

80
00:04:29.550 --> 00:04:32.040
because I think it's gonna happen really soon.

81
00:04:32.680 --> 00:04:36.480
I think it could easily happen in the next three to five years

82
00:04:37.660 --> 00:04:39.160
and that when it does happen,

83
00:04:39.190 --> 00:04:43.950
it's gonna happen in suddenly here's the sequence of events that I think is

84
00:04:43.951 --> 00:04:46.110
gonna happen. Step one,

85
00:04:46.640 --> 00:04:51.350
we're going to have sufficient progress in the laboratory or the clinic

86
00:04:52.700 --> 00:04:57.310
that most of my scientific colleagues are going to be

87
00:04:57.420 --> 00:05:02.180
willing to come out and say more or less. Yeah. Bri gray was right. All along.

88
00:05:02.490 --> 00:05:05.300
They're gonna say, yeah. You know, it's, you're very excited about that.

89
00:05:05.300 --> 00:05:07.500
Mm-hmm &lt;affirmative&gt; no, I'm terrified.

90
00:05:07.501 --> 00:05:10.100
And I'm gonna tell you why you're a little excited, a little excited. I mean,

91
00:05:10.180 --> 00:05:13.940
I know I have been a &lt;laugh&gt; recognition is never something that's driven me.

92
00:05:14.540 --> 00:05:18.380
Um, um, but yeah, they're gonna, they're gonna come out and say, yeah,

93
00:05:18.381 --> 00:05:21.890
it's only a matter of time before we let this aging thing now,

94
00:05:21.891 --> 00:05:24.410
what do you think is gonna happen next? You're a media guy, right?

95
00:05:24.710 --> 00:05:26.570
Here's what I think's gonna happen, but I want your,

96
00:05:26.890 --> 00:05:28.490
I wanna know whether you think I'm right. Okay.

97
00:05:28.610 --> 00:05:32.090
I think the next thing's gonna happen is that real opinion forms people like

98
00:05:32.091 --> 00:05:32.891
you, people like Oprah,

99
00:05:32.891 --> 00:05:37.530
Oprah Winfrey are going to hear that being said and written,

100
00:05:37.670 --> 00:05:41.490
you know, in the media and they're gonna say, oh,

101
00:05:42.350 --> 00:05:46.600
this is actually gonna happen. And they're gonna say so on air.

102
00:05:47.380 --> 00:05:50.080
And they're going, not only to say, say what their opinion is,

103
00:05:50.081 --> 00:05:53.760
but they're gonna say what they think people ought to do in particular.

104
00:05:53.760 --> 00:05:56.480
They're gonna say, well, look, you know, let's actually, if we're, if,

105
00:05:56.500 --> 00:05:57.720
if it's only a matter of time,

106
00:05:58.620 --> 00:06:03.320
if we're losing 110,000 people every day worldwide to this

107
00:06:03.520 --> 00:06:04.353
phenomenon,

108
00:06:04.390 --> 00:06:08.760
then we do kind of have a bit of a moral obligation to make it less time if we

109
00:06:08.770 --> 00:06:12.280
can't. So my sense is that once that happens,

110
00:06:12.780 --> 00:06:15.920
the following day, it's gonna become impossible to get elected.

111
00:06:15.921 --> 00:06:19.990
Unless you have a manifesto commitment to, you know, have a war on aging,

112
00:06:19.991 --> 00:06:21.790
you know, throw proper money at this. I mean,

113
00:06:21.910 --> 00:06:23.470
I really mean a proper war on aging,

114
00:06:23.471 --> 00:06:28.110
not just like the war on cancer was lots of money, not just to do the research,

115
00:06:28.210 --> 00:06:31.470
but also to front load all of the investment in infrastructure and you know,

116
00:06:31.630 --> 00:06:33.670
training and medical personnel and so on. Okay.

117
00:06:35.250 --> 00:06:38.780
And everyone's gonna, I know it like the world,

118
00:06:38.880 --> 00:06:40.580
the public is going to make that switch.

119
00:06:40.580 --> 00:06:42.740
I just mentioned of expectation like at once.

120
00:06:43.440 --> 00:06:46.340
So it's gonna be ridiculously sudden once it happens.

121
00:06:47.080 --> 00:06:51.740
And the first step is going to be that shift in what my

122
00:06:51.741 --> 00:06:56.180
colleagues in the biogyrontology community feel able to say

123
00:06:57.590 --> 00:07:00.690
on camera and on stage. Now,

124
00:07:00.691 --> 00:07:05.290
therefore the question is what amount of progress is gonna be

125
00:07:05.291 --> 00:07:10.050
required for that to occur? Now here's the thing. There aren't very many of us,

126
00:07:10.240 --> 00:07:11.073
it's a small field.

127
00:07:11.510 --> 00:07:14.010
The number of people at the top of the field who actually talk to the media

128
00:07:14.011 --> 00:07:17.930
quite a bit is, you know, a dozen maximum there's me, this's David that'.

129
00:07:17.931 --> 00:07:19.680
You had on the show, there's, you know,

130
00:07:19.790 --> 00:07:23.920
very few others and we all know each other. We're all good mates, right?

131
00:07:24.100 --> 00:07:27.200
So we know exactly where our heads are.

132
00:07:27.380 --> 00:07:29.680
You know what the drivers are,

133
00:07:31.220 --> 00:07:36.080
the number one reason why my colleagues don't already

134
00:07:36.180 --> 00:07:39.230
say what I say is funding.

135
00:07:40.290 --> 00:07:41.430
The fact that unlike me,

136
00:07:42.040 --> 00:07:46.990
those people are reliant for most of the money

137
00:07:47.100 --> 00:07:48.390
that drives their research

138
00:07:49.890 --> 00:07:54.430
on peer reviewed government, money, government grants.

139
00:07:55.450 --> 00:07:56.910
And they just won't get them.

140
00:07:57.450 --> 00:08:01.100
If it's possible to accuse those,

141
00:08:01.280 --> 00:08:04.420
accuse them of saying irresponsible things for the media,

142
00:08:04.720 --> 00:08:08.820
things that get people's hopes up, undoly remember,

143
00:08:08.821 --> 00:08:11.180
there's hardly there's, there's nowhere near enough money.

144
00:08:11.181 --> 00:08:15.500
There's less than 10% of the necessary money to fund research at the moment.

145
00:08:15.560 --> 00:08:20.130
So the committees that decide who gets money and who doesn't are always

146
00:08:20.200 --> 00:08:23.290
desperately scouting around for reasons to say no,

147
00:08:24.080 --> 00:08:26.970
that can be justified and saying, oh,

148
00:08:26.971 --> 00:08:31.850
this guy says irresponsible things to the media is a totally safe way to say

149
00:08:31.870 --> 00:08:34.650
no. Right? So anyway, so this is, this is the problem.

150
00:08:34.651 --> 00:08:37.570
This is why my colleagues have to be really pretty curmogenently.

151
00:08:38.040 --> 00:08:43.040
Even David David is probably the person out of my colleagues who pushes the

152
00:08:43.160 --> 00:08:47.120
envelope as much as possible out of people who have regular faculty positions.

153
00:08:48.020 --> 00:08:50.960
But, you know, he's just written a book, which I see you have on yourself.

154
00:08:50.961 --> 00:08:54.320
Mm-hmm &lt;affirmative&gt; called, you know, uh, why we age and why we don't have to,

155
00:08:55.300 --> 00:09:00.280
he could not have written that book with that title five years ago and kept his

156
00:09:00.281 --> 00:09:03.240
job. Wow. Um, so, you know,

157
00:09:03.820 --> 00:09:06.760
the question is how much has to change and actually it's not very much,

158
00:09:08.340 --> 00:09:10.000
you know, there's a balance here. There's a, there's a,

159
00:09:10.001 --> 00:09:12.840
there's a tension here between, on the one hand,

160
00:09:12.940 --> 00:09:15.310
not saying things that can be characterized as they're responsible,

161
00:09:15.570 --> 00:09:16.430
but on the other hand,

162
00:09:16.730 --> 00:09:19.870
not saying things that could be character characterized as simply untrue,

163
00:09:20.550 --> 00:09:24.110
&lt;laugh&gt; like, right. So the more progress is made in the laboratory,

164
00:09:24.410 --> 00:09:28.670
not even in the clinic, just with mice, right? In terms of actually, you know,

165
00:09:28.671 --> 00:09:29.710
rejuvenating them,

166
00:09:29.711 --> 00:09:33.190
making them live longer with treatments that were given to those mice when they

167
00:09:33.191 --> 00:09:38.020
were already in middle age, the more progress is made. Um, you know,

168
00:09:38.120 --> 00:09:42.580
the more impossible it's gonna be to carry on being pessimistic and refusing to,

169
00:09:43.620 --> 00:09:45.540
uh, to, to make timeframe predictions or anything like that.

170
00:09:45.880 --> 00:09:48.660
<v 0>So there's a, almost a forced pessimism, correct?</v>

171
00:09:48.661 --> 00:09:50.500
That's created by the establishment. Correct. Well,

172
00:09:50.501 --> 00:09:54.660
I think what you're saying makes a ton of sense in that once it does get to the

173
00:09:54.661 --> 00:09:59.410
point where this is undeniable, this is peer reviewed, proven,

174
00:10:00.360 --> 00:10:04.370
established science, and also implementable mm-hmm &lt;affirmative&gt;.

175
00:10:04.371 --> 00:10:05.650
This is something that can be

176
00:10:07.470 --> 00:10:10.170
at scale mm-hmm &lt;affirmative&gt; distributed worldwide. Yeah.

177
00:10:10.171 --> 00:10:11.570
Things are gonna get real weird. So people.

178
00:10:11.570 --> 00:10:12.011
<v 1>Are already,</v>

179
00:10:12.011 --> 00:10:16.440
people are obviously still gonna be saying it can't be done in humans. You know,

180
00:10:16.900 --> 00:10:21.560
it can't really be done, you know, until the cows come home, you know,

181
00:10:21.710 --> 00:10:25.680
just in the same ways has had happened for any other pioneering technology

182
00:10:25.681 --> 00:10:26.520
throughout history.

183
00:10:27.020 --> 00:10:31.400
But what matters is what the center of gravity of expert least

184
00:10:31.740 --> 00:10:33.080
stated expert opinion is.

185
00:10:34.380 --> 00:10:38.750
<v 0>It is a really, really polar housing subject. I mean, it,</v>

186
00:10:38.770 --> 00:10:39.870
it is funny how,

187
00:10:40.180 --> 00:10:44.670
what you're saying brings so true that academics and intellectuals have to be

188
00:10:44.830 --> 00:10:49.230
cautious about talking about even what is potentially possible,

189
00:10:49.940 --> 00:10:51.790
even though in private,

190
00:10:52.020 --> 00:10:56.550
they probably are more than aware that there's just a few steps to go

191
00:10:57.200 --> 00:11:01.540
before this stuff gets implemented. And we see really catastrophic,

192
00:11:01.580 --> 00:11:04.420
I mean really spectacular, rather changes. Yeah. And I mean.

193
00:11:04.420 --> 00:11:07.380
<v 1>I'm not saying that all of us absolutely agree on a hundred percent on</v>

194
00:11:07.381 --> 00:11:08.214
everything in the science.

195
00:11:08.610 --> 00:11:13.500
Certainly I would say that I'm slightly on the optimistic end of the spectrum of

196
00:11:13.501 --> 00:11:15.300
expert opinion. But yeah,

197
00:11:15.360 --> 00:11:18.850
my colleagues are not all that far behind me in terms of what they would say.

198
00:11:18.851 --> 00:11:19.684
The timeframes are.

199
00:11:20.240 --> 00:11:23.650
<v 0>What you're saying in terms of people discussing it in the media makes absolute</v>

200
00:11:23.651 --> 00:11:27.370
sense to me that as soon as that, that Pandora's box gets opened,

201
00:11:28.120 --> 00:11:31.690
then people are going to be looking to establish clinics everywhere. And it's,

202
00:11:31.910 --> 00:11:34.090
it could be very strange. Well.

203
00:11:34.090 --> 00:11:35.050
<v 1>Even if, even if,</v>

204
00:11:35.120 --> 00:11:39.000
even if a lot of these things are not yet available for clinical use,

205
00:11:39.150 --> 00:11:42.800
even if some of them are still at the beginning of the clinical trial process,

206
00:11:43.020 --> 00:11:46.960
and we're still maybe 10 or 15 years away from the R Mackay, you know,

207
00:11:47.070 --> 00:11:50.360
that will still be enough to trigger this pemonian. Mm.

208
00:11:50.540 --> 00:11:54.640
And that's why policy makers decision makers in every way and both in government

209
00:11:54.700 --> 00:11:58.440
and in key aspect of industry need to, I,

210
00:11:58.560 --> 00:12:01.720
I call it anticipticipate the anticipation they need to be,

211
00:12:01.870 --> 00:12:06.560
have already thought through and prepared for this change

212
00:12:06.780 --> 00:12:10.080
in public expectation of how long they're gonna live. So you.

213
00:12:10.080 --> 00:12:10.920
<v 0>Think that this, uh,</v>

214
00:12:12.020 --> 00:12:16.790
one day a will be a gigantic public issue in terms of elected

215
00:12:16.791 --> 00:12:17.710
representatives,

216
00:12:17.711 --> 00:12:21.510
that they they're gonna need to have some sort of an anti-aging policy mm-hmm.

217
00:12:21.550 --> 00:12:24.990
<v 1>&lt;Affirmative&gt; that's right. And the switch from essentially situation normal.</v>

218
00:12:25.250 --> 00:12:30.230
But this is usual to this completely new world will be ridiculously

219
00:12:30.231 --> 00:12:31.710
sudden it'll happen in a week.

220
00:12:41.580 --> 00:12:41.580
<v 2>So.</v>

