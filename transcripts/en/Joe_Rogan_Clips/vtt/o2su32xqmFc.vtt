WEBVTT

1
00:00:00.960 --> 00:00:03.990
<v 0>The Joe Rogan experience. The problem you identified though,</v>

2
00:00:04.050 --> 00:00:08.940
or just a moment ago was that, um, if people identify with their beliefs,

3
00:00:09.240 --> 00:00:11.970
that is the, the, the, the specific, um,

4
00:00:12.030 --> 00:00:16.230
say political platforms like on immigration, abortion, you know,

5
00:00:16.290 --> 00:00:19.370
civil rights, whatever. Um, those,

6
00:00:19.650 --> 00:00:23.280
those are sort of secondary to the deeper core moral values that people hold.

7
00:00:23.281 --> 00:00:27.780
I define myself as a liberal, I define myself as a conservative, Republican,

8
00:00:27.781 --> 00:00:31.770
whatever. And so when you attack one little thing here, well, you know, I,

9
00:00:31.771 --> 00:00:34.290
I agree with you on this and this and this, but you know, on the abortion thing,

10
00:00:34.291 --> 00:00:37.260
I think you're wrong. And here's why, you know, the, the impulses. Well,

11
00:00:37.290 --> 00:00:39.660
but if I give, if I gave up on that one,

12
00:00:39.690 --> 00:00:41.580
then I'm going to lose all these other ones. And then I've,

13
00:00:41.630 --> 00:00:45.390
I've given up my identity, right? So like when I used to debate creationists,

14
00:00:45.480 --> 00:00:48.580
intelligent design theorists, and so on, you know, I could tell that it,

15
00:00:48.690 --> 00:00:50.130
you know, if I give people a choice,

16
00:00:50.131 --> 00:00:54.420
like you have to choose between Jesus and Darwin for your life, you know,

17
00:00:54.450 --> 00:00:56.580
they're not picking Darwin. Okay. Because, you know,

18
00:00:56.760 --> 00:01:01.200
there's this sort of belief in their Christian dogmas about Jesus.

19
00:01:01.230 --> 00:01:04.380
That is their core being who cares about Darwin and, you know,

20
00:01:04.381 --> 00:01:08.460
whoever the scientist was. But if I say, keep Jesus, keep your whole religion.

21
00:01:08.461 --> 00:01:11.550
I don't care what you believe, but the science is really good on this.

22
00:01:11.551 --> 00:01:14.490
And here's why you should follow the facts and you don't have to give up

23
00:01:14.491 --> 00:01:18.060
anything for it. And it was like, oh, okay. I'll, I'll listen. Right? So,

24
00:01:18.080 --> 00:01:23.040
and like with more recently with climate change, um, you know, most people,

25
00:01:23.041 --> 00:01:25.860
most of us don't know much about climate science. It's a technical science,

26
00:01:25.861 --> 00:01:28.500
the models are super complex. People send me these papers.

27
00:01:28.501 --> 00:01:32.710
I don't really understand them, you know, but, but if you self identify, say,

28
00:01:32.711 --> 00:01:33.810
as a conservative,

29
00:01:34.380 --> 00:01:38.100
then climate change is just a proxy for something else.

30
00:01:38.101 --> 00:01:42.960
Like I believe in free markets and free enterprise and I'm pro

31
00:01:42.961 --> 00:01:46.470
business and those guys over there, you know,

32
00:01:46.471 --> 00:01:49.890
they want to attack that now. Unfortunately,

33
00:01:50.100 --> 00:01:54.090
Al gore his success with his film and books and so forth, um,

34
00:01:54.180 --> 00:01:58.440
then affiliated climate science with a left wing liberal cause

35
00:01:58.830 --> 00:02:01.300
therefore conservatives have to go against it,

36
00:02:01.710 --> 00:02:05.750
even though neither side knows all that much about climate science it's becomes

37
00:02:05.751 --> 00:02:08.160
something else that you identify yourself as.

38
00:02:08.161 --> 00:02:10.770
So we have to take that out of the formula.

39
00:02:10.771 --> 00:02:14.520
Like you keep your worldview that you define yourself as don't give up that,

40
00:02:14.521 --> 00:02:17.970
but just follow the facts on these specific issues. Yeah.

41
00:02:18.030 --> 00:02:21.300
<v 1>The polarization is the thing it's right.</v>

42
00:02:21.840 --> 00:02:23.820
If you are on one side,

43
00:02:23.821 --> 00:02:27.870
you have to subscribe to the whole menu of ideas. And if you like,

44
00:02:27.871 --> 00:02:32.070
if you're left wing, you can't really be pro-life. You know, and if you're,

45
00:02:32.160 --> 00:02:33.680
if you're right wing, you,

46
00:02:33.681 --> 00:02:36.160
you're supposed to have some certain amount of skepticism about.

47
00:02:36.270 --> 00:02:37.800
<v 0>Climate change, right?</v>

48
00:02:38.430 --> 00:02:42.450
So when somebody publicly signals where they stand on,

49
00:02:42.451 --> 00:02:46.350
say climate change, um, well, what they're really saying is look, I'm,

50
00:02:46.590 --> 00:02:50.580
I am publicly declaring my commitment to my team. Yes.

51
00:02:51.450 --> 00:02:53.700
<v 1>Yes. That's an it problem. Right? That's a problem.</v>

52
00:02:53.701 --> 00:02:56.940
The virtue signaling the comp the, the, the, the,

53
00:02:56.950 --> 00:03:01.840
these saying I have loyalty to this position because of this is my

54
00:03:01.841 --> 00:03:02.674
tribe.

55
00:03:03.900 --> 00:03:04.790
<v 0>That's right. And,</v>

56
00:03:04.791 --> 00:03:09.670
and so a lot of cognitive science studies of reasoning shows

57
00:03:09.671 --> 00:03:13.120
that we, we generally, don't reason toward finding the truth,

58
00:03:13.121 --> 00:03:17.800
but defending positions that are part of our team

59
00:03:17.860 --> 00:03:21.160
ideology, or sort of collective whole, and in this case,

60
00:03:21.161 --> 00:03:22.990
we've been talking about left and right. But, you know, there's,

61
00:03:23.020 --> 00:03:26.260
there's religious idea or economic ideologies and so on, that are part of that.

62
00:03:26.740 --> 00:03:29.720
And so even if you don't know anything about it, it's a virtue signal that I'm,

63
00:03:29.721 --> 00:03:33.970
I'm in that team and, you know, okay, fine. We're all on teams. That's,

64
00:03:34.000 --> 00:03:35.170
that's fine. Defend your team.

65
00:03:35.200 --> 00:03:39.730
But what I try to do in the book is disentangle the specific

66
00:03:39.760 --> 00:03:41.680
issues. Let's just take them one by one. Like,

67
00:03:41.710 --> 00:03:46.510
why can't I be personally against abortion? I don't want to do that, but I, I,

68
00:03:46.511 --> 00:03:50.530
and I recognize say, Ben Shapiro's arguments for the rights of the fetus,

69
00:03:50.531 --> 00:03:54.010
but I also think we have conflicting moral values there,

70
00:03:54.160 --> 00:03:58.780
the rights of a woman and, and the history of the way women have been treated.

71
00:03:58.780 --> 00:04:00.220
And men have always tried to Lord it,

72
00:04:00.221 --> 00:04:02.950
order over women's reproductive choices historically.

73
00:04:02.951 --> 00:04:06.610
And this has always led to bad things like infanticide and, uh,

74
00:04:06.640 --> 00:04:10.690
back alley abortions and so on. So I got an air on one side or the other,

75
00:04:10.960 --> 00:04:11.390
you know, I,

76
00:04:11.390 --> 00:04:15.550
I recognize and acknowledge your arguments are really good Ben or whoever is a

77
00:04:15.551 --> 00:04:17.890
pro-lifer, but I still hold this position.

78
00:04:17.891 --> 00:04:22.690
I think there's a lot of progress that can be made socially to

79
00:04:22.691 --> 00:04:26.170
kind of reduce the tension. When you say, I acknowledge your position,

80
00:04:26.200 --> 00:04:28.600
I understand it. You know, steel man in the argument.

81
00:04:28.990 --> 00:04:31.480
And then the person on the other side feels like, well,

82
00:04:31.481 --> 00:04:32.770
at least this guy is listening to me.

83
00:04:32.800 --> 00:04:34.480
<v 1>Yeah. Well, I think that's a,</v>

84
00:04:34.500 --> 00:04:38.530
that is the best topic when it comes to that,

85
00:04:38.770 --> 00:04:43.720
because it's when you get to particularly, we get to late term abortions. Boy,

86
00:04:43.750 --> 00:04:47.770
that's a very hard thing to defend morally and ethically.

87
00:04:48.280 --> 00:04:52.510
And it's also one of the things about the abortion topic is that it's so

88
00:04:52.511 --> 00:04:57.160
uniquely human in that it's such a messy topic.

89
00:04:57.161 --> 00:05:01.540
It's not, there's not like here's a clear one, don't murder people, right.

90
00:05:01.570 --> 00:05:04.570
Don't just go up to people and murder and everyone's like, yeah, yeah.

91
00:05:04.600 --> 00:05:07.930
That's clean. That's, that's a, that's a clean subject.

92
00:05:08.380 --> 00:05:11.830
Abortion is not that clean. Like when is it? Okay?

93
00:05:11.831 --> 00:05:16.150
Is it okay when the fetus is not a fetus, when it's just a bundle of cells?

94
00:05:16.420 --> 00:05:20.230
Most people like, yeah. Well, it's not even, it's not really anything then.

95
00:05:20.620 --> 00:05:24.550
Well, it will become a person though. When, when do we decide, well,

96
00:05:24.551 --> 00:05:28.360
that's such a messy subject and it's such a human subject.

97
00:05:28.600 --> 00:05:33.040
And I like you. Uh, I am on the side of pro-choice.

98
00:05:33.041 --> 00:05:37.810
And I think that it is the woman's choice to decide whether or not she wants to

99
00:05:37.811 --> 00:05:41.770
keep the baby. But I also recognize that a certain point in time,

100
00:05:41.771 --> 00:05:43.420
that choice becomes very different.

101
00:05:43.720 --> 00:05:46.660
The choice becomes very different when it's a six month old fetus, like,

102
00:05:46.661 --> 00:05:49.600
what is, what are we saying there? If you, if you are just,

103
00:05:49.750 --> 00:05:52.690
I am pro choice period. Okay.

104
00:05:52.930 --> 00:05:57.380
Are you pro choice up until the day of birth? Like when do you back it off?

105
00:05:57.381 --> 00:05:58.770
When do you back it off? And it,

106
00:05:58.920 --> 00:06:03.080
it is a subject that people do not want to breach. They don't want to touch it.

107
00:06:03.380 --> 00:06:05.300
And, um, particular,

108
00:06:05.360 --> 00:06:08.270
particularly people on the left when it comes to deciding when it's okay.

109
00:06:08.271 --> 00:06:09.140
And when it's not okay,

110
00:06:09.350 --> 00:06:13.880
because they feel like this is angling towards an elimination of a woman's right

111
00:06:13.881 --> 00:06:16.100
to choose. And it angles towards this.

112
00:06:16.910 --> 00:06:19.490
It's very difficult conversation where you,

113
00:06:19.491 --> 00:06:23.750
you recognize that there is a difference between someone who's seven months

114
00:06:23.751 --> 00:06:27.050
pregnant and someone who's seven days pregnant. There's a very,

115
00:06:27.051 --> 00:06:31.400
very big difference. And if we can't acknowledge that, then we're being tribal.

116
00:06:31.430 --> 00:06:35.450
We're being ideologically driven where we're sticking to our position,

117
00:06:35.451 --> 00:06:40.130
because we feel like if we concede that this is a complex

118
00:06:40.131 --> 00:06:44.120
issue, then we open up the door to possibly losing a woman's right.

119
00:06:44.121 --> 00:06:46.370
To choose and losing these reproductive rights.

120
00:06:47.600 --> 00:06:50.840
<v 0>Yeah. I think part of the problem also is that we tend to dichotomize.</v>

121
00:06:50.870 --> 00:06:53.750
Most moral issues is right or wrong, good or evil.

122
00:06:54.350 --> 00:06:59.030
And [inaudible] the problem is that the law has to draw the line somewhere.

123
00:06:59.031 --> 00:07:02.030
We have to have a law and to get along and so forth.

124
00:07:02.031 --> 00:07:05.450
So we have to say the drinking age is this. Instead of that,

125
00:07:05.451 --> 00:07:07.370
or driving age is this.

126
00:07:07.371 --> 00:07:11.510
And the point at which you're going to have abortion is right here. But most,

127
00:07:11.690 --> 00:07:15.530
most of life is much more on a spectrum, a continuum. So I, here,

128
00:07:15.531 --> 00:07:18.770
I make the distinction in the book between binary thinking and continuous

129
00:07:18.771 --> 00:07:23.390
thinking, most moral issues are on a continuum. You know, like immigration, uh,

130
00:07:23.400 --> 00:07:27.290
you know, it's like we closed the borders. What don't let anybody in ever. No,

131
00:07:27.291 --> 00:07:31.070
no, no. We gotta let send, man. Okay. Then we should open the borders.

132
00:07:31.190 --> 00:07:34.430
You mean you want to just open the borders up and let everybody in? No, no, no.

133
00:07:34.431 --> 00:07:37.190
I'm not saying everybody. Okay. Where do you draw the line? Right.

134
00:07:37.670 --> 00:07:38.690
And it's another.

135
00:07:38.690 --> 00:07:40.160
<v 1>Messy human subject.</v>

136
00:07:40.430 --> 00:07:42.860
<v 0>Yeah. Yeah. But, but if you think of it like, well,</v>

137
00:07:42.861 --> 00:07:46.670
it's a continuum instead of a binary choice and, you know, whatever answer,

138
00:07:46.671 --> 00:07:48.680
it's not just right or wrong, good or evil,

139
00:07:48.681 --> 00:07:53.120
that there's different places to set the, uh, the, the dial.

140
00:07:53.121 --> 00:07:53.900
So some,

141
00:07:53.900 --> 00:07:57.530
and here the comparative method of looking at what different countries do as

142
00:07:57.531 --> 00:08:01.370
experiments, thinking of those as experiments like the, you know,

143
00:08:01.371 --> 00:08:05.240
Japan has a very tight, you know, they they've slid it way down here.

144
00:08:05.241 --> 00:08:08.780
They let almost nobody in Australia is a little looser, but, but,

145
00:08:08.900 --> 00:08:10.280
but tighter than us and so on.

146
00:08:10.490 --> 00:08:14.060
And you kind of look at the consequences of letting this many people in or that

147
00:08:14.061 --> 00:08:17.090
many people and see what it does. Of course, all countries are different.

148
00:08:17.091 --> 00:08:20.300
Some are more diverse, some are more homogeneous. You have to account for that.

149
00:08:20.690 --> 00:08:22.700
And on and on. So here, I think, you know,

150
00:08:22.701 --> 00:08:26.480
instead of thinking of it in these kind of polarized black and white, you know,

151
00:08:26.900 --> 00:08:29.300
that it's either this or that. And if you're on this side,

152
00:08:29.301 --> 00:08:32.600
then you're on the bad side, you know, that that's not helpful.

153
00:08:32.630 --> 00:08:35.510
So instead of binary thinking, continuous thinking abortion,

154
00:08:35.570 --> 00:08:40.280
certainly you just articulated it perfectly. I mean, seven days of come on,

155
00:08:40.310 --> 00:08:44.120
you know, it's just a bundle of cells, but now it looks like, you know,

156
00:08:44.121 --> 00:08:48.860
by 20 weeks or so feel pain. You know, the, some consciousness comes online,

157
00:08:48.861 --> 00:08:51.560
you know, around 24 weeks, 25 weeks, you know,

158
00:08:51.620 --> 00:08:55.650
at some point you gotta draw the line somewhere around there. Now, scientists,

159
00:08:55.651 --> 00:08:58.740
of course they don't want to put lines anywhere. It's a, it's a day by day,

160
00:08:58.770 --> 00:09:01.320
week by week, day by day, even hour by hour.

161
00:09:01.321 --> 00:09:05.010
If the development of the connectome that creates thought and so on,

162
00:09:05.340 --> 00:09:08.100
there's no good place, but we have to have a line somewhere.

163
00:09:08.250 --> 00:09:12.150
So the law has to do that, but that then forces us into that binary thinking,

164
00:09:12.151 --> 00:09:12.984
which is not helpful.

165
00:09:13.370 --> 00:09:17.640
<v 1>And it, it creates this. This is like the line in the sand,</v>

166
00:09:17.641 --> 00:09:20.760
this polarization line between these two sides.

167
00:09:20.761 --> 00:09:25.590
And I think that so much of what people subscribe to when they

168
00:09:25.591 --> 00:09:29.820
do choose an ideology, once they choose an ideology,

169
00:09:29.821 --> 00:09:34.800
they S they have this conglomeration of ideas that they adopt and they

170
00:09:34.801 --> 00:09:37.770
adopt in order to be accepted by the tribe. And it's,

171
00:09:38.040 --> 00:09:42.330
this is also a very unique aspect of human communication and civilization that

172
00:09:42.570 --> 00:09:47.310
we, we have to adhere to the principles and the ideologies of that tribe.

173
00:09:47.580 --> 00:09:49.470
So you just take on all these thoughts,

174
00:09:49.890 --> 00:09:54.150
and it's one of the real problems with only having two choices in this country

175
00:09:54.160 --> 00:09:58.170
when it comes to politics and when it comes to just styles of life, you know,

176
00:09:58.350 --> 00:10:02.490
and there's so many people that take great relish in switching teams too,

177
00:10:02.640 --> 00:10:05.760
which is interesting, right? It's like I was a liberal my whole life.

178
00:10:05.760 --> 00:10:09.780
And then one day I woke up and realized I was being a moron, you know,

179
00:10:09.781 --> 00:10:14.490
and now I'm a pro second amendment pro Trump Maga make America

180
00:10:14.520 --> 00:10:15.900
great. Keep America great.

181
00:10:16.050 --> 00:10:19.830
It's interesting because those are sometimes the most, uh, the,

182
00:10:19.831 --> 00:10:22.860
the most passionate supporters of the new side,

183
00:10:22.861 --> 00:10:26.820
whether they're they're newly liberal or newly conservative, or, you know,

184
00:10:26.940 --> 00:10:31.590
w some of the people that are the most interesting to talk to are people that

185
00:10:31.591 --> 00:10:36.120
used to be vegans and are now carnivore. They're just, they just eat meat.

186
00:10:36.121 --> 00:10:40.010
And I was realizing I was being a fool and like, oh my God, it's,

187
00:10:40.200 --> 00:10:44.880
it's the same thing it's with it's with almost every style of

188
00:10:44.881 --> 00:10:48.900
living. You can find a contrary style that people find appealing. You know,

189
00:10:48.901 --> 00:10:52.350
there's people that used to be atheist to become Muslims. And they, they, they,

190
00:10:52.470 --> 00:10:56.580
they were, you know, the hijab and they, they fully adhered to the Koran.

191
00:10:56.850 --> 00:11:01.650
It's really, really interesting because I I've spent a lot of time

192
00:11:01.920 --> 00:11:06.330
watching, uh, religious scholars online, uh,

193
00:11:06.360 --> 00:11:11.040
talk and watching them preach and watch. And there's something.

194
00:11:11.610 --> 00:11:15.510
And as a person, who's very agnostic. When I watched that,

195
00:11:15.511 --> 00:11:16.830
it's appealing to me,

196
00:11:17.250 --> 00:11:20.880
there's a certain aspect of the confidence that they have when they're talking

197
00:11:20.881 --> 00:11:23.580
about what God wants or what, you know,

198
00:11:23.581 --> 00:11:28.380
what a law has in store for you when you die or what you should do,

199
00:11:28.381 --> 00:11:32.550
because it's written in this particular religious texts that confidence that

200
00:11:32.551 --> 00:11:36.780
they have when they describe these things is very alluring. Even to me,

201
00:11:36.960 --> 00:11:39.150
it's not like I'm going to join,

202
00:11:39.300 --> 00:11:43.710
but I'm sitting there in front of my computer and I'm recognizing, oh,

203
00:11:43.860 --> 00:11:48.090
I see the appeal here. Like, it's not, it's not that it's working on me,

204
00:11:48.270 --> 00:11:50.640
but it's attractive to me. I see it.

205
00:11:50.700 --> 00:11:53.290
I see how this works on people.

206
00:11:53.590 --> 00:11:57.160
And I find it incredibly fascinating. And I think it has to,

207
00:11:57.370 --> 00:12:01.570
it has to have some sort of an evolutionary reason.

208
00:12:01.720 --> 00:12:06.130
There's some sort of an evolutionary benefit that adhering and

209
00:12:06.131 --> 00:12:10.810
being accepting of the morals and the ethics and the ideology of the

210
00:12:10.811 --> 00:12:13.660
tribe is that that's how you stay alive.

211
00:12:13.900 --> 00:12:17.290
That's how you find other like-minded people that stick with you.

