WEBVTT

1
00:00:01.020 --> 00:00:02.790
<v 0>The general good experience.</v>

2
00:00:03.150 --> 00:00:06.660
<v 1>It like fundamentally, there's two ways to think about security. One is, uh,</v>

3
00:00:06.690 --> 00:00:10.140
like computer security, uh, this idea that we'll somehow make computers secure,

4
00:00:10.590 --> 00:00:13.350
we'll put information on the computers and then we'll prevent other people from

5
00:00:13.351 --> 00:00:15.030
accessing those computers.

6
00:00:15.060 --> 00:00:18.900
And that is like a losing strategy that people have been losing for 30 years.

7
00:00:18.930 --> 00:00:19.770
You know, uh,

8
00:00:19.771 --> 00:00:23.100
you information ends up on a computer somewhere and it ends up compromised in

9
00:00:23.101 --> 00:00:25.620
the end. The other way to think about security is information security,

10
00:00:25.621 --> 00:00:27.270
where you secure the information itself,

11
00:00:27.300 --> 00:00:29.310
that you don't have to worry about the security of the computers.

12
00:00:29.340 --> 00:00:30.960
You could have some computers in the cloud,

13
00:00:30.961 --> 00:00:33.930
somewhere information is flowing through them and people can compromise,

14
00:00:34.170 --> 00:00:35.100
compromise those things.

15
00:00:35.101 --> 00:00:39.000
And it doesn't really matter because the information itself is encrypted. Um,

16
00:00:39.390 --> 00:00:43.680
and so, you know, things like SMS, um, you know, the I message cloud backups,

17
00:00:44.190 --> 00:00:47.460
um, uh, most other messengers, Facebook messenger, all that stuff, you know, um,

18
00:00:47.490 --> 00:00:50.160
they're relying on this computer security model, um,

19
00:00:50.790 --> 00:00:55.530
and that, uh, ends up disappointing people in the end.

20
00:00:56.480 --> 00:01:01.330
<v 0>Mm. And so you, why did you guys create it? Like what,</v>

21
00:01:01.331 --> 00:01:05.810
what was unsatisfactory about the other options that were available?

22
00:01:06.380 --> 00:01:10.250
<v 1>The way the internet works today is like insane. Uh, you know, that, uh,</v>

23
00:01:10.640 --> 00:01:12.830
you know, fundamentally, I feel like, um,

24
00:01:12.860 --> 00:01:16.280
private communication is important because I think that change happens in

25
00:01:16.281 --> 00:01:21.170
private, um, everything that is fundamentally decent today, uh,

26
00:01:21.200 --> 00:01:25.010
started out as something that was a socially unacceptable idea at the time. Uh,

27
00:01:25.040 --> 00:01:29.090
you look at things like, you know, obvious things that abolition of slavery,

28
00:01:29.120 --> 00:01:33.680
legalization of marijuana, legalization of same-sex marriage, uh, even,

29
00:01:34.340 --> 00:01:36.560
you know, constructing the declaration of independence.

30
00:01:37.040 --> 00:01:41.840
Those are all things that required a space for people to process

31
00:01:41.841 --> 00:01:46.790
ideas outside the context of everyday life. And, um,

32
00:01:48.290 --> 00:01:50.870
those spaces don't exist on the internet today.

33
00:01:50.930 --> 00:01:53.900
And I think it's kind of crazy the way the internet works today. You know,

34
00:01:54.080 --> 00:01:58.670
that like if you imagined, um, you know,

35
00:01:59.000 --> 00:02:01.820
every moment that you were talking to somebody in real life,

36
00:02:01.850 --> 00:02:03.350
there was somebody there just with a clipboard,

37
00:02:03.380 --> 00:02:07.880
a stranger taking notes about what you said that would change the character of

38
00:02:07.881 --> 00:02:11.960
your conversations. Uh, and I think that in some ways,

39
00:02:12.080 --> 00:02:17.000
like we're living through a shortage of brave or

40
00:02:17.001 --> 00:02:21.800
bold or courageous ideas in part because people don't have the space to process

41
00:02:21.801 --> 00:02:25.850
what's happening in their lives outside of the context of everyday

42
00:02:26.570 --> 00:02:27.403
interactions. You know.

43
00:02:27.770 --> 00:02:31.580
<v 0>That's a really good way to put it because you got to give people a chance to</v>

44
00:02:31.581 --> 00:02:36.320
think things through. But if you do that publicly, they're not going to,

45
00:02:36.830 --> 00:02:41.780
they're going to sort of like, like basically what you see on Twitter. You know,

46
00:02:41.810 --> 00:02:46.700
if you stray from what is considered to be

47
00:02:46.701 --> 00:02:50.330
the acceptable norm or the current ideology or whatever,

48
00:02:50.840 --> 00:02:51.441
whenever you're supposed to,

49
00:02:51.441 --> 00:02:54.680
whatever opinions you're supposed to have on a certain subject,

50
00:02:54.980 --> 00:02:57.260
you get attacked ruthlessly. So,

51
00:02:57.261 --> 00:03:02.020
so you see a lot of censorship and you also see a lot of virtue signaling where

52
00:03:02.021 --> 00:03:05.980
people sort of pretend that they espouse a certain series of ideas because

53
00:03:05.981 --> 00:03:09.310
that'll get them some, you know, some social credit.

54
00:03:10.380 --> 00:03:11.490
<v 1>Yeah, exactly.</v>

55
00:03:11.491 --> 00:03:15.780
I think that the communication in those environments is performative. You know,

56
00:03:15.781 --> 00:03:20.550
you're either performing for an angry mob. You're performing for advertisers,

57
00:03:20.551 --> 00:03:23.730
you're performing for, you know, the governments that are watching.

58
00:03:24.450 --> 00:03:29.220
And I think also the ideas that make it through are kind of

59
00:03:29.221 --> 00:03:33.710
tainted as a result, you know, that like, uh, did you watch any of the,

60
00:03:34.650 --> 00:03:37.980
like the online hearing stuff that was happening over COVID, uh, you know,

61
00:03:37.981 --> 00:03:41.460
where like, uh, city councils and stuff were having their hearings online? No,

62
00:03:41.461 --> 00:03:45.420
I did not. Uh, it was kind of interesting to me because it's like, um, you know,

63
00:03:45.421 --> 00:03:48.210
they can't meet in person, so they're doing it online. And, uh,

64
00:03:48.870 --> 00:03:51.840
that means that the public comment period was also online, you know?

65
00:03:52.110 --> 00:03:54.390
And so it used to be that like, you know, if you go to a city council meeting,

66
00:03:55.110 --> 00:03:56.580
uh, they have a period of public comment where, you know,

67
00:03:56.581 --> 00:03:59.790
people could just stand up and say, what do you think? You know? And like,

68
00:03:59.791 --> 00:04:01.890
ordinarily, it's like, Oh, you got to go to city hall. You got to like,

69
00:04:01.891 --> 00:04:04.110
wait in line, you got to sit there, you know, but then want us on zoom.

70
00:04:04.111 --> 00:04:07.290
It's just sort of like, anyone can just show up at the zoom thing, you know,

71
00:04:07.291 --> 00:04:09.510
they just dial in and then they're just like, here's what I think, you know?

72
00:04:10.080 --> 00:04:14.670
And, uh, you know, it was kind of interesting because particularly,

73
00:04:15.180 --> 00:04:18.930
uh, when a lot of the police brutality stuff was happening in Los Angeles,

74
00:04:18.931 --> 00:04:21.510
I was, I was watching those city council hearings and, you know,

75
00:04:21.511 --> 00:04:23.720
people were just like, you know, you know,

76
00:04:23.880 --> 00:04:27.420
they were just calling you and be like, you. I yield the rest of my time. you.

77
00:04:27.421 --> 00:04:31.800
You know, like it was just like a really brutal and, uh,

78
00:04:32.010 --> 00:04:35.430
not undeservedly. So, and, uh, you know,

79
00:04:35.700 --> 00:04:39.540
what was interesting to me was just watching the politicians basically,

80
00:04:39.541 --> 00:04:43.230
you know, uh, who just had to sit there and just, they were just like it,

81
00:04:43.890 --> 00:04:44.790
you know, and it was just like, you know,

82
00:04:44.791 --> 00:04:46.650
you get three minutes and then there's someone else to get it, you know,

83
00:04:46.651 --> 00:04:50.700
they're just like, okay. And now we'll hear from, you know, like since, and,

84
00:04:50.730 --> 00:04:53.400
you know, watching that, you sort of realize that it's like, um,

85
00:04:54.090 --> 00:04:55.500
to be a politician,

86
00:04:55.800 --> 00:05:00.690
you have to just sort of fundamentally not really care what people think of

87
00:05:00.691 --> 00:05:04.470
you, you know, uh, you have to fundamentally, uh,

88
00:05:04.500 --> 00:05:09.240
just be comfortable sitting, you know, and having people yell at you,

89
00:05:09.330 --> 00:05:12.060
you know, for three minutes and three minute increments for an hour or whatever,

90
00:05:12.061 --> 00:05:12.870
you know?

91
00:05:12.870 --> 00:05:16.740
And so it seems like what we've sort of done is like bred these people who were

92
00:05:16.741 --> 00:05:17.670
willing to do that, you know,

93
00:05:17.671 --> 00:05:20.160
and in some ways that's like a useful characteristic,

94
00:05:20.190 --> 00:05:23.250
but in other ways that's the characteristic of a psychopath, you know? Yes.

95
00:05:23.680 --> 00:05:25.620
And yes. And I think, you know, what we're seeing is that,

96
00:05:25.621 --> 00:05:29.760
that also extends outside of those environments to do anything

97
00:05:29.910 --> 00:05:34.890
ambitious today requires that you just are comfortable with

98
00:05:34.891 --> 00:05:38.040
that kind of, um, feedback.

99
00:05:38.190 --> 00:05:42.240
<v 0>Like Trump's tweets, if you watch, you know,</v>

100
00:05:42.241 --> 00:05:45.090
if you look at Twitter and look at any of Trump's tweets,

101
00:05:45.091 --> 00:05:49.290
when he tweets watch what people say, it's ruthless,

102
00:05:49.530 --> 00:05:53.250
they go crazy. They go so hard and I'm, so I'm assuming he doesn't read them.

103
00:05:53.550 --> 00:05:57.090
I'm assuming he just, or maybe he does. And just doesn't say anything.

104
00:05:57.410 --> 00:06:00.050
He knows he doesn't go back and forth with people at least.

105
00:06:00.370 --> 00:06:02.380
<v 1>No, but, and I'm, I think, you know,</v>

106
00:06:02.530 --> 00:06:05.020
Trump is perfectly capable of just not caring, you know,

107
00:06:05.140 --> 00:06:07.090
there's like people like, you know, grazing, it's just like, yeah, whatever,

108
00:06:07.300 --> 00:06:10.600
you know, I'm the best they don't, you know? Yeah. And like, that's, um,

109
00:06:11.590 --> 00:06:15.730
you know, that's politics, but I think, you know, the danger is when that, uh,

110
00:06:16.720 --> 00:06:19.540
you know, to do anything ambitious, you know, outside of politics or whatever,

111
00:06:19.541 --> 00:06:19.870
you know,

112
00:06:19.870 --> 00:06:23.950
requires that you're capable of just not caring what people think or whatever,

113
00:06:24.190 --> 00:06:25.630
because everything is happening in public.

114
00:06:26.110 --> 00:06:31.030
<v 0>I think you made a really good point in that change comes from</v>

115
00:06:31.060 --> 00:06:34.990
people discussing things privately, because you have to,

116
00:06:35.650 --> 00:06:38.380
it's a, you have to be able to take a chance.

117
00:06:38.410 --> 00:06:42.310
You have to be daring in and you have to be able to confide in people and you

118
00:06:42.311 --> 00:06:45.610
have to be able to say, Hey, um, this is not right.

119
00:06:45.640 --> 00:06:49.300
And we're going to do something about it. If you do that publicly,

120
00:06:49.780 --> 00:06:54.400
the powers that be that do not want change in any way, shape or form they'll,

121
00:06:54.460 --> 00:06:55.750
they'll come down on you. I mean,

122
00:06:55.751 --> 00:07:00.250
this is essentially what Edward Snowden was warning everyone about when he

123
00:07:00.251 --> 00:07:04.630
decided to go public with all this NSA information, he was saying, look, we,

124
00:07:04.960 --> 00:07:07.830
this is not what we signed up for. You.

125
00:07:08.290 --> 00:07:10.750
Someone's constantly monitoring your emails,

126
00:07:10.751 --> 00:07:12.280
constantly listening to phone calls.

127
00:07:12.281 --> 00:07:14.860
Like this is not this mass surveillance thing.

128
00:07:15.070 --> 00:07:19.420
It's very bad for just the culture of free expression,

129
00:07:19.810 --> 00:07:24.400
just our ability to have ideas and to be able to share them back and forth and

130
00:07:24.401 --> 00:07:26.140
vet them out. It's very bad.

131
00:07:26.380 --> 00:07:27.400
<v 1>Yeah. Yeah. I mean,</v>

132
00:07:27.401 --> 00:07:30.160
I think when you look at the history of that kind of surveillance,

133
00:07:30.250 --> 00:07:32.320
there are a few interesting inflection points, you know,

134
00:07:32.321 --> 00:07:36.850
like at the beginning of, um, you know, the internet, as we know it,

135
00:07:36.940 --> 00:07:38.830
and like the early to mid nineties, um,

136
00:07:38.890 --> 00:07:43.510
that were these like DOD efforts to do mass surveillance, you know, um,

137
00:07:44.020 --> 00:07:48.430
and, um, they were sort of open about what they were doing. Uh, uh,

138
00:07:48.550 --> 00:07:52.390
and you know, one of them was this program called total information awareness.

139
00:07:53.440 --> 00:07:56.800
Uh, and, uh, it was, they were trying to start this office, I think,

140
00:07:56.801 --> 00:07:59.020
called the total awareness office or something within the DOD.

141
00:07:59.380 --> 00:08:00.050
And the idea was like,

142
00:08:00.050 --> 00:08:04.180
they're just going to like collect information on all Americans and everyone's

143
00:08:04.181 --> 00:08:07.330
communication and just stock pilot into these, uh, databases.

144
00:08:07.331 --> 00:08:10.540
And then they would use that to my mind, those things for information, uh,

145
00:08:10.570 --> 00:08:13.120
it was sort of like, you know, their, their, uh,

146
00:08:13.180 --> 00:08:16.690
effort to get in on this at the beginning of the information age. Uh,

147
00:08:16.750 --> 00:08:18.640
and you know, th it was ridiculous, you know,

148
00:08:18.641 --> 00:08:20.980
it's like they called it total information awareness.

149
00:08:21.010 --> 00:08:24.190
They had a logo that was like, um, you know, the,

150
00:08:24.191 --> 00:08:27.130
the pyramid with the eye on top of it. Oh yeah, this is, this is.

151
00:08:27.250 --> 00:08:29.320
<v 0>Their logo. It's like.</v>

152
00:08:30.190 --> 00:08:32.590
<v 1>The pyramid with the eye, like casting a beam on the earth.</v>

153
00:08:32.830 --> 00:08:36.730
That bit of Latin there means knowledge is power. Oh, wow.

154
00:08:37.030 --> 00:08:39.940
And interestingly, this program was actually started by, uh,

155
00:08:39.970 --> 00:08:43.780
John Poindexter of all people who was involved in the Iran Contra and stuff,

156
00:08:43.781 --> 00:08:45.700
I think really? Yeah.

157
00:08:45.910 --> 00:08:48.820
And he like went to jail for a second and then was pardoned or something. But,

158
00:08:50.110 --> 00:08:51.580
uh, so anyway, you know.

159
00:08:52.220 --> 00:08:56.460
<v 0>Was some up, these people are in charge of anything. I know, but what's also,</v>

160
00:08:56.490 --> 00:08:56.820
I just.

161
00:08:56.820 --> 00:08:59.400
<v 1>Kind of comical, is it like, they were like, this is what we're going to do.</v>

162
00:08:59.490 --> 00:08:59.730
Like.

163
00:08:59.730 --> 00:09:01.980
<v 2>You know, crazy. This is like this, this is our.</v>

164
00:09:01.980 --> 00:09:05.790
<v 1>Plan, you know? And people were like, uh, I don't think so. You know, like,</v>

165
00:09:07.230 --> 00:09:09.120
I, this was like early mid nineties.

166
00:09:09.650 --> 00:09:11.900
<v 0>This authentication, biometric data,</v>

167
00:09:12.440 --> 00:09:17.390
face fingerprints gate, Iris, your gate.

168
00:09:18.230 --> 00:09:21.230
So they're going to identify people based on the way they walk,

169
00:09:21.380 --> 00:09:23.330
I guess your gate is that specific.

170
00:09:24.640 --> 00:09:29.000
And then automated virtual data, repositories, privacy, and security.

171
00:09:29.180 --> 00:09:32.030
This is fascinating because if you look at, I mean,

172
00:09:32.150 --> 00:09:34.850
obviously no one thought of cell phones back then.

173
00:09:34.880 --> 00:09:37.580
<v 1>Exactly. Right. This is, so this is like kind of amateurish, right.</v>

174
00:09:37.581 --> 00:09:39.470
So it's like, they're like, this is what we're going to do. You know?

175
00:09:39.740 --> 00:09:42.110
And people are like, ah, I don't think, you know, even like Congress is like,

176
00:09:42.320 --> 00:09:44.730
ah, guys, I don't think we can like approve this, you know? Uh,

177
00:09:44.731 --> 00:09:46.370
like you need a better logo, you know?

178
00:09:47.200 --> 00:09:51.080
<v 0>Yeah. For sure. But it's just this whole flow chart.</v>

179
00:09:52.010 --> 00:09:54.590
Is that what this would be? What do you, what do you call something like this?

180
00:09:55.190 --> 00:09:58.070
What is called flow chart.

181
00:09:58.280 --> 00:10:01.100
<v 1>But yeah. Sort of designed to dazzle you in approving them.</v>

182
00:10:01.310 --> 00:10:04.370
<v 0>It's like baffling to figure out what it is. Like, first of all,</v>

183
00:10:04.371 --> 00:10:07.850
what are all those little color tubes, those little ones,

184
00:10:08.150 --> 00:10:09.620
those little cylinders, data.

185
00:10:09.620 --> 00:10:11.660
<v 1>Silos. Oh, that's the universal, they're all.</v>

186
00:10:11.660 --> 00:10:14.530
<v 0>Different colors. There's purple ones. What's in the verbal data.</v>

187
00:10:14.780 --> 00:10:19.670
<v 1>Gate or gate lives. Yeah. It's all princess information, but so,</v>

188
00:10:19.671 --> 00:10:22.820
okay. So that, you know, this, this stuff all sort of got shut down. Right.

189
00:10:22.821 --> 00:10:25.460
You know, like they're like, okay, we can't do this, you know? Uh,

190
00:10:25.550 --> 00:10:26.780
and then instead,

191
00:10:26.781 --> 00:10:31.070
what ended up happening was like data naturally accumulated in different

192
00:10:31.760 --> 00:10:36.170
places, you know, that, um, you know, like back then, if you had been, you know,

193
00:10:36.171 --> 00:10:39.590
what they were trying to do is be like our proposal is that everyone carry a

194
00:10:39.591 --> 00:10:42.350
government mandated tracking device at all times. Like, what do you guys think?

195
00:10:42.380 --> 00:10:44.420
You know, it'll make us safer. You know? And people were like, no,

196
00:10:44.421 --> 00:10:45.254
I don't think so. You know,

197
00:10:45.320 --> 00:10:48.890
but instead everyone ended up just carrying cell phones at all times,

198
00:10:48.920 --> 00:10:52.040
which are tracking your location and reporting them into centralized

199
00:10:52.640 --> 00:10:56.030
repositories that government has access to, you know? And so, uh, you know,

200
00:10:56.060 --> 00:11:00.080
this, this sort of like oblique surveillance infrastructure ended up emerging.

201
00:11:00.530 --> 00:11:04.580
And that was what, you know, people sort of knew about, but didn't really know.

202
00:11:04.581 --> 00:11:08.390
And that's what, uh, Snowden, um, revealed was like, uh, you know,

203
00:11:08.720 --> 00:11:11.240
we don't have this instead. It's like all of that,

204
00:11:11.241 --> 00:11:14.330
all of those things are happening naturally. You know, you're, you know,

205
00:11:14.600 --> 00:11:15.560
Gates detection, fingerprint, you know,

206
00:11:15.561 --> 00:11:18.380
like all this stuff's happening naturally, it's ending up in these places.

207
00:11:18.381 --> 00:11:20.360
And then, you know,

208
00:11:20.630 --> 00:11:24.170
governments are just going to those places and getting the information.

209
00:11:24.980 --> 00:11:29.330
<v 0>Catch new episodes of the Joe Rogan experience for free only on Spotify,</v>

210
00:11:29.510 --> 00:11:32.840
watch back catalog J R E videos on Spotify,

211
00:11:32.990 --> 00:11:37.730
including clips easily seamlessly switch between video

212
00:11:37.820 --> 00:11:40.280
and audio experience on Spotify.

213
00:11:40.340 --> 00:11:44.630
You can listen to the JRE in the background while using other apps and can

214
00:11:44.631 --> 00:11:48.650
download episodes to save on data costs. All for free.

215
00:11:49.040 --> 00:11:51.560
Spotify is absolutely free.

216
00:11:51.770 --> 00:11:55.370
You don't have to have a premium account to watch new JRE episodes.

217
00:11:55.640 --> 00:11:59.060
You just need to search for the JRE on your Spotify app.

218
00:11:59.300 --> 00:12:04.280
Go to Spotify now to get this full episode of the Joe Rogan experience.

