WEBVTT

1
00:00:00.030 --> 00:00:04.230
<v 0>And earlier this year, we just, uh, sold to AppFolio,</v>

2
00:00:04.570 --> 00:00:08.640
which is where I am building out the product, scaling it and, uh,

3
00:00:09.120 --> 00:00:13.380
adapting the product to their client base. Got it. Mind if I ask,

4
00:00:13.381 --> 00:00:16.920
how much did you guys sell it for? Well, it's public, uh,

5
00:00:16.980 --> 00:00:21.060
for people who wanted to know mine, if I do my research and put on my video,

6
00:00:21.690 --> 00:00:24.600
I guess, I guess I can just tell you because you're going to put it on anyways.

7
00:00:25.380 --> 00:00:26.520
Uh, we, we sold for 60.

8
00:00:26.870 --> 00:00:29.210
<v 1>Okay. Before we continue this video, I just want to say,</v>

9
00:00:29.240 --> 00:00:33.950
thank you brilliant for sponsoring this video everyday brilliant publishes daily

10
00:00:33.951 --> 00:00:38.090
challenges on many STEM topics like math, science,

11
00:00:38.091 --> 00:00:39.530
and computer science.

12
00:00:39.740 --> 00:00:44.240
This site is extremely sleek and they have over 60 interactive courses,

13
00:00:44.390 --> 00:00:47.960
which makes learning these concepts ways easier because of the hands on

14
00:00:47.961 --> 00:00:52.760
approach. They also have a artificial neuro networks course, which is really,

15
00:00:52.761 --> 00:00:55.970
really well-made. And I think if you're very interested in ML,

16
00:00:56.090 --> 00:00:57.680
you should definitely check it out.

17
00:00:57.890 --> 00:01:02.090
This is a great compliment to university because you can do practice questions

18
00:01:02.091 --> 00:01:05.120
under well curated sequences of problems,

19
00:01:05.330 --> 00:01:09.620
which allows you to master to top. If you want to master, you know,

20
00:01:09.621 --> 00:01:14.600
I wish I had brilliant when I was in college because I'm more of a hands-on

21
00:01:14.601 --> 00:01:18.140
kind of guy I learned by practicing. And if I had brilliant,

22
00:01:18.141 --> 00:01:21.950
I think I would have understood these concepts a lot faster.

23
00:01:22.430 --> 00:01:24.590
So if you're interested, you can go on

24
00:01:26.600 --> 00:01:31.070
brilliant.org/joma and then the first 200 people will get 20% off. All right.

25
00:01:31.100 --> 00:01:31.933
That's it.

26
00:01:32.360 --> 00:01:35.420
<v 0>All right. We'll come back. Thank you. Thank you. Thanks for having me back.</v>

27
00:01:36.410 --> 00:01:40.130
Yeah. Thanks for coming. David LA light brother. Cool.

28
00:01:40.490 --> 00:01:42.140
I think I'm your first, uh,

29
00:01:42.170 --> 00:01:44.780
interview that came back for a second round in way am my right.

30
00:01:45.050 --> 00:01:48.350
I think you are actually. Yeah. Yeah. Interesting.

31
00:01:48.800 --> 00:01:52.070
Because you were high in demand, so I had to bring it back. Okay, cool.

32
00:01:52.100 --> 00:01:55.250
So just a little context in the previous video,

33
00:01:55.370 --> 00:01:59.480
I made an interview with you and it's mostly about how you were a quantity at

34
00:01:59.481 --> 00:02:00.314
two Sigma,

35
00:02:00.410 --> 00:02:05.390
and then that video you told me that you quit your job to do

36
00:02:05.480 --> 00:02:09.680
to co-found a startup. Is that correct? Yep. So a lot of people were wondering,

37
00:02:09.710 --> 00:02:14.240
why did you make the switch? The switch? There was a lot of small reasons, um,

38
00:02:14.340 --> 00:02:19.190
wanting to try something new, um, wanting to see what was out there for,

39
00:02:19.550 --> 00:02:22.220
uh, deep learning. I wanted to also look at cryptocurrencies.

40
00:02:22.221 --> 00:02:25.910
I want to look at biotech. Um, but in the end, uh, Elliot,

41
00:02:25.911 --> 00:02:28.700
the co-founder of dynasty, uh,

42
00:02:28.730 --> 00:02:33.380
reached out to me like a week after, uh, I said I was going to quit.

43
00:02:34.010 --> 00:02:38.060
And he was like, Hey, have you ever thought about quitting? And I was like,

44
00:02:38.480 --> 00:02:42.470
dude, I quit like one week ago. Hi, how do you, how did you, how'd you do this?

45
00:02:43.400 --> 00:02:47.450
And then, then he said like, yeah, just come out to LA and then, uh,

46
00:02:48.050 --> 00:02:52.110
see what we're doing. And then, uh, there's nothing, no harm done. Right. God,

47
00:02:52.130 --> 00:02:55.760
I, one thing led to the next and you know, here I am now. Nice. Nice.

48
00:02:55.970 --> 00:03:00.070
So between back then, when I interviewed to now.

49
00:03:00.340 --> 00:03:02.800
<v 1>Any updates on the startup is dynasty, right?</v>

50
00:03:02.910 --> 00:03:05.490
<v 0>Yeah. There was a lot, a lot, a lot, a lot happened since, uh,</v>

51
00:03:05.520 --> 00:03:10.230
since the last time we spoke, um, I joined dynasty at that time,

52
00:03:10.231 --> 00:03:14.280
we had just pivoted into, um, the,

53
00:03:15.060 --> 00:03:18.450
the AI for, for real estate, uh, business.

54
00:03:19.170 --> 00:03:24.000
And during that time, uh, we built a product found product market fit.

55
00:03:25.290 --> 00:03:28.020
Um, and earlier this year we just, uh,

56
00:03:28.050 --> 00:03:32.100
sold to AppFolio and which is where I am building out the product,

57
00:03:32.101 --> 00:03:36.600
scaling it and, uh, adapting the product to their clients.

58
00:03:37.290 --> 00:03:40.320
<v 1>Got it. Mind if I ask, how much did you guys sell it for?</v>

59
00:03:40.560 --> 00:03:44.070
<v 0>Well, it's public, uh, for people who want to, to know.</v>

60
00:03:44.340 --> 00:03:46.380
<v 1>Mind if I do my research and put on my video.</v>

61
00:03:47.130 --> 00:03:49.950
<v 0>I guess, I guess I can just tell you because you're going to put it on anyways.</v>

62
00:03:50.730 --> 00:03:52.980
Uh, w we sell for 60 million. Yeah.

63
00:03:53.340 --> 00:03:55.470
<v 1>Nice. How many co-founders are you guys?</v>

64
00:03:55.680 --> 00:04:00.630
<v 0>So dynasty was initially a different business, which did not succeed. Uh,</v>

65
00:04:00.631 --> 00:04:05.400
and that's very, that's very common for, um, a lot of startups. Uh, so we,

66
00:04:05.790 --> 00:04:10.230
at the end of the last business, everything was, we were like 10 people.

67
00:04:11.370 --> 00:04:15.900
Uh, and I joined that as like the six person. Um, and at that time,

68
00:04:16.080 --> 00:04:17.640
things were not going well. The,

69
00:04:17.641 --> 00:04:22.470
there was no product market fits and we started pivoting into the AI

70
00:04:22.740 --> 00:04:26.700
for real estate and, uh, about half the people left. Oh.

71
00:04:26.850 --> 00:04:31.770
So in terms of co-founder originally there were two co-founders and then,

72
00:04:32.220 --> 00:04:36.570
uh, this new, well for the new pivot, uh, five of us were left.

73
00:04:43.110 --> 00:04:43.560
<v 2>Yeah.</v>

74
00:04:43.560 --> 00:04:48.000
<v 1>Just a TLDR. What was the previous product and what is the product now,</v>

75
00:04:48.180 --> 00:04:49.290
just to make it more clear.

76
00:04:49.800 --> 00:04:53.160
<v 0>Um, back then we wanted to create, we wanted to securitize, uh,</v>

77
00:04:53.190 --> 00:04:56.610
real estate assets, um, basically create a,

78
00:04:56.640 --> 00:05:01.170
an exchange and then allowing people with a smaller amount of

79
00:05:01.171 --> 00:05:06.150
capital to, uh, taken, take positions in real estate assets.

80
00:05:06.270 --> 00:05:09.810
If you think about it right now, you have to buy a house. You have to have,

81
00:05:10.560 --> 00:05:12.600
you know, especially in, uh, Silicon Valley,

82
00:05:12.601 --> 00:05:16.470
you have to have like 200 K 300 K just to put it put down a,

83
00:05:16.670 --> 00:05:20.580
a deposit it's not very democratic, right. And also your,

84
00:05:20.581 --> 00:05:23.790
all your money is into this one single assets.

85
00:05:23.850 --> 00:05:27.120
That's very susceptible to, um,

86
00:05:27.660 --> 00:05:29.910
to local changes. Uh,

87
00:05:29.911 --> 00:05:33.390
so we wanted to change that it didn't really work out. Uh, we,

88
00:05:33.420 --> 00:05:36.180
at least we didn't find how to make it work. Uh,

89
00:05:36.210 --> 00:05:39.600
I'm not going to say it's a bad idea because we still think that, you know,

90
00:05:40.170 --> 00:05:44.130
there are benefits to this world we're dreaming of. Um,

91
00:05:44.460 --> 00:05:48.000
but in the process, Elliots and other, uh,

92
00:05:48.240 --> 00:05:52.950
people who joined before me found out that a lot of real estate participants

93
00:05:52.951 --> 00:05:57.800
had a lot of trouble managing their assets. So it's unlike stocks,

94
00:05:57.830 --> 00:06:00.950
real estate is a as an asset that you have to, you know,

95
00:06:00.951 --> 00:06:05.480
it's a real thing you have to keep. Yeah, there's up cave. You want to like,

96
00:06:05.481 --> 00:06:08.060
get people into it for rentals and stuff like that.

97
00:06:08.420 --> 00:06:12.020
I think half of the income comes from, uh, rentals. Right?

98
00:06:12.770 --> 00:06:15.530
If you take it, the other half has appreciation.

99
00:06:16.070 --> 00:06:20.480
So one of the big challenges was the operations of leasing

100
00:06:21.080 --> 00:06:26.000
a building or leasing, uh, your assets. So we decided, well,

101
00:06:26.060 --> 00:06:30.920
everybody says, it's a problem. So let's do something about it. Yeah. And that,

102
00:06:30.930 --> 00:06:32.480
that's where, uh, Lisa came in,

103
00:06:32.510 --> 00:06:36.200
Lisa is the second iteration of dynasty. So.

104
00:06:36.200 --> 00:06:38.540
<v 1>That's like the pivot, that's your new business. That's.</v>

105
00:06:38.540 --> 00:06:42.680
<v 0>Right. Yeah. And of course, Lisa is an AI for leasing.</v>

106
00:06:43.780 --> 00:06:44.613
The fun.

107
00:06:45.280 --> 00:06:49.330
<v 1>I was wondering now that you've, you know, dig your hands deep into ML.</v>

108
00:06:49.630 --> 00:06:54.040
Are there any misconceptions about ML engineering that you want to debunk?

109
00:06:54.460 --> 00:06:57.550
<v 0>I think the, the general, uh,</v>

110
00:06:57.880 --> 00:07:02.620
excitement about ML is great. It made a lot of people go into ML that,

111
00:07:02.650 --> 00:07:07.180
and that's awesome, but like a lot of focus has been on, uh,

112
00:07:07.210 --> 00:07:10.780
how do I build models and how do I, uh, fit, uh,

113
00:07:10.781 --> 00:07:15.340
fit a model to the data. But like very little focus has been, uh,

114
00:07:15.400 --> 00:07:17.350
on how do I generate data?

115
00:07:17.710 --> 00:07:22.690
How do I design a business process that will create data for the algorithm

116
00:07:22.691 --> 00:07:25.630
that I want to build? How do I handle the outputs?

117
00:07:25.720 --> 00:07:28.330
How do I build all the process around, uh,

118
00:07:28.420 --> 00:07:33.070
DML components that there's too much focus on building the models? Uh,

119
00:07:33.190 --> 00:07:36.430
not in the focus on how to integrate, uh,

120
00:07:36.490 --> 00:07:41.230
ML into existing, uh, products and to be fair,

121
00:07:41.231 --> 00:07:44.290
it's kind of a new field, right? Um,

122
00:07:44.350 --> 00:07:48.760
not many people have to know how to do this because it's, it's, it's so new. Uh,

123
00:07:48.790 --> 00:07:52.510
like an analogy is when, you know,

124
00:07:52.520 --> 00:07:56.530
computers were first invented or like the internet was first invented.

125
00:07:57.160 --> 00:08:01.510
People were finding out how to integrate that into existing business processes.

126
00:08:01.870 --> 00:08:05.500
And, you know, it took a lot of trial and error, but that's the same thing.

127
00:08:05.530 --> 00:08:07.600
Like not everything is just building up.

128
00:08:08.290 --> 00:08:09.123
<v 1>Right? Yeah.</v>

129
00:08:09.160 --> 00:08:13.750
Not everything becomes more useful if there's machine learning in it. Yeah.

130
00:08:13.840 --> 00:08:18.370
Right. Maybe not everything should use blockchain technology. Exactly. Right.

131
00:08:18.550 --> 00:08:20.770
That's what, that's the example I wanted to use. Like,

132
00:08:20.800 --> 00:08:24.100
I always wonder a lot of people want to do machine learning. Now my viewers,

133
00:08:24.101 --> 00:08:28.660
especially because I think it's because I'm in the intersection of data science

134
00:08:28.661 --> 00:08:31.930
and software engineering, but, um,

135
00:08:32.140 --> 00:08:37.000
I don't wan I don't really understand the appeal of machine learning at the job

136
00:08:37.390 --> 00:08:39.610
because in my mind what you do is like you said,

137
00:08:39.640 --> 00:08:43.150
you make sure you have good data, make sure you solve a problem with your ML.

138
00:08:43.240 --> 00:08:45.460
So most of the time in my head,

139
00:08:45.730 --> 00:08:50.470
you build data pipelines to funnel into your model. You pick a model,

140
00:08:51.340 --> 00:08:53.170
you play with the,

141
00:08:53.200 --> 00:08:57.240
you tune the parameters and then try to optimize for that AUC.

142
00:08:58.020 --> 00:09:02.850
And then that's it like is, or is there more to it that I don't know?

143
00:09:03.060 --> 00:09:04.850
That is fun. I think.

144
00:09:05.420 --> 00:09:07.850
<v 0>Like, you're, you're kind of right. I mean,</v>

145
00:09:08.180 --> 00:09:10.340
especially if you're building products, you know,

146
00:09:10.550 --> 00:09:14.780
you don't have the time to do the fun stuff. And in ML research,

147
00:09:15.350 --> 00:09:19.280
the way I see it, software engineering is the core skill.

148
00:09:19.820 --> 00:09:24.410
And then there's like ML engineering that, that gives you a bit more,

149
00:09:25.070 --> 00:09:29.870
um, domain knowledge into how to build ML products or ML

150
00:09:29.871 --> 00:09:34.190
models. But in the end, once you, once you've done that, like a V1 of it,

151
00:09:34.460 --> 00:09:38.690
that's it, you have to, you have to build all of the systems around it. Uh,

152
00:09:38.720 --> 00:09:42.350
and that's not what the school, uh,

153
00:09:42.620 --> 00:09:44.420
it's not what you really learn at school.

154
00:09:45.170 --> 00:09:49.400
<v 1>Okay. So imagine the fun stuff that machine learning researchers do.</v>

155
00:09:49.520 --> 00:09:51.290
What is that? What is the fun stuff?

156
00:09:51.440 --> 00:09:53.630
<v 0>What would be fun for me? I think, uh,</v>

157
00:09:53.690 --> 00:09:57.470
in terms of research would be, you know,

158
00:09:57.500 --> 00:10:01.820
investigating the latest, uh, algorithms and like, uh,

159
00:10:01.880 --> 00:10:06.230
understanding why they work, why they don't trying different set data sets on,

160
00:10:06.980 --> 00:10:10.760
um, these new algorithms. A lot of the things that you've seen out there,

161
00:10:10.761 --> 00:10:14.570
like Gans, generative, adversarial networks,

162
00:10:14.600 --> 00:10:18.350
you make like funky images, uh, style transfers,

163
00:10:18.380 --> 00:10:23.000
like these were all investigations and why do convolutional

164
00:10:23.001 --> 00:10:27.350
networks work as they do? Um, and that's research, right.

165
00:10:27.380 --> 00:10:29.840
And that's not, it's not primarily those,

166
00:10:29.870 --> 00:10:32.900
those things were not built primarily for a business.

167
00:10:33.440 --> 00:10:34.273
<v 1>Yeah. Got it.</v>

168
00:10:35.870 --> 00:10:39.440
<v 0>And of course, Lisa is an AI for leasing.</v>

169
00:10:42.170 --> 00:10:46.760
One of the problems that people had was like, when you put your, uh, your,

170
00:10:46.800 --> 00:10:49.610
your apartment for, uh, on Zillow or something like that,

171
00:10:49.910 --> 00:10:54.020
you get a ton of inbound. You have, um, you have emails, you have text messages.

172
00:10:54.021 --> 00:10:58.880
Yeah. Phone calls. Like it's the, it's very fragmented.

173
00:10:58.881 --> 00:11:03.440
The things that you get and you have to take all of that inbound

174
00:11:04.190 --> 00:11:05.750
coordinate, showings,

175
00:11:05.870 --> 00:11:10.250
take care of applications and like do all that move in process. Uh,

176
00:11:10.280 --> 00:11:11.210
so Lisa,

177
00:11:11.360 --> 00:11:15.350
what we decided to do was to automate

178
00:11:16.100 --> 00:11:20.810
the responses, uh, to, uh, text messages, emails,

179
00:11:20.840 --> 00:11:24.590
phone calls. And on the other side, we just produced a showing.

180
00:11:24.750 --> 00:11:29.180
So people just had to show up and least the leasing agents just have

181
00:11:29.750 --> 00:11:33.890
to show up and, uh, sell, sell the property.

182
00:11:34.370 --> 00:11:38.870
They didn't have to coordinate and do all that stuff. Uh, and that was the main,

183
00:11:38.900 --> 00:11:43.100
the main focus. Um, other, I think a lot of people liked how, you know,

184
00:11:43.101 --> 00:11:46.740
their phone stopped ringing, uh, after they used, they started using it.

185
00:11:47.480 --> 00:11:50.480
<v 1>Yeah. Yeah. Cool. Awesome. So what about you?</v>

186
00:11:50.481 --> 00:11:55.360
What did you do in dynasty? Yeah. You worked on DISA, I guess. Yeah, of course.

187
00:11:56.970 --> 00:12:00.270
<v 0>So originally I was hired for it to do some research because, you know,</v>

188
00:12:00.300 --> 00:12:03.750
I was a researcher, blah, blah, blah. Um, but you know,

189
00:12:03.780 --> 00:12:06.180
nothing turns out as we plan it.

190
00:12:06.210 --> 00:12:10.200
And I decided to take that opportunity to, uh,

191
00:12:10.680 --> 00:12:15.090
dive into ML. Uh, I mean, I had some MLS experiences, uh,

192
00:12:15.180 --> 00:12:19.590
back in college and a little bit, uh, back in my previous job,

193
00:12:19.830 --> 00:12:21.990
but never, uh, deeply.

194
00:12:22.710 --> 00:12:27.300
So I decided to build out the, the ML components, uh,

195
00:12:27.330 --> 00:12:30.630
got into deep learning, learn about, uh, NLP,

196
00:12:30.660 --> 00:12:32.370
which is natural language processing.

197
00:12:32.790 --> 00:12:37.410
And once that core thing was built, uh, you know,

198
00:12:37.411 --> 00:12:41.250
we were still a startup, we just had to do other things. So I, uh,

199
00:12:41.280 --> 00:12:44.040
got myself into software engineering, um, you know,

200
00:12:44.041 --> 00:12:48.750
before that had never done like real software engineering, but under, uh,

201
00:12:49.170 --> 00:12:53.760
our CTO, uh, I was able to learn a lot about,

202
00:12:54.510 --> 00:12:58.920
um, you know, how to build, uh, how to build products and like,

203
00:12:59.250 --> 00:13:03.270
yes, I did software engineering and, uh, product design. Yeah.

204
00:13:03.900 --> 00:13:05.520
Basically you have to do everything at a startup.

205
00:13:06.420 --> 00:13:10.890
<v 1>[Inaudible] so why, why couldn't other people just do the same thing,</v>

206
00:13:10.891 --> 00:13:15.510
just apply AI to real estate stuff. And then would they be a competitor?

207
00:13:15.750 --> 00:13:18.870
Like how, why, what made dynasty successful?

208
00:13:20.130 --> 00:13:23.520
<v 0>We also thought that there was going to be competitors. And I think there,</v>

209
00:13:23.580 --> 00:13:28.320
there are, but nobody took the symbol. The exact approach that we did, uh,

210
00:13:28.350 --> 00:13:33.150
which was Lisa would talk to, to prospects, prospects,

211
00:13:33.151 --> 00:13:36.120
being the people who would rent, uh,

212
00:13:36.150 --> 00:13:39.660
they would talk to them without telling them that they it's a bot or anything,

213
00:13:39.720 --> 00:13:43.890
because in reality, we're not fully a bot either. Um,

214
00:13:44.040 --> 00:13:47.460
about 40% of our messages are handled by humans,

215
00:13:47.461 --> 00:13:52.260
who we call operators. The fact that we try to give such a natural,

216
00:13:52.890 --> 00:13:56.640
um, experienced prospect is something that, um,

217
00:13:56.820 --> 00:14:00.330
the clients really liked because in general, um,

218
00:14:00.390 --> 00:14:03.750
people don't like to interact with a bot. Um,

219
00:14:03.810 --> 00:14:07.080
so our conversations look very natural, uh,

220
00:14:07.110 --> 00:14:10.110
because there's a lot of humans that kind of, uh,

221
00:14:10.170 --> 00:14:13.560
that we fall back to when things go wrong. Actually,

222
00:14:13.561 --> 00:14:18.300
I have a funny story about people not liking to interact with bots.

223
00:14:18.870 --> 00:14:22.140
So one, one thing that we measured, um,

224
00:14:22.740 --> 00:14:27.510
was how often would people see a reply when we send

225
00:14:27.511 --> 00:14:30.720
messages back to them, right? It's like reply ratio or whatever.

226
00:14:31.440 --> 00:14:35.870
Initially we would reply instantaneously because, uh, people would message in.

227
00:14:35.990 --> 00:14:39.720
And we were like, Hey, we have a showing at, uh, two 30. Do you want to come?

228
00:14:40.320 --> 00:14:41.770
Like within seconds? And then,

229
00:14:41.890 --> 00:14:46.740
and then people were probably freaked out and replied less

230
00:14:46.770 --> 00:14:50.910
than if we were to wait two minutes, uh, before.

231
00:14:51.950 --> 00:14:53.930
So all the, we can reply very quickly.

232
00:14:54.080 --> 00:14:58.820
Sometimes we wait a minute or two before doing so that's interesting.

233
00:14:59.180 --> 00:15:03.620
So another part that made us successful, I think, uh, was the fact, well,

234
00:15:04.310 --> 00:15:07.980
I think that the biggest, the biggest success was the, the,

235
00:15:08.010 --> 00:15:12.350
the market validation that was done prior to the pivot, but that aside,

236
00:15:13.250 --> 00:15:18.000
uh, another thing was our willingness to just build what

237
00:15:18.300 --> 00:15:21.500
was needed and like not focus on, uh,

238
00:15:21.530 --> 00:15:26.360
technology too much and just get something out, out there, re uh,

239
00:15:26.390 --> 00:15:27.620
get it in front of people,

240
00:15:27.650 --> 00:15:32.540
iterate and build it as simply as possible so that we don't waste

241
00:15:32.541 --> 00:15:37.250
too much energy trying to optimize a system that was not going to exist like

242
00:15:37.640 --> 00:15:42.440
a week later. Yeah. And also these days, AI products that are like very,

243
00:15:43.100 --> 00:15:44.450
uh, already hot. Um,

244
00:15:44.840 --> 00:15:49.700
a lot of people spend a lot of time optimizing that small, uh,

245
00:15:50.210 --> 00:15:53.660
small component, which in retrospect,

246
00:15:53.661 --> 00:15:57.740
like I could have spent more time on that. But if I did that,

247
00:15:57.741 --> 00:16:02.120
I wouldn't have like use my time to build out the product in terms of the

248
00:16:02.150 --> 00:16:06.350
software engineering part. Right. Deciding to say, okay, that's good enough.

249
00:16:06.980 --> 00:16:11.630
And work on, uh, like the most important part for the business,

250
00:16:12.380 --> 00:16:17.120
uh, was, was something was a, was spirit that like everybody had at dynasty.

251
00:16:17.121 --> 00:16:20.240
And I think that really, um, you know,

252
00:16:20.270 --> 00:16:23.240
pushed us beyond the edge.

253
00:16:23.410 --> 00:16:27.730
<v 1>Can you give me a concrete example of that thing you just described? Like,</v>

254
00:16:27.731 --> 00:16:32.170
what could have you optimized on, like, how did your ML system work as a whole,

255
00:16:32.380 --> 00:16:36.220
what was that part of the ML system that you could have optimized on,

256
00:16:36.221 --> 00:16:39.040
but what did you work on instead to make your product better.

257
00:16:39.250 --> 00:16:44.020
<v 0>In the backend? The first ML component that we created was,</v>

258
00:16:44.650 --> 00:16:46.900
um, uh, an intent classifier.

259
00:16:46.930 --> 00:16:51.550
So we would take in messages and, uh,

260
00:16:51.580 --> 00:16:55.990
understand what is the intent to classify them as, uh, uh,

261
00:16:56.050 --> 00:17:00.130
one of a few intents, like, do they want to showing, um,

262
00:17:00.340 --> 00:17:02.350
did they accept something like whatever, um.

263
00:17:02.530 --> 00:17:05.140
<v 1>Actually before we continue, can I just, um,</v>

264
00:17:05.290 --> 00:17:09.400
kind of have a high level overview of what Lisa does, because right now,

265
00:17:09.430 --> 00:17:13.180
I think it's kind of just like a chat bot for leasing. Yep. And then,

266
00:17:13.570 --> 00:17:17.080
is there anything that does, like, how does it interact with the, um,

267
00:17:17.410 --> 00:17:19.540
the operators and also the clients?

268
00:17:19.650 --> 00:17:20.290
<v 0>Right.</v>

269
00:17:20.290 --> 00:17:24.760
So Lisa is a pretty complicated product in terms of

270
00:17:25.270 --> 00:17:29.680
how you would explain it, like with the components that you understand,

271
00:17:29.681 --> 00:17:34.420
because there's a lot of interactions. One interaction is with the prospect.

272
00:17:35.440 --> 00:17:40.330
Uh, so with, through there, we, it's just a bunch of texts or emails.

273
00:17:40.660 --> 00:17:44.080
The first text comes in, we ask them, uh,

274
00:17:44.110 --> 00:17:47.650
do they want to showing then the CA the, the conversation can go anywhere.

275
00:17:47.651 --> 00:17:51.690
They can ask questions about property. They can like, um, you know,

276
00:17:51.720 --> 00:17:56.520
decide not to do anything. We have to confirm them for the showing.

277
00:17:56.521 --> 00:17:58.710
And like, we asked them how, how it's going.

278
00:17:59.040 --> 00:18:03.570
That's one interaction with the agents, the leasing agents, uh,

279
00:18:03.690 --> 00:18:07.350
we schedule things on their calendar. Uh,

280
00:18:07.351 --> 00:18:10.830
we ask them questions that we don't know the answer of.

281
00:18:11.100 --> 00:18:14.520
We answer the questions that they have for us.

282
00:18:14.640 --> 00:18:18.600
And there's like an interaction with bosses, which bosses.

283
00:18:18.630 --> 00:18:20.940
<v 1>The bosses real estate agent boss, correct.</v>

284
00:18:20.970 --> 00:18:24.900
<v 0>Okay. Uh, sometimes the same person, but like often it's not, uh,</v>

285
00:18:24.920 --> 00:18:29.760
they want reporting. Uh, so that's, uh, that's the main interaction.

286
00:18:30.210 --> 00:18:34.890
And then there's our human operators, which, uh,

287
00:18:34.950 --> 00:18:37.860
uses Lisa as like an interface to the outside world.

288
00:18:39.120 --> 00:18:42.930
They have, uh, what we call the command center.

289
00:18:43.470 --> 00:18:47.130
And it's mostly like a, uh, messenger interface,

290
00:18:47.160 --> 00:18:52.080
but like augmented with a lot of information. And also, uh,

291
00:18:52.170 --> 00:18:54.990
they have a concept called the quick action,

292
00:18:55.410 --> 00:19:00.240
which they can quickly find a commonly use action to

293
00:19:00.241 --> 00:19:02.580
reply to prospects. Awesome. Yep.

294
00:19:02.720 --> 00:19:03.170
<v 1>Okay.</v>

295
00:19:03.170 --> 00:19:06.500
So that means back then real estate agent would have to communicate with the

296
00:19:06.501 --> 00:19:10.730
prospects due to showing scheduled or own showing, manage your own calendar,

297
00:19:11.210 --> 00:19:13.460
but now they actually don't even need to talk to the prospects.

298
00:19:13.490 --> 00:19:17.300
And you just have Lisa that is kind of like a layer in between the swept them

299
00:19:17.330 --> 00:19:18.230
all. And it's really cool.

300
00:19:18.710 --> 00:19:20.580
<v 0>Till they get to the showing, which I don't, you know,</v>

301
00:19:20.870 --> 00:19:22.770
they want to use their human specialties.

302
00:19:23.060 --> 00:19:24.230
<v 1>Through the cell, you know? Well, I mean,</v>

303
00:19:24.231 --> 00:19:29.210
one day you could build robots and just replace that too one day. Yeah.

304
00:19:29.240 --> 00:19:33.350
Cool. Okay. So now that we have a good overview, let's go back to, um,

305
00:19:33.710 --> 00:19:36.740
what are de Mol parts that are very specific.

306
00:19:36.830 --> 00:19:39.710
I'm pretty sure there's ML in the quick reply.

307
00:19:40.430 --> 00:19:41.330
<v 0>There's.</v>

308
00:19:41.810 --> 00:19:45.260
<v 1>Probably ML in trying to classify what messages there are.</v>

309
00:19:45.590 --> 00:19:47.510
So what were the other stuff that you could,

310
00:19:47.570 --> 00:19:50.960
that you worked on that was better for the business than just optimizing?

311
00:19:52.390 --> 00:19:56.060
<v 0>Once we got the intent classifiers, we could have know,</v>

312
00:19:56.090 --> 00:20:00.560
tried better models like Burt or Elmo,

313
00:20:00.680 --> 00:20:03.950
like the stuff that came out in 2008, I was really hot.

314
00:20:04.100 --> 00:20:06.920
We could have tried using that to, you know,

315
00:20:06.950 --> 00:20:09.380
gain a few percentage points of accuracy.

316
00:20:10.060 --> 00:20:12.170
<v 1>Or those models, uh, like NLP models.</v>

317
00:20:12.590 --> 00:20:16.790
<v 0>Sorry. Okay. Yeah. We used something like pretty simple, like, uh, uh, tech,</v>

318
00:20:16.791 --> 00:20:21.470
CNN, um, for our core models and it worked, it worked fine.

319
00:20:22.580 --> 00:20:27.080
Uh, but like, you know, show, could we have done better? Uh, we're still trying,

320
00:20:27.440 --> 00:20:31.400
uh, so when we have time, but like, there are more important parts, uh,

321
00:20:31.430 --> 00:20:33.490
to work on. Got it. Yeah. Like,

322
00:20:34.130 --> 00:20:38.030
like the question tiger was born out of necessity and like,

323
00:20:38.330 --> 00:20:42.230
they were there were answering the questions over and over again. Um,

324
00:20:42.290 --> 00:20:45.800
so like finding other places to, to,

325
00:20:46.000 --> 00:20:50.920
to package an ML solution is more impactful than trying

326
00:20:50.921 --> 00:20:55.120
to optimize the existing components. Got it. Yeah.

327
00:20:56.220 --> 00:21:01.140
<v 1>So what do you think most startups make as</v>

328
00:21:01.141 --> 00:21:04.260
mistakes using ML, like water to come mistakes,

329
00:21:04.261 --> 00:21:06.720
startups make using ML,

330
00:21:06.990 --> 00:21:11.280
cause I'm guessing you're comparing your dynasty to other startups.

331
00:21:11.310 --> 00:21:13.950
So how would they do, what would they do wrong?

332
00:21:14.310 --> 00:21:18.840
<v 0>My guess would be focusing too much on the latest</v>

333
00:21:19.260 --> 00:21:20.580
technology that's out there,

334
00:21:20.640 --> 00:21:25.290
especially the academic literature and trying to apply that

335
00:21:25.291 --> 00:21:29.520
to their business. It takes time to, for academic literature,

336
00:21:29.521 --> 00:21:33.960
to mature for business. And a lot of, uh,

337
00:21:33.961 --> 00:21:38.280
a lot of the literature is sometimes not reproducible.

338
00:21:39.030 --> 00:21:43.920
Um, and that's a common problem. Uh, so like investing too much there, uh,

339
00:21:44.430 --> 00:21:47.370
we'll waste a lot of time. And as a startup, you don't have a lot of time.

340
00:21:47.790 --> 00:21:48.623
Got it. Now.

341
00:21:48.630 --> 00:21:51.240
<v 1>I heard a lot of people saying that in theory,</v>

342
00:21:51.241 --> 00:21:54.300
the paper sounds great and it works with their dataset,

343
00:21:54.630 --> 00:21:57.540
but applying it as a whole different story. Yeah. Applying, you have to.

344
00:21:58.080 --> 00:22:02.280
<v 0>So finding a way to apply ML to a business</v>

345
00:22:02.340 --> 00:22:06.750
environment is difficult because you have to specifically

346
00:22:07.440 --> 00:22:11.910
know which problem like business in itself is like many, many problems.

347
00:22:11.940 --> 00:22:16.740
And you have to carve out one specific problem for ML.

348
00:22:17.070 --> 00:22:19.950
It has to be worth it worth the time of research.

349
00:22:20.250 --> 00:22:24.720
You have to be able to find a process that will generate data for that problem.

350
00:22:25.050 --> 00:22:29.160
And once your algorithm is working, you have false positives,

351
00:22:29.161 --> 00:22:33.090
you have false negatives, you have to have a process to handle that.

352
00:22:33.870 --> 00:22:38.610
And then not even including monitoring, like making sure that, uh,

353
00:22:38.880 --> 00:22:41.280
your, your models are, are always, uh,

354
00:22:41.430 --> 00:22:46.080
performing as well as you think they are in our business with Lisa is generally

355
00:22:46.081 --> 00:22:50.850
pretty. It's not too bad because like English generally doesn't change. Uh,

356
00:22:50.880 --> 00:22:54.360
but you know, maybe if you're working on ads or like, uh,

357
00:22:54.390 --> 00:22:59.370
trading your environment will change and your algorithm performance might

358
00:22:59.371 --> 00:23:02.160
decay. And you, you have to like, know about that.

359
00:23:02.820 --> 00:23:05.940
So there's a lot of stuff that happens around that.

360
00:23:06.150 --> 00:23:08.060
It's no small ML components.

361
00:23:08.820 --> 00:23:10.650
<v 1>So from what I understand,</v>

362
00:23:10.651 --> 00:23:14.070
it seems like it's better to build out your system,

363
00:23:14.100 --> 00:23:15.780
understanding what you have to do,

364
00:23:15.781 --> 00:23:20.520
how to do everything and then identify what are the spots that need ML and then

365
00:23:20.521 --> 00:23:25.500
solve for that rather than some other companies would identify maybe

366
00:23:25.501 --> 00:23:30.210
even an emo problem and then build out a solution like everything

367
00:23:30.211 --> 00:23:31.980
else, which ultimately,

368
00:23:31.981 --> 00:23:36.510
maybe that solution wasn't even that useful for the market anyways. Right.

369
00:23:36.840 --> 00:23:39.530
Okay. Awesome. So do you want to say, yeah.

370
00:23:39.820 --> 00:23:41.400
<v 0>I think another, uh,</v>

371
00:23:41.850 --> 00:23:46.280
pitfall would be trying to solve too much with ML.

372
00:23:46.970 --> 00:23:51.710
Like there was a, you know, there's a few companies out there that wanted to,

373
00:23:52.700 --> 00:23:53.120
uh,

374
00:23:53.120 --> 00:23:57.830
build personal assistants and it turns out the job of

375
00:23:57.831 --> 00:24:02.300
personal assistant is like extremely difficult and there's like infinite

376
00:24:03.110 --> 00:24:05.780
variation, right. Even in our business of leasing,

377
00:24:05.810 --> 00:24:10.580
we found that it's very subtle taking the,

378
00:24:10.581 --> 00:24:15.370
the very simple example of what's the rent, you know, you think that's, uh,

379
00:24:15.560 --> 00:24:20.300
a simple answer. Uh, it's a simple question at first, but then you had to say,

380
00:24:20.390 --> 00:24:23.720
you think, okay, well actually, what are they talking about?

381
00:24:23.721 --> 00:24:24.950
The one bedroom or two bedroom.

382
00:24:25.910 --> 00:24:30.710
Are they talking about moving now or moving later? Are they talking about, uh,

383
00:24:31.150 --> 00:24:35.150
uh, one, one, one year lease or two year lease? Oh, wait,

384
00:24:35.360 --> 00:24:36.650
are we talking about the,

385
00:24:36.680 --> 00:24:41.510
like about all our properties or like only the ones that are available? Yeah.

386
00:24:41.511 --> 00:24:46.340
There's a lot of intricacies in a, in a simple question just as like,

387
00:24:46.370 --> 00:24:47.810
what is the rent? Yeah.

388
00:24:48.130 --> 00:24:52.780
<v 1>And I also know it's quite difficult because I'm trying to hire a real</v>

389
00:24:52.810 --> 00:24:57.190
personal assistant and that is still very hard. So I'm guessing, you know,

390
00:24:57.430 --> 00:25:00.460
cause if you can't even solve my problems with a real human,

391
00:25:01.450 --> 00:25:03.520
I don't even know how to start solving, uh,

392
00:25:03.760 --> 00:25:05.440
with the like machine learning model,

393
00:25:06.100 --> 00:25:09.910
because usually I think if something is easy to solve manually,

394
00:25:09.911 --> 00:25:13.330
like a rapid pellets of repetition, then you can kind of replace it with AI.

395
00:25:13.960 --> 00:25:15.070
But yeah. Yeah.

396
00:25:15.270 --> 00:25:17.800
<v 0>So that's actually one of the guidelines that we have.</v>

397
00:25:18.160 --> 00:25:23.080
If we want to carve out something for the, for ML first,

398
00:25:23.740 --> 00:25:26.920
solve it with humans, see how it works, see how it works,

399
00:25:27.130 --> 00:25:31.240
if it's really repetitive. And like people make, don't make a lot of mistakes,

400
00:25:31.270 --> 00:25:35.140
right? Some heuristics, uh, not even ML and run,

401
00:25:35.170 --> 00:25:39.190
run with it for awhile, handle your handle, your false positives,

402
00:25:39.191 --> 00:25:43.120
handle your false negatives. And then if the system is humming,

403
00:25:43.540 --> 00:25:48.430
then you know, try to increase the accuracy with, uh, with ML.

404
00:25:49.390 --> 00:25:53.140
But without these intermediate steps, like don't even think about it.

405
00:25:54.460 --> 00:25:58.840
<v 1>So dynasty, are you guys, um, are you guys hiring, you know.</v>

406
00:25:59.410 --> 00:26:03.760
<v 0>Yes. Yeah. We're definitely hiring, uh, right now, you know, we need a lot of,</v>

407
00:26:04.390 --> 00:26:07.160
uh, good engineers. Um, the,

408
00:26:07.161 --> 00:26:11.860
the way we want to hire is hiring people who have

409
00:26:12.040 --> 00:26:16.900
a decent software engineering experience because we don't currently have

410
00:26:17.170 --> 00:26:21.100
a lot of time to, to bring people up to speed, uh,

411
00:26:21.130 --> 00:26:22.150
because we're still a startup,

412
00:26:22.180 --> 00:26:26.440
even though we were acquired and we want general software engineering

413
00:26:26.441 --> 00:26:27.274
skills,

414
00:26:27.460 --> 00:26:32.380
we think that that will translate well into the ML parts or,

415
00:26:32.860 --> 00:26:35.650
uh, if you focus on, um, you know,

416
00:26:35.920 --> 00:26:40.840
more system reliability or like, um, more product, uh,

417
00:26:41.140 --> 00:26:45.300
but like the core software skill is what we're looking for. Okay.

418
00:26:45.560 --> 00:26:49.430
<v 1>What kind of technologies would they be working with if they want to be an</v>

419
00:26:49.431 --> 00:26:50.930
applied machine learning engineer?

420
00:26:51.380 --> 00:26:56.270
<v 0>We, we, we, uh, we use like typical stuff like TensorFlow, uh, you know,</v>

421
00:26:56.271 --> 00:27:01.100
the Python packages and stuff like that. Um, our stack, uh,

422
00:27:01.400 --> 00:27:04.820
on the backend is Java. Again, our pragmatism, we don't,

423
00:27:04.850 --> 00:27:09.260
we don't try to use too many fancy, uh, latest technologies.

424
00:27:09.290 --> 00:27:12.410
We just use what is tried and proven. Uh,

425
00:27:12.470 --> 00:27:15.320
so really that's kind of our core philosophies.

426
00:27:16.310 --> 00:27:19.940
<v 1>Right. So what would make a good machine learning engineer, a good hire for you?</v>

427
00:27:20.120 --> 00:27:25.070
What kind of skills are not just skills, but, um, attributes,

428
00:27:25.100 --> 00:27:26.540
personal attributes. Yeah.

429
00:27:27.500 --> 00:27:32.000
<v 0>Uh, willing to dig into the details, understanding the business, uh,</v>

430
00:27:32.030 --> 00:27:36.860
not like focusing too much on, on the ML part. Um, being good at,

431
00:27:37.280 --> 00:27:41.480
uh, software engineering in general at dynasty, not like ML engineers are not,

432
00:27:42.080 --> 00:27:44.990
are not like, Oh, I'm the ML guy. And then you can,

433
00:27:45.050 --> 00:27:46.880
you guys can do like the backend,

434
00:27:46.940 --> 00:27:49.520
like you have to do you have to do the software engineering.

435
00:27:49.820 --> 00:27:52.100
You don't get like an assistant for that. Yeah.

436
00:27:52.340 --> 00:27:56.000
<v 1>So what's next for you and dynasty in the next five years?</v>

437
00:27:56.900 --> 00:28:01.640
<v 0>Well, five years is a long time. I mean, uh, just a year and a half ago. Uh,</v>

438
00:28:01.880 --> 00:28:04.250
it was a different business. Yeah. Uh, th yeah,

439
00:28:04.280 --> 00:28:08.630
two years ago it was a different thing. Um, definitely for me, uh,

440
00:28:08.660 --> 00:28:13.640
I want to see Lisa built out to its full potential. Uh, hopefully, you know,

441
00:28:13.670 --> 00:28:17.900
the viewers will, well someday, uh, rented an apartment.

442
00:28:18.020 --> 00:28:22.580
I'd be talking to Lisa. Um, and after that, who knows, uh,

443
00:28:22.910 --> 00:28:27.560
I think I'll be at folio for the foreseeable future. Yeah. Cool. Well,

444
00:28:27.770 --> 00:28:31.070
maybe I'll be building other ML products, hopefully, uh,

445
00:28:31.100 --> 00:28:34.280
finding other ways to apply ML into the real world.

446
00:28:34.910 --> 00:28:37.430
<v 1>Awesome. Cool. Yeah. Thank you so much.</v>

447
00:28:37.460 --> 00:28:42.230
And I just want to say best of luck to Lisa dynasty and

448
00:28:42.231 --> 00:28:46.730
AppFolio. Um, if they do want to apply to dynasty,

449
00:28:46.760 --> 00:28:50.750
do they have to do it through AppFolio website or is there a separate dynasty

450
00:28:50.751 --> 00:28:51.584
website?

451
00:28:52.430 --> 00:28:57.140
<v 0>Uh, we are fully under a full fuller now, so you should apply to AppFolio.</v>

452
00:28:57.590 --> 00:29:00.140
<v 1>Exactly. Yeah. So, and then if you want to prepare for AppFolio,</v>

453
00:29:00.141 --> 00:29:02.150
don't forget to check out tech and bupropion.

454
00:29:02.330 --> 00:29:06.170
I take on take in referral if you're interested in getting ready for interviews.

455
00:29:06.350 --> 00:29:06.480
Okay.

456
00:29:06.480 --> 00:29:09.680
<v 0>Yeah. I also want to plug my Twitter. M a David J.</v>

457
00:29:10.590 --> 00:29:14.000
<v 1>Um, a David J. Cool. All right.</v>

458
00:29:14.030 --> 00:29:17.000
Thank you so much for being here. Really appreciate.

459
00:29:17.000 --> 00:29:18.860
<v 0>It. Thank you for having me. All right.</v>

