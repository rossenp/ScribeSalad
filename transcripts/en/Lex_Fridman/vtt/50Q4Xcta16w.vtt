WEBVTT

1
00:00:03.250 --> 00:00:08.150
<v 0>The really interesting thing about Harvey Weinstein and you choosing these</v>

2
00:00:08.151 --> 00:00:13.110
exceptionally difficult cases is also thinking about

3
00:00:15.700 --> 00:00:19.550
what it means to defend evil people. What,

4
00:00:19.551 --> 00:00:22.630
what it means to defend these, we could say,

5
00:00:24.120 --> 00:00:29.060
and you might push back against the, the word evil, but bad people in society.

6
00:00:30.060 --> 00:00:30.940
Um, first of all,

7
00:00:30.941 --> 00:00:34.340
do you think there's such a thing as evil or do you think all people are good

8
00:00:34.600 --> 00:00:39.500
and it's just circumstances that create evil and also is there

9
00:00:39.780 --> 00:00:41.780
somebody too evil for the law to defend?

10
00:00:42.820 --> 00:00:45.410
<v 1>Right. So that's a, so the first question, that's a deep, uh,</v>

11
00:00:45.411 --> 00:00:49.730
philosophical question, whether the category of evil, uh,

12
00:00:49.800 --> 00:00:54.170
does any work, uh, for me, uh, it, it does for me, I,

13
00:00:54.410 --> 00:00:55.890
I do think that, uh,

14
00:00:55.930 --> 00:01:00.450
I do subscribe to that category that there is, uh, evil,

15
00:01:01.250 --> 00:01:05.080
uh, in the world as conventionally. Uh, understood. So, uh,

16
00:01:05.260 --> 00:01:07.000
so there are many who will say, yeah,

17
00:01:07.030 --> 00:01:11.680
that just doesn't doesn't do any work for me. Uh, but, uh,

18
00:01:11.820 --> 00:01:16.440
the category evil, in fact, does intellectual work for me. And I,

19
00:01:16.560 --> 00:01:21.520
I understand it as, as, as something that, uh, that, uh, exists.

20
00:01:21.920 --> 00:01:25.310
<v 0>Um, is it genetic or is it the circumstance? Like what,</v>

21
00:01:25.311 --> 00:01:27.270
what kind of work does it do for you intellectually?

22
00:01:27.510 --> 00:01:30.710
<v 1>I think that it's, uh, highly contingent.</v>

23
00:01:30.711 --> 00:01:35.110
That is to say that the conditions in which one

24
00:01:35.640 --> 00:01:40.390
grows up and so forth, uh, uh, uh,

25
00:01:41.410 --> 00:01:46.060
begins to create this category that we may think of as evil.

26
00:01:46.400 --> 00:01:51.300
Now, there are, um, studies and, and, and whatnot that show that, uh,

27
00:01:51.530 --> 00:01:56.220
certain, um, uh, brain abnormalities and so forth are,

28
00:01:56.540 --> 00:01:59.220
are more prevalent in say serial killer.

29
00:01:59.320 --> 00:02:03.900
So there may be a biological predisposition to certain

30
00:02:04.030 --> 00:02:08.050
forms of conduct, but, um, uh, I don't, uh,

31
00:02:08.170 --> 00:02:10.410
I don't have the, uh,

32
00:02:11.140 --> 00:02:15.610
biological evidence to make a statement that someone is born evil and,

33
00:02:16.070 --> 00:02:20.690
and, you know, uh, I I'm, I'm not a determinist thinker in that way.

34
00:02:20.710 --> 00:02:24.890
So you come out the womb evil, and you're destined to be that way, um,

35
00:02:25.270 --> 00:02:30.040
to the extent, or maybe biological, uh, determinants, uh,

36
00:02:30.320 --> 00:02:34.720
that still require some, um, uh, nurture, uh, as well.

37
00:02:35.440 --> 00:02:36.520
Um, so, but.

38
00:02:36.520 --> 00:02:40.440
<v 0>Do you still put a responsibility for the, on the individual? Of.</v>

39
00:02:40.440 --> 00:02:45.040
<v 1>Course, yeah. We all make choices. And so some responsibility,</v>

40
00:02:45.520 --> 00:02:46.950
uh, on the individual, indeed,

41
00:02:50.770 --> 00:02:53.990
we live in a culture, unfortunately,

42
00:02:54.120 --> 00:02:58.870
where a lot of people have a constellation of

43
00:02:58.980 --> 00:03:03.040
bad choices in front of them. And that makes me very sad. Yeah. Um,

44
00:03:03.600 --> 00:03:08.480
that the people grow up with, with predominantly bad choices in,

45
00:03:08.580 --> 00:03:12.400
in front of them. And that's unfair and that's that that's on all of us. Uh,

46
00:03:12.420 --> 00:03:14.360
but yes, I do think we make, we make choices.

47
00:03:14.940 --> 00:03:19.030
<v 0>Wow. That's so powerful. The constellation of bad choices. I,</v>

48
00:03:21.770 --> 00:03:26.470
that's such a powerful way to think about sort of equality,

49
00:03:27.240 --> 00:03:32.190
which is this, the set of trajectories before you,

50
00:03:32.540 --> 00:03:36.110
that you could take, if you just roll the dice is a,

51
00:03:37.570 --> 00:03:40.420
you know, life is, is a kind of optimization problem.

52
00:03:40.670 --> 00:03:45.020
Sorry to take us into math over a set of trajectories under imperfect

53
00:03:45.021 --> 00:03:46.900
information. Uh,

54
00:03:47.160 --> 00:03:50.900
so you're gonna do a lot of stupid &lt;laugh&gt; to put it, uh,

55
00:03:51.520 --> 00:03:55.980
in technical terms. Uh, but, uh,

56
00:03:56.360 --> 00:04:00.250
the, the, the fraction of the trajectories take you into,

57
00:04:00.480 --> 00:04:03.290
into bad places or into good places is really important.

58
00:04:03.630 --> 00:04:05.330
And that's ultimately what we're talking about.

59
00:04:05.930 --> 00:04:09.810
An evil might be just a little bit of a predisposition biologically,

60
00:04:09.830 --> 00:04:11.850
but the rest is just trajectories that you can take.

