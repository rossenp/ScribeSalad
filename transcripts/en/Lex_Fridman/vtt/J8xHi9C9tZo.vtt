WEBVTT

1
00:00:03.020 --> 00:00:07.070
<v 0>Every so often some big idea happens, but it might be one person.</v>

2
00:00:07.960 --> 00:00:11.740
<v 1>Ideas in what, in the space of engineering or is it in a space?</v>

3
00:00:12.730 --> 00:00:16.660
<v 0>So one of the limits of computer performance is branch predictions. So,</v>

4
00:00:17.320 --> 00:00:17.801
and there's a,

5
00:00:17.801 --> 00:00:20.680
there's a whole bunch of ideas about how good you could predict a branch.

6
00:00:20.800 --> 00:00:24.250
And people said there was a limit to it to not spin Tata curve.

7
00:00:24.850 --> 00:00:27.550
And somebody came up with a better way to do branch prediction.

8
00:00:27.850 --> 00:00:32.170
It was a lot better and he published a paper on it and every computer in the

9
00:00:32.171 --> 00:00:36.430
world now uses it. And it was one idea. So the,

10
00:00:36.460 --> 00:00:38.950
the engineers who build branch picks and hardware,

11
00:00:39.460 --> 00:00:43.060
we're happy to drop the one kind of training array and put it in another one.

12
00:00:43.720 --> 00:00:45.670
So it was, it was a real idea.

13
00:00:46.210 --> 00:00:47.043
<v 1>And branch,</v>

14
00:00:47.930 --> 00:00:51.340
as one of the key problems underlying all of,

15
00:00:51.341 --> 00:00:54.880
sort of the lowest low software, it boils down to branch. The prediction.

16
00:00:55.150 --> 00:00:56.200
<v 0>Boils down, the uncertainty,</v>

17
00:00:56.230 --> 00:01:00.400
computers are limited by single-threaded computers limited by two things, the,

18
00:01:00.880 --> 00:01:03.670
the predictability of the path of the branches and the predictability of the

19
00:01:03.671 --> 00:01:05.320
locality of data.

20
00:01:06.670 --> 00:01:10.480
So we have predictors that now predict both of those pretty well. Yeah.

21
00:01:10.510 --> 00:01:13.150
So memory is, you know, a couple hundred cycles away.

22
00:01:13.290 --> 00:01:17.020
The local cash has a couple cycles away when you're executing fast,

23
00:01:17.050 --> 00:01:22.000
virtually all the data has to be in the local cache. So a simple program says,

24
00:01:22.450 --> 00:01:24.550
you know, add one to every element and array.

25
00:01:24.610 --> 00:01:27.220
It's really easy to see what the stream of data will be,

26
00:01:28.000 --> 00:01:30.400
but you might have a more complicated program that's, you know,

27
00:01:30.430 --> 00:01:32.380
so was good to get an element of this Ray,

28
00:01:32.381 --> 00:01:35.530
look at something and make a decision and go get another element it's kind of

29
00:01:35.531 --> 00:01:38.380
random. And you can think that's really unpredictable.

30
00:01:39.100 --> 00:01:42.220
And then you make this big predictor that looks at this kind of pattern and you

31
00:01:42.221 --> 00:01:44.320
realize, well, if you get this data and this data,

32
00:01:44.321 --> 00:01:45.580
then you probably want that one.

33
00:01:45.850 --> 00:01:49.060
And if you get this one and this one and this one, you probably want that one.

34
00:01:49.240 --> 00:01:52.630
<v 1>And is that theory or is that engineering like the paper that was written?</v>

35
00:01:52.660 --> 00:01:57.460
Was it a symbiotic kind of kind of discussion or is it more like here's a hack

36
00:01:57.461 --> 00:01:58.294
that works well?

37
00:01:59.260 --> 00:02:01.810
<v 0>Um, it's a little bit of both like there's information theory in it,</v>

38
00:02:01.840 --> 00:02:05.920
I think somewhere. Okay. There's actually trying to prove, but once, once,

39
00:02:05.921 --> 00:02:09.850
you know, the method implementing it is an engineering problem.

