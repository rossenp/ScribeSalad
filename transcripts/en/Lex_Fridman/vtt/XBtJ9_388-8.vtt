WEBVTT

1
00:00:03.030 --> 00:00:06.610
<v 0>Who is your favorite robot in science fiction books or movies?</v>

2
00:00:07.570 --> 00:00:08.291
<v 1>Wally in R two D two,</v>

3
00:00:08.291 --> 00:00:13.090
where they were able to convey such an incredible degree of intent

4
00:00:13.120 --> 00:00:17.970
emotion and kind of character attachment without having

5
00:00:18.150 --> 00:00:21.810
any language whatsoever. Um, and just purely through the emotion,

6
00:00:21.811 --> 00:00:25.200
richness of emotion interactions. So those were fantastic. And then, uh,

7
00:00:25.860 --> 00:00:30.840
the Terminator series just like really ruined my pretty wide range. Right. Uh,

8
00:00:30.860 --> 00:00:32.640
but, uh, I kind of love this, uh,

9
00:00:32.641 --> 00:00:35.800
dynamic where you have this like incredible Terminator itself that,

10
00:00:35.801 --> 00:00:39.840
that Arnold played. But, uh, and then he was kind of like the inferior,

11
00:00:40.070 --> 00:00:44.310
like previous generation version that was like totally outmatched, uh, you know,

12
00:00:44.311 --> 00:00:46.710
in terms of kind of specs by the new one, but, you know,

13
00:00:46.711 --> 00:00:49.870
still kind of like El zone. And so it was kind of interesting where you,

14
00:00:50.190 --> 00:00:51.023
you realize how many,

15
00:00:51.550 --> 00:00:55.110
how many levels there are on the spectrum from human to kind of potentials and

16
00:00:55.210 --> 00:00:59.310
AI and robotics to futures. And so, yeah, that movie really,

17
00:01:00.050 --> 00:01:04.700
as much as it was like kind of a dark world in a way was actually fascinating,

18
00:01:04.701 --> 00:01:05.460
gets the imagination.

19
00:01:05.460 --> 00:01:08.940
<v 0>Going well from an engineering perspective, both the movies you mentioned, uh,</v>

20
00:01:09.420 --> 00:01:13.860
Wally and, uh, Terminator. Uh, the first one is probably achievable,

21
00:01:14.320 --> 00:01:15.460
you know, humanoid robot,

22
00:01:15.990 --> 00:01:19.740
maybe not with like the realism in terms of skin and so on,

23
00:01:19.800 --> 00:01:24.260
but that humanoid form, we have that humanoid form. It seems like a compelling,

24
00:01:24.900 --> 00:01:27.770
maybe the challenges that's super expensive to, to build,

25
00:01:28.190 --> 00:01:31.330
but you can imagine maybe not a machine of war. Yeah.

26
00:01:31.331 --> 00:01:35.010
But you can imagine terminated type robots walking around. Yeah.

27
00:01:35.270 --> 00:01:38.050
And then that same, obviously with WIES you've basically,

28
00:01:38.051 --> 00:01:42.370
so for people who don't know you, uh, created the company Anky that created, uh,

29
00:01:42.730 --> 00:01:46.240
a small robot with a big personality called Osmo, that just,

30
00:01:46.600 --> 00:01:48.040
it does exactly what Wally does,

31
00:01:48.041 --> 00:01:52.840
which is somehow with very few basic visual tools

32
00:01:53.200 --> 00:01:56.960
is able to communicate a depth of emotion. And that's fascinating. Uh,

33
00:01:56.980 --> 00:02:01.440
but then again, the humanoid form is, uh, super compelling.

34
00:02:01.540 --> 00:02:05.200
So like, uh, Cosmo is very distant from a humanoid form.

35
00:02:05.870 --> 00:02:07.790
And then the Terminator has a humanoid formula.

36
00:02:07.810 --> 00:02:10.750
You can imagine both of those actually being in our society.

37
00:02:11.220 --> 00:02:12.870
<v 1>It's true. And it's interesting because, um,</v>

38
00:02:13.530 --> 00:02:17.670
it was very intentional to go really far away from human form.

39
00:02:17.671 --> 00:02:21.470
When you think about a character like Cosmo or like Wally, where, um,

40
00:02:22.650 --> 00:02:27.340
you can completely rethink, uh, the constraints you on that character, um,

41
00:02:27.490 --> 00:02:31.980
what tools you average and then how you actually create a personality, uh,

42
00:02:32.200 --> 00:02:36.900
and a level of intelligence interactivity that actually matches the constraints

43
00:02:36.970 --> 00:02:41.700
that you're under, whether it's, uh, mechanical or sensors or AI of the day.

44
00:02:41.890 --> 00:02:43.140
This is why I almost, um,

45
00:02:43.340 --> 00:02:46.970
I was always very surprised by how much energy people put towards trying to

46
00:02:46.971 --> 00:02:47.970
replicate human form.

47
00:02:48.290 --> 00:02:51.050
Mm-hmm &lt;affirmative&gt; in a robot because you actually take on some pretty

48
00:02:51.051 --> 00:02:54.730
significant, um, kind of constraints and, and downsides when you do that.

49
00:02:55.050 --> 00:02:55.670
Mm-hmm &lt;affirmative&gt;, um,

50
00:02:55.670 --> 00:02:58.610
the first of which is obviously the cost where it just the,

51
00:02:58.830 --> 00:03:03.240
the articulation of a human body is just so like magical, um,

52
00:03:03.340 --> 00:03:04.200
in both the precision,

53
00:03:04.201 --> 00:03:08.440
as well as the dimensionality that to replicate that even in it CLO reasonably

54
00:03:08.640 --> 00:03:12.360
close form takes a giant amount of joints and actuators and, uh, and motion and,

55
00:03:12.760 --> 00:03:15.640
and, you know, sensors and coders and so forth. But then, um,

56
00:03:16.020 --> 00:03:19.750
you're almost like setting an expectation that the closer you try to get to

57
00:03:19.751 --> 00:03:21.910
human form, the more you expect the strengths to match.

58
00:03:22.530 --> 00:03:26.390
And that's not the way AI works is there's places where you're way stronger and

59
00:03:26.391 --> 00:03:29.470
there's places where you're weaker. And by moving away from human form,

60
00:03:29.471 --> 00:03:30.870
you can actually, uh,

61
00:03:30.930 --> 00:03:34.590
change the rules and embrace your strengths and bypass your weaknesses.

62
00:03:34.610 --> 00:03:35.150
And at the same.

63
00:03:35.150 --> 00:03:35.970
<v 0>Time,</v>

64
00:03:35.970 --> 00:03:40.540
the human form like has way too many degree use of freedom to play with.

65
00:03:41.010 --> 00:03:43.900
It's, it's kind of con counterintuitive just as you're saying,

66
00:03:44.240 --> 00:03:46.540
but when you have fewer constraints,

67
00:03:47.410 --> 00:03:51.580
it's almost harder to master the, the, the communication of emotion.

68
00:03:52.010 --> 00:03:54.300
Like you see this with cartoons, like stick figures,

69
00:03:54.880 --> 00:03:57.660
you can communicate quite a lot with just very minimal,

70
00:03:58.170 --> 00:04:02.730
like two dots for eyes and align for, for a smile. I think it, like,

71
00:04:02.830 --> 00:04:07.130
you can almost communicate arbitrary levels of emotion with just two dots and a

72
00:04:07.131 --> 00:04:08.850
line. Yeah. And like, that's enough.

73
00:04:08.851 --> 00:04:13.570
And if you focus on just that you can communicate the full range, and then you,

74
00:04:13.760 --> 00:04:18.530
like, if you do that, then you can focus on the actual magic of, of,

75
00:04:18.930 --> 00:04:20.320
uh, human and,

76
00:04:20.420 --> 00:04:25.120
and dot line interaction versus all the engineering mess.

77
00:04:25.120 --> 00:04:27.800
<v 1>That's right. Like dimensionality, voice, all these sort of things.</v>

78
00:04:28.000 --> 00:04:30.880
They actually become a crutch yeah. Where you get lost in a search space almost.

79
00:04:31.320 --> 00:04:35.600
Um, and so some of the best animators that we've worked with, um,

80
00:04:36.030 --> 00:04:39.800
they almost like study when they come up, uh, you know, kind of in,

81
00:04:40.080 --> 00:04:43.390
in building their expertise by forcing these, um,

82
00:04:43.630 --> 00:04:47.750
projects where all you have is like a ball that can like kind of jump and

83
00:04:47.751 --> 00:04:49.510
manipulate itself, or like really,

84
00:04:49.511 --> 00:04:53.830
really like aggressive constraints where you're forced to kind of ex extract the

85
00:04:53.831 --> 00:04:56.870
deepest level of motion. And so in a lot of ways, um, you know,

86
00:04:56.871 --> 00:04:58.550
we thought when we thought about Cosmo, I was like, you're you're right.

87
00:04:58.710 --> 00:05:01.660
Like our, if we had to like, describe it in like small phrase,

88
00:05:01.720 --> 00:05:05.460
it was bringing a Pixar character to life in the real world. It's, uh, it's,

89
00:05:05.620 --> 00:05:08.060
it's what we were going for. And, um, and in a lot of ways,

90
00:05:08.061 --> 00:05:09.900
what was interesting is that with like Wally,

91
00:05:09.901 --> 00:05:13.260
which we studied incredibly deeply, and in fact, some of our team were,

92
00:05:13.680 --> 00:05:18.020
you know, kind of had worked previously at, um, at Pixar on our project. Um,

93
00:05:18.021 --> 00:05:21.340
they intentionally constrained Wally as well, even though in an animated film,

94
00:05:21.341 --> 00:05:26.290
you, you could do whatever you wanted to because it forced you to like really

95
00:05:26.410 --> 00:05:29.690
saturate the smaller amount of dimensions, but, uh,

96
00:05:29.870 --> 00:05:33.450
you sometimes end up getting a far more beautiful output, um,

97
00:05:33.520 --> 00:05:35.850
because you're pushing at the extremes, um,

98
00:05:36.390 --> 00:05:40.250
of this emotional space in a way that you just wouldn't because you get lost in

99
00:05:40.251 --> 00:05:43.920
a surface area. Uh, if you have like thing that is just infinitely articulable.

100
00:05:44.060 --> 00:05:48.480
<v 0>So if we backtrack a little bit and, uh, you thought of Cosmo in 2011,</v>

101
00:05:48.800 --> 00:05:53.080
in 2013, actually, uh, designed and built it, what is Anky?

102
00:05:53.081 --> 00:05:57.680
What is Cosmo, I guess, who is Cosmo? And, uh,

103
00:05:58.520 --> 00:06:00.600
uh, what was the vision behind this incredible little.

104
00:06:00.650 --> 00:06:03.520
<v 1>Robot? We started, uh, on key back in,</v>

105
00:06:03.990 --> 00:06:06.840
like while we were still in graduate school. So myself and my two co-founders,

106
00:06:06.841 --> 00:06:11.200
we were PhD students, uh, in the robotics Institute at Carnegie me. Um,

107
00:06:11.300 --> 00:06:15.760
and so we were, uh, studying robotics, AI, machine learning, kind of different,

108
00:06:15.761 --> 00:06:17.710
you know, different, uh, uh, areas.

109
00:06:17.711 --> 00:06:20.190
One of my co-founders working on walking robots, uh, you know,

110
00:06:20.530 --> 00:06:23.390
for a period of time. And so we all had a, um,

111
00:06:23.710 --> 00:06:25.710
a bit of a really deep,

112
00:06:26.190 --> 00:06:30.230
kinda a deeper passion for applications of robotics and AI, where, um,

113
00:06:30.300 --> 00:06:33.190
there's like a spectrum where there's people that get like really fascinated by

114
00:06:33.191 --> 00:06:36.270
the theory of AI and machine learning, robotics, where, um,

115
00:06:36.271 --> 00:06:40.580
whether it gets applied in the near future or not is less of a kind of factor on

116
00:06:40.700 --> 00:06:43.500
them, but they love the pursuit of the, like the challenge and that's necessary.

117
00:06:43.500 --> 00:06:45.260
And there's a lot of incredible breakthroughs that happen there.

118
00:06:45.430 --> 00:06:47.020
We're probably closer to the other end of the spectrum,

119
00:06:47.021 --> 00:06:50.860
where we love the technology and the, um, and all the evolution of it.

120
00:06:50.861 --> 00:06:53.180
But we were really driven by applications.

121
00:06:53.181 --> 00:06:58.050
Like how can you really reinvent experiences and functionality and build value

122
00:06:58.520 --> 00:07:01.810
that wouldn't have been possible without, um, these approaches and,

123
00:07:02.050 --> 00:07:02.771
and that's what drove us.

124
00:07:02.771 --> 00:07:06.370
And we had a kind of some experiences through previous jobs and internships

125
00:07:06.371 --> 00:07:08.930
where we like got to see the applied side of robotics.

126
00:07:09.070 --> 00:07:13.330
And at that time there was actually relatively few applications of robotics, um,

127
00:07:13.331 --> 00:07:17.930
that were outside of, um, you know, pure research or industrial application,

128
00:07:18.600 --> 00:07:22.360
um, military applications and so forth. There were very few outside of it.

129
00:07:22.361 --> 00:07:23.194
So maybe, you know,

130
00:07:23.340 --> 00:07:25.520
iRobot was like one exception and maybe there were a few others,

131
00:07:25.620 --> 00:07:27.320
but for the most part, there weren't that many.

132
00:07:27.320 --> 00:07:30.560
And so we got excited about consumer applications of robotics,

133
00:07:30.561 --> 00:07:34.480
where you could leverage way higher levels of intelligence, um,

134
00:07:34.481 --> 00:07:38.080
through software to create value and experiences that were just not possible,

135
00:07:38.870 --> 00:07:42.030
um, in, in those fields today. Um,

136
00:07:42.410 --> 00:07:47.030
and we saw kind of a, a pretty wide range of applications, um,

137
00:07:47.220 --> 00:07:49.990
that varied in the complexity of what it would take to actually solve those.

138
00:07:50.450 --> 00:07:52.710
And what we wanted to do was to commercialize this into a company,

139
00:07:53.050 --> 00:07:57.510
but actually do a bottoms up approach where we could have a huge impact in a

140
00:07:57.511 --> 00:07:59.900
space that was ripe to have an impact at that time,

141
00:08:00.400 --> 00:08:02.500
and then build up off of that and move into other areas.

142
00:08:02.501 --> 00:08:05.100
And entertainment became the place to start mm-hmm &lt;affirmative&gt; because, um,

143
00:08:05.640 --> 00:08:09.420
you had relatively little innovation in a toy space, uh, an entertainment space.

144
00:08:09.421 --> 00:08:13.700
You had these really rich, um, experiences and video games and, uh, and movies,

145
00:08:13.920 --> 00:08:15.460
but there was like this chasm in between.

146
00:08:15.760 --> 00:08:19.460
And so we thought that we could really reinvent that experience.

147
00:08:19.830 --> 00:08:22.730
And there was a, a really fascinating transition,

148
00:08:22.731 --> 00:08:26.090
technically that was happening at the time where the cost of components was

149
00:08:26.091 --> 00:08:29.250
plummeting because of the mobile phone industry and then the smartphone

150
00:08:29.450 --> 00:08:29.990
industry.

151
00:08:29.990 --> 00:08:33.730
And so the cost of a micro controller of a camera of a motor of memory of

152
00:08:34.520 --> 00:08:38.370
microphones cameras was dropping by orders of magnitude mm-hmm &lt;affirmative&gt;.

153
00:08:38.430 --> 00:08:42.240
And then on top of that, with the iPhone coming out in 2000, uh,

154
00:08:42.560 --> 00:08:46.600
I think it was 2007, I believe. Yeah, this is right. Um, you,

155
00:08:47.020 --> 00:08:50.800
it started to become apparent within a couple of years that this could become a

156
00:08:50.801 --> 00:08:55.760
really incredible interface device and the brain with much more computation

157
00:08:55.761 --> 00:08:57.720
behind a physical world experience. Mm-hmm &lt;affirmative&gt;,

158
00:08:57.721 --> 00:09:01.280
that wouldn't have been possible previously. Um, and so, um,

159
00:09:01.780 --> 00:09:06.000
we really got excited about that and how we push all the complexity from the

160
00:09:06.200 --> 00:09:09.200
physical world into software, by using really an expensive components,

161
00:09:09.420 --> 00:09:11.640
but putting huge amounts of complexity into the AI side.

162
00:09:12.020 --> 00:09:13.840
And so Cosmo became our second product.

163
00:09:14.280 --> 00:09:17.510
And then the one that we're probably most proud of the idea there was to create

164
00:09:17.630 --> 00:09:22.310
a physical character that had enough understanding and awareness of the physical

165
00:09:22.311 --> 00:09:26.190
world around it, and the context that mattered to feel like, uh,

166
00:09:26.191 --> 00:09:28.510
like he was alive. Um, and, uh,

167
00:09:28.511 --> 00:09:32.390
to be able to have these like emotional kind of connections and experiences with

168
00:09:32.610 --> 00:09:35.820
people that you would typically only find, uh, inside of a movie.

169
00:09:36.000 --> 00:09:40.420
And the motivation very much was, was Pixar. Like we had an incredible, uh,

170
00:09:40.690 --> 00:09:43.340
respect and appreciation for what they were able to, um,

171
00:09:43.350 --> 00:09:46.180
build in this like really beautiful fashion and film. Um,

172
00:09:46.240 --> 00:09:49.340
but it was always like a, you know, one, it was virtual and two,

173
00:09:49.640 --> 00:09:52.380
it was like a story on rails that had no interactivity to it.

