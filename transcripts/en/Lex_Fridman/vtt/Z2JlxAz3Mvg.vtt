WEBVTT

1
00:00:03.020 --> 00:00:05.480
<v 0>Let me ask a bit of a human question. Hmm.</v>

2
00:00:07.230 --> 00:00:11.960
Charles Hoskinson someone you've worked with in the early days of

3
00:00:11.961 --> 00:00:12.794
Ethereum,

4
00:00:13.010 --> 00:00:17.480
there appears to my outsider view to have been a bit of a falling out.

5
00:00:18.140 --> 00:00:18.973
Is there positive,

6
00:00:19.470 --> 00:00:23.430
inspiring human story to be told about why two part of ways?

7
00:00:26.790 --> 00:00:30.350
<v 1>I kind of wants to let the various books about Ethereum speak for themselves.</v>

8
00:00:31.150 --> 00:00:34.790
Um, but you know, I feel like, you know,

9
00:00:35.160 --> 00:00:38.750
since that time, I think, uh, you know, Charles has, uh, clearly

10
00:00:41.510 --> 00:00:43.820
progressed into matured in a lot is,

11
00:00:44.000 --> 00:00:48.300
and people who follow Charles closely have definitely told me that, you know,

12
00:00:48.301 --> 00:00:49.060
like 20,

13
00:00:49.060 --> 00:00:52.980
21 Charles is very different from my 2014 Charles and I'm sure 2021 Vitalic is

14
00:00:52.981 --> 00:00:55.060
much, uh, different from 2014 Vitalic as well.

15
00:00:55.720 --> 00:00:57.620
<v 0>I'm kind of interested how the 20,</v>

16
00:00:57.621 --> 00:01:00.620
30 and 2040 Vitalic in Charles look like as well.

17
00:01:01.220 --> 00:01:02.180
<v 1>Oh, interesting. &lt;laugh&gt;.</v>

18
00:01:02.560 --> 00:01:03.860
<v 0>The progression of the humans.</v>

19
00:01:04.510 --> 00:01:07.650
<v 1>Is this going to be one of those things where like everyone comes full circle</v>

20
00:01:07.750 --> 00:01:11.090
and then 20, 30 vial and Charles are best friends? Yeah. Um, I mean.

21
00:01:11.550 --> 00:01:16.050
<v 0>Not necessarily best friends, but some kind of, uh, um,</v>

22
00:01:16.450 --> 00:01:19.050
mm-hmm &lt;affirmative&gt; are able to reminisce in ways that is, um,

23
00:01:19.530 --> 00:01:22.650
mm-hmm &lt;affirmative&gt; that puts some of the tension of the past behind, I.

24
00:01:22.650 --> 00:01:26.760
<v 1>Think such things are possible. I, um, think, uh, you know,</v>

25
00:01:26.860 --> 00:01:30.480
people definitely absolutely have a right to, and, uh,

26
00:01:31.040 --> 00:01:34.960
I think should strive to this constantly change and reinvent themselves. Um.

27
00:01:35.940 --> 00:01:39.600
<v 0>Is there something you could say about your thoughts about the Cardon project</v>

28
00:01:40.070 --> 00:01:43.800
that, uh, Charles Hoskinson leads they've um, they've,

29
00:01:43.950 --> 00:01:46.950
they've worked on some interesting ideas. Mm-hmm &lt;affirmative&gt; that, um,

30
00:01:47.530 --> 00:01:51.430
mirror some of the ideas in Ethereum mm-hmm &lt;affirmative&gt; proof of stake, uh,

31
00:01:51.431 --> 00:01:56.110
working on, um, uh, smart contracts and all those kinds of things. Is,

32
00:01:56.130 --> 00:01:59.790
is there something, again, uh, positive, inspiring that you could say,

33
00:02:00.170 --> 00:02:02.990
are they a competitor? Is it a complimentary technology?

34
00:02:04.060 --> 00:02:07.180
<v 1>It's, uh, there's definitely interesting ideas in there. I mean,</v>

35
00:02:07.220 --> 00:02:11.420
I do think Cardon takes a bit of a different approach to, than Ethereum in that,

36
00:02:11.421 --> 00:02:15.220
you know, they really emphasize having these big academic proofs for everything.

37
00:02:15.780 --> 00:02:20.500
Um, whereas Ethereum tends to be more okay with heuristic arguments and in part,

38
00:02:20.501 --> 00:02:23.940
because it's just trying to do more faster. Um, but you know,

39
00:02:23.941 --> 00:02:28.050
there's definitely theory and interesting things that come out of, um, you know,

40
00:02:28.170 --> 00:02:30.690
I H K research. And so is there.

41
00:02:30.870 --> 00:02:33.810
<v 0>Can you comment on that kind of idea, I, as sort of, uh,</v>

42
00:02:34.270 --> 00:02:36.570
having a foot in research enjoy,

43
00:02:36.960 --> 00:02:41.130
Charles's kind of emphasis on papers and like deep academic rigor,

44
00:02:41.790 --> 00:02:42.190
is there,

45
00:02:42.190 --> 00:02:47.160
what's the role of deep research rigor in the world of the currency?

46
00:02:47.880 --> 00:02:50.680
<v 1>Interesting. I'm actually the sort of person who thinks deep rigor is overrated.</v>

47
00:02:52.080 --> 00:02:56.440
Um, the reason why I think deep rigor is overrated is because I think like the,

48
00:02:56.880 --> 00:02:59.760
the, in terms of like, why protocols fail.

49
00:03:00.080 --> 00:03:04.680
I think the number of failures or that are outside the model is even more

50
00:03:04.681 --> 00:03:07.640
important is like bigger and more important than the failures that are inside

51
00:03:07.641 --> 00:03:11.560
the model. Right? So like if you take selfish mining, for example, like the,

52
00:03:12.310 --> 00:03:17.120
that original discovery from 2013 that showed how, um,

53
00:03:18.780 --> 00:03:23.230
Bitcoin does, like, even if it has a 50% of fault tolerance,

54
00:03:23.470 --> 00:03:25.910
assuming everyone's honest, it only has a yeah. You know,

55
00:03:26.180 --> 00:03:30.990
zero to 33% fault tolerance, depending on your network model, if you assume, uh,

56
00:03:31.110 --> 00:03:34.030
rational actors. And like, to me, that was an,

57
00:03:34.340 --> 00:03:37.230
that was a great example of like an outside the model failure, right.

58
00:03:37.231 --> 00:03:42.060
Because traditional consensus research just up until or before the, uh,

59
00:03:42.061 --> 00:03:45.940
blockchain days did not think about like incentivization much, right?

60
00:03:46.500 --> 00:03:48.700
Like there was a little bit of thought about incentivization.

61
00:03:48.701 --> 00:03:52.140
There's like a couple of papers on the visit and Altru rational model,

62
00:03:52.540 --> 00:03:56.100
but it wasn't that deep, it was mostly operating under the assumption that,

63
00:03:56.480 --> 00:04:00.090
you know, this we're gonna make consensus between 15 and or disciplines,

64
00:04:00.091 --> 00:04:03.890
and these are institutions and if something goes wrong, then, you know,

65
00:04:03.891 --> 00:04:07.050
if it was, we can figure out whether or not it was deliberate, offline,

66
00:04:07.210 --> 00:04:09.770
and if they did something evil, we can Sue them. Whereas, you know,

67
00:04:09.810 --> 00:04:11.330
in the crypto world, you can't do that. Right.

68
00:04:11.670 --> 00:04:16.490
And so like that whole discovery basically arose just because like, you know,

69
00:04:16.670 --> 00:04:19.890
the model of, uh, traditional, uh, consensus research,

70
00:04:20.240 --> 00:04:22.760
just like didn't cover the responsibilities. And then of like,

71
00:04:22.761 --> 00:04:26.480
once you go out of the model, those like other issues do exist. Right. Um, so,

72
00:04:27.100 --> 00:04:30.280
but then at the same time, like there definitely are, um,

73
00:04:30.680 --> 00:04:35.000
protocols that turn out to be ins that do have failures inside the model.

74
00:04:35.150 --> 00:04:39.360
Like this reminds me of, uh, the time when, uh, I, like I found a yeah.

75
00:04:39.460 --> 00:04:43.750
Bug in a proposed, uh, consensus implementation from, uh,

76
00:04:43.751 --> 00:04:47.830
either shares or EOS, this happened around the end of 2017. Um,

77
00:04:48.290 --> 00:04:52.550
so that was definitely inside the model because like they had a very clear idea

78
00:04:52.551 --> 00:04:55.750
of what they were trying to achieve. They had a very clear description and like,

79
00:04:55.751 --> 00:04:57.430
there's a very clear mathematical, um,

80
00:04:57.670 --> 00:04:59.910
argument for why the description doesn't lead to what they're trying to achieve.

81
00:05:00.230 --> 00:05:03.700
But like ultimately what you're trying to achieve can never be fully math

82
00:05:03.810 --> 00:05:08.300
described in formal language. Right? Like I, this is the big discovery of, um,

83
00:05:08.301 --> 00:05:12.540
you know, the AI safety people, for example, right. Like just having a,

84
00:05:13.100 --> 00:05:16.340
a specification of what you want is an insanely hard problem.

85
00:05:16.920 --> 00:05:18.620
And like the more powerful,

86
00:05:18.880 --> 00:05:21.180
the optimizer that you're giving the instructions to,

87
00:05:21.181 --> 00:05:25.770
the more you have to be careful. Uh, and so, you know,

88
00:05:25.810 --> 00:05:29.250
I think there are kind of these two sides.

89
00:05:29.790 --> 00:05:33.250
And then the other thing is that a lot,

90
00:05:33.530 --> 00:05:37.850
like a lot of the academic approach ends up like basically optimizing for other

91
00:05:37.851 --> 00:05:42.010
people inside of the academic system. Right. And it doesn't really optimize for,

92
00:05:42.360 --> 00:05:44.760
or like curious outsiders.

93
00:05:44.761 --> 00:05:48.120
Whereas like I personally met like totally optimized for curious outsiders,

94
00:05:48.121 --> 00:05:51.000
or at least I, I feel like I strive to. So I guess, like,

95
00:05:51.100 --> 00:05:55.000
that's my case for why I, uh,

96
00:05:55.680 --> 00:05:58.360
like tends to behave in ways that, you know,

97
00:05:58.800 --> 00:06:02.160
occasionally traditional academic types, criticizes being reckless. Um,

98
00:06:02.340 --> 00:06:05.720
but I mean, on the other hand, you know, there's, I mean,

99
00:06:05.910 --> 00:06:08.440
there's definitely real benefits that come from,

100
00:06:08.750 --> 00:06:13.200
like just taking a, a rigorous approach,

101
00:06:13.210 --> 00:06:17.270
especially when, you know, you know, what, the thing that, like, you know,

102
00:06:17.271 --> 00:06:20.670
what the specification is of what you're trying to get. And like,

103
00:06:20.671 --> 00:06:25.230
you're trying to kind of improve your way or provide protocols that actually

104
00:06:25.231 --> 00:06:27.630
provide that. And like, you know exactly what you're looking for.

105
00:06:28.030 --> 00:06:29.830
I feel like realistically,

106
00:06:30.130 --> 00:06:34.270
you probably wants to do both kinds of analysis and like sometimes even wanna do

107
00:06:34.271 --> 00:06:36.590
both kinds of analysis and stages, right? Like you have,

108
00:06:37.020 --> 00:06:40.540
you want to do more quick and dirty things and even watch public feedback on the

109
00:06:40.541 --> 00:06:41.221
quick and dirty stuff.

110
00:06:41.221 --> 00:06:44.860
And then later on you formalize it more and then you get more feedback. Um,

111
00:06:45.690 --> 00:06:46.523
like in general,

112
00:06:46.700 --> 00:06:51.460
I guess I feel like the norms of a research in the future.

113
00:06:51.690 --> 00:06:54.620
Like there, it, the internet has just changed so much.

114
00:06:54.621 --> 00:06:57.260
There's no way that it's not going. Uh, and you know, it's, it's even,

115
00:06:57.460 --> 00:07:01.490
she changed like collaboration structures and like the patterns in which we work

116
00:07:01.491 --> 00:07:02.324
with each other.

117
00:07:02.480 --> 00:07:07.450
There's no way that the correct structure for collaborative research is

118
00:07:07.451 --> 00:07:09.210
the same as what it was 15 years ago.

119
00:07:09.211 --> 00:07:14.010
But like what combination of these existing components and of new

120
00:07:14.180 --> 00:07:16.170
ideas, it is like, that's something that's, you know,

121
00:07:16.320 --> 00:07:19.360
totally legitimates that kind of fight it out.

122
00:07:19.361 --> 00:07:21.080
And I think it's great that there's, uh,

123
00:07:21.081 --> 00:07:23.800
different ecosystems that have different attitudes to things. Like, I think,

124
00:07:24.060 --> 00:07:27.880
you know, there's a big possibility that, you know, things that the Ethereum,

125
00:07:28.240 --> 00:07:31.000
uh, ways that the Ethereum ecosystem approaches some problems is totally wrong.

126
00:07:31.240 --> 00:07:34.560
And if there's other ecosystems or different principles, then they can do well.

127
00:07:34.561 --> 00:07:35.680
That's something that we can learn from.

