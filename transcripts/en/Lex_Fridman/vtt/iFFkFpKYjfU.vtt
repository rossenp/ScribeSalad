WEBVTT

1
00:00:03.080 --> 00:00:05.570
<v 0>What is harder to solve vision or language,</v>

2
00:00:05.910 --> 00:00:08.490
visual intelligence or linguistic intelligence.

3
00:00:08.870 --> 00:00:10.730
<v 1>So I'm going to say computer vision is harder.</v>

4
00:00:10.950 --> 00:00:13.490
My reason for this is basically that, uh,

5
00:00:14.210 --> 00:00:17.890
language of course has a big structure to it because we developed it. Uh,

6
00:00:17.891 --> 00:00:20.730
whereas vision is something that is common in a lot of animals.

7
00:00:21.250 --> 00:00:22.410
Everyone is able to get by.

8
00:00:22.570 --> 00:00:25.600
A lot of these animals on earth are actually able to get by without language

9
00:00:26.080 --> 00:00:27.600
mm-hmm &lt;affirmative&gt;. And we, a lot of these animals,

10
00:00:27.601 --> 00:00:31.240
we also deem to be intelligent. So clearly intelligence, uh,

11
00:00:31.430 --> 00:00:34.600
does have like a visual component to it. And yes, of course,

12
00:00:34.601 --> 00:00:36.960
in the case of humans, it, of course also has a linguistic component,

13
00:00:37.500 --> 00:00:40.880
but it means that there is something far more fundamental about vision than

14
00:00:40.881 --> 00:00:44.470
there is about language. And I'm sorry to anyone disagrees, but yes,

15
00:00:44.471 --> 00:00:45.304
this is what I feel.

16
00:00:45.650 --> 00:00:48.790
<v 0>So that's being a little bit reflected in, um,</v>

17
00:00:49.050 --> 00:00:51.110
the challenges that have to do with the,

18
00:00:51.590 --> 00:00:53.470
the progress of self supervised learning. Would you say,

19
00:00:53.610 --> 00:00:58.390
or is that just the peculiar accidents of the progress of the AI community

20
00:00:58.460 --> 00:01:03.070
that we focused on Lang or we discovered self attention and transformers in the

21
00:01:03.071 --> 00:01:04.030
context of language for.

22
00:01:05.020 --> 00:01:08.220
<v 1>So like the self supervised learning success was actually, uh,</v>

23
00:01:08.480 --> 00:01:11.060
for vision has not much to do with the transformers part.

24
00:01:11.140 --> 00:01:13.100
I would say it's actually been independent a little bit.

25
00:01:13.740 --> 00:01:17.300
I think it's just that the signal was a little bit different for, uh,

26
00:01:17.320 --> 00:01:21.100
vision than there was for like NLP and probably NLP. Yeah. Folks, uh,

27
00:01:21.380 --> 00:01:22.860
discovered it before. So for vision,

28
00:01:22.920 --> 00:01:26.090
the main success has basically been in this like crops so far mm-hmm,

29
00:01:26.170 --> 00:01:28.850
&lt;affirmative&gt; like taking different crops of images. Uh, whereas for NLP,

30
00:01:28.930 --> 00:01:30.330
it was this masking thing, but.

31
00:01:30.330 --> 00:01:33.210
<v 0>Also the level of success is still much higher for language. Yes.</v>

32
00:01:33.210 --> 00:01:36.210
<v 1>It has. So that has a lot to do with, I mean,</v>

33
00:01:36.850 --> 00:01:39.690
I can get into a lot of details for this particular question. Let's go for it.

34
00:01:39.691 --> 00:01:43.250
Okay. So the first thing is language is very structured.

35
00:01:43.251 --> 00:01:46.600
So you are going to produce a distribu over a finite vocabulary.

36
00:01:47.040 --> 00:01:48.720
Mm-hmm &lt;affirmative&gt; English has a finite number of words.

37
00:01:48.790 --> 00:01:50.600
It's actually not that large. Uh,

38
00:01:50.620 --> 00:01:53.920
and you need to produce basically when you're doing this masking thing,

39
00:01:53.921 --> 00:01:57.080
all you need to do is basically tell me which one of these like 50,000 words it

40
00:01:57.081 --> 00:02:00.880
is. Yeah. That's it now for vision, let's imagine doing the same thing. Okay.

41
00:02:00.881 --> 00:02:04.280
We are basically going to blank out a particular part of the image and we ask

42
00:02:04.281 --> 00:02:08.270
the network or this neural to predict what is present in this missing patch.

43
00:02:09.220 --> 00:02:13.150
It's combinatory large, right? You have 256 pixel values.

44
00:02:13.690 --> 00:02:17.150
If you're even producing basically a seven cross seven or a 14 cross 14,

45
00:02:17.260 --> 00:02:21.990
like window of pixels at each of these 169 or each of these 49

46
00:02:22.190 --> 00:02:25.390
locations, you have 256 values to predict. Yeah. And so it's really,

47
00:02:25.391 --> 00:02:30.300
really large and very quickly the kind of like prediction problems that

48
00:02:30.301 --> 00:02:33.460
we are setting up are going to be extremely like intractable for us.

49
00:02:33.880 --> 00:02:35.180
And so the thing is for NLP,

50
00:02:35.181 --> 00:02:38.700
it has been really successful because we are very good at predicting,

51
00:02:38.701 --> 00:02:41.460
like doing this like distribution over a finite set.

52
00:02:42.000 --> 00:02:44.860
And the problem is when this set becomes really large, we are,

53
00:02:44.861 --> 00:02:46.140
we are going to become really,

54
00:02:46.141 --> 00:02:50.690
really bad at making these predictions and at solving basically this particular

55
00:02:50.790 --> 00:02:51.850
set of problems. Mm-hmm &lt;affirmative&gt;.

56
00:02:52.230 --> 00:02:56.250
So if you were to do it exactly in the same way as NLP for vision,

57
00:02:56.890 --> 00:02:57.890
there is very limited success.

58
00:02:58.230 --> 00:03:02.360
The way stuff is working right now is actually not by predicting these masks.

59
00:03:02.790 --> 00:03:05.840
It's basically by saying that you take these two, like crops from the image,

60
00:03:06.260 --> 00:03:07.880
you get a feature representation from it.

61
00:03:08.220 --> 00:03:09.680
And just saying that these two features,

62
00:03:09.900 --> 00:03:13.200
so they're like vectors just saying that the distance between these vectors

63
00:03:13.201 --> 00:03:17.480
should be small. And so it's a very different way of learning, uh,

64
00:03:17.710 --> 00:03:20.590
from the visual signal, then there is from NLP. Okay.

65
00:03:20.591 --> 00:03:23.590
The other reason is the distribution hypothesis that we talked about for NLP,

66
00:03:23.591 --> 00:03:26.030
right? So a word given its context,

67
00:03:26.670 --> 00:03:29.150
basically the context actually supplies a lot of meaning to the word mm-hmm

68
00:03:29.190 --> 00:03:33.350
&lt;affirmative&gt; now, because there are just finite number, finite number of words.

69
00:03:33.370 --> 00:03:35.870
And there is a finite way in like, which we compose them.

70
00:03:36.850 --> 00:03:38.630
Of course the same thing, hold for pixels,

71
00:03:38.631 --> 00:03:40.940
but in language there's a lot of structure, right?

72
00:03:40.941 --> 00:03:43.980
So I always say whatever the dash jumped over the fence, for example,

73
00:03:44.830 --> 00:03:48.660
there are lots of these sentences that you'll get. And from this,

74
00:03:48.720 --> 00:03:51.740
you can actually look at this particular sentence might occur in a lot of

75
00:03:51.741 --> 00:03:52.620
different context as well.

76
00:03:52.820 --> 00:03:54.700
This exact same sentence might occur in a different context.

77
00:03:55.040 --> 00:03:58.140
So the sheep jumped over the fence, the car jumped over the fence, it talk,

78
00:03:58.141 --> 00:04:02.050
jumped over the fence. So you immediately get a lot of these words, which are,

79
00:04:02.240 --> 00:04:05.410
because this particular token itself has so much meaning you get a lot of these

80
00:04:05.550 --> 00:04:08.050
tokens or these words, which are actually going to have a,

81
00:04:08.320 --> 00:04:11.090
have sort of this related meaning across given this context.

82
00:04:11.520 --> 00:04:15.210
Whereas for vision it's much harder because just by like pure,

83
00:04:15.211 --> 00:04:18.330
like the way we capture images, lighting can be different. Um,

84
00:04:18.420 --> 00:04:20.440
there might be like different noise and the sensor.

85
00:04:20.900 --> 00:04:23.280
So the thing is you're capturing a physical phenomenon.

86
00:04:23.340 --> 00:04:26.800
And then you're basically going through a very complicated pipeline of like

87
00:04:26.801 --> 00:04:27.521
image processing.

88
00:04:27.521 --> 00:04:31.200
And then you're translating that into some kind of like digital signal mm-hmm

89
00:04:31.280 --> 00:04:35.640
&lt;affirmative&gt; whereas with language you write it down and you transfer it to a

90
00:04:35.641 --> 00:04:37.840
digital signal, almost like it's a lossless like transfer.

91
00:04:38.580 --> 00:04:41.550
And each of these tokens are very, very well. If find there.

92
00:04:41.550 --> 00:04:46.550
<v 0>Could be a little bit of an argument there because language as written down</v>

93
00:04:47.330 --> 00:04:49.430
is a projection of thought,

94
00:04:50.580 --> 00:04:55.550
this is one of the open questions is if you perfectly can solve

95
00:04:56.030 --> 00:05:00.150
language, are you getting close to being able to solve, you know,

96
00:05:00.290 --> 00:05:03.940
easily with flying colors, past the touring test kind of thing. Right?

97
00:05:03.960 --> 00:05:08.180
So that's, it's similar, uh, but different. And, uh,

98
00:05:08.181 --> 00:05:12.540
the computer vision problem is in the 2d plane is a projection of a three

99
00:05:12.980 --> 00:05:16.620
dimensional world. So perhaps there's similar, uh, uh, similar problems there,

100
00:05:16.670 --> 00:05:17.180
maybe.

101
00:05:17.180 --> 00:05:20.540
<v 1>This, I think what I'm saying is NLP is not easy. Of course don't get me wrong.</v>

102
00:05:20.541 --> 00:05:23.810
Like I abstract thought expressed in knowledge, uh,

103
00:05:24.070 --> 00:05:27.370
or knowledge basically expressed in language is really hard to understand,

104
00:05:27.570 --> 00:05:30.770
right? I mean, we've been communicating with language for so long and it's,

105
00:05:30.870 --> 00:05:34.490
it is of course a very complicated concept. The thing is, uh,

106
00:05:34.830 --> 00:05:38.130
at least getting like some somewhat reasonable, um,

107
00:05:38.360 --> 00:05:42.010
like being able to solve some kind of reasonable tasks with language, I,

108
00:05:42.160 --> 00:05:44.320
I would say slightly easier than it is with computer vision.

109
00:05:44.710 --> 00:05:47.560
<v 0>Yeah. I would say, yeah, so that that's well put,</v>

110
00:05:47.800 --> 00:05:52.680
I would say getting impressive performance on language is, uh,

111
00:05:52.681 --> 00:05:56.360
easier there. I feel like for both language and computer vision,

112
00:05:56.361 --> 00:06:01.120
there's going to be this wall of like that you like, uh,

113
00:06:01.390 --> 00:06:06.360
this hump you have to overcome to achieve superhuman level performance or human

114
00:06:06.361 --> 00:06:11.000
level performance. And I feel like for language, it, that wall is farther away.

115
00:06:11.300 --> 00:06:14.680
So you can get pretty nice. You can, you can do a lot of tricks.

116
00:06:15.180 --> 00:06:20.030
You can show really performance. You can even fool people that you're,

117
00:06:20.230 --> 00:06:24.550
uh, tweeting or you're right. Blog, post writing, or your question answering,

118
00:06:25.550 --> 00:06:27.470
uh, is, has intelligence behind it.

119
00:06:28.130 --> 00:06:32.270
But to truly demonstrate understanding of dialogue,

120
00:06:33.630 --> 00:06:38.180
uh, of continuous long form dialogue that would require perhaps

121
00:06:38.840 --> 00:06:41.180
big breakthroughs in the same way, way in computer vision.

122
00:06:41.660 --> 00:06:46.060
I think the big breakthroughs need to happen earlier to, to achieve, uh,

123
00:06:46.070 --> 00:06:47.220
impressive performance.

