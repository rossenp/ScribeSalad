WEBVTT

1
00:00:00.030 --> 00:00:04.100
<v 0>Dear fellow scholars. This is two minute papers with Dr. Károly Zsolnai-Fehér. Let's ask.</v>

2
00:00:06.080 --> 00:00:10.100
<v 1>To jump into the pool at the same time on three, two,</v>

3
00:00:10.310 --> 00:00:13.730
one go. And then this happens.

4
00:00:14.240 --> 00:00:15.620
And if we slow things down,

5
00:00:15.800 --> 00:00:19.370
like we would slow down an action sequence in a movie. Look,

6
00:00:19.620 --> 00:00:23.330
this is one and then two, and then three,

7
00:00:23.900 --> 00:00:28.430
not even close to being in the same time we see that this footage is

8
00:00:28.431 --> 00:00:33.380
completely unsalvageable. And please note the smile at the end of the video.

9
00:00:33.500 --> 00:00:37.850
I'll tell you in a moment why, imagine that after a little training,

10
00:00:37.920 --> 00:00:41.750
the little chaps were able to jump into the pool at the same time.

11
00:00:42.410 --> 00:00:46.220
Congratulations, but wait a second. Look,

12
00:00:46.520 --> 00:00:49.790
the smile is the same. As in the previous footage,

13
00:00:50.480 --> 00:00:54.140
this is not a different video. This is the same video as before,

14
00:00:54.380 --> 00:00:59.360
but it has been three timed to seem as if the jumps happened at the same

15
00:00:59.361 --> 00:01:04.130
time. Absolutely amazing. And how about this footage?

16
00:01:04.490 --> 00:01:08.120
They move in tandem totally in tandem, right?

17
00:01:09.410 --> 00:01:13.640
Except that this was the original footage, which is a complete mess.

18
00:01:14.360 --> 00:01:19.010
And now with this technique, it could be re timed as if this happened,

19
00:01:19.610 --> 00:01:22.880
incredible work. So what is this wizardry?

20
00:01:23.300 --> 00:01:27.830
This is a new learning based technique that can pull off nice tricks like this,

21
00:01:28.130 --> 00:01:32.600
and it can deal with cases that would otherwise be extremely challenging to read

22
00:01:32.601 --> 00:01:36.710
time by hand, to find out why let's have a look at this footage.

23
00:01:38.090 --> 00:01:42.920
Got it. And now let's try to pretend that this meeting never happened.

24
00:01:43.460 --> 00:01:45.620
Now, first, to be able to do this,

25
00:01:45.830 --> 00:01:48.890
we have to be able to recognize the test subjects of the video.

26
00:01:49.310 --> 00:01:53.930
This method performs pose estimation. These are the skeletons that you see here,

27
00:01:54.440 --> 00:01:59.240
nothing new here. This can be done with off the shelf components. However,

28
00:01:59.300 --> 00:02:03.890
that is not nearly enough to remove or a time them we need to do more.

29
00:02:04.400 --> 00:02:06.920
Why is that? Well, look,

30
00:02:07.370 --> 00:02:09.410
mirror reflections and shadows.

31
00:02:09.980 --> 00:02:12.380
If we will only be able to remove the person,

32
00:02:12.590 --> 00:02:17.240
these secondary effects would give the trick away in a second to address this

33
00:02:17.241 --> 00:02:17.750
issue.

34
00:02:17.750 --> 00:02:22.190
One of the key contributions of this new AI based technique is that it is able

35
00:02:22.191 --> 00:02:26.390
to find these mirror reflections, shadows, and even more,

36
00:02:26.600 --> 00:02:31.460
which can be defined as motions that correlate with a test subject or in

37
00:02:31.461 --> 00:02:34.790
other words, things that move together with the humans.

38
00:02:35.690 --> 00:02:37.940
And if we have all of these puzzle pieces,

39
00:02:38.120 --> 00:02:42.530
we can use a newer render to remove people or even adjust the

40
00:02:42.531 --> 00:02:44.060
timing of these videos.

41
00:02:46.220 --> 00:02:50.990
And now hold onto your papers because it is not at all limited to shadows

42
00:02:51.080 --> 00:02:54.830
and mirror reflections. Remember this example here,

43
00:02:54.860 --> 00:02:59.000
the algorithm recognizes that these people cause deformations in the,

44
00:02:59.980 --> 00:03:02.170
and is able to line them up together.

45
00:03:02.740 --> 00:03:07.420
Note that we need some intense and variable time warping to make this

46
00:03:07.421 --> 00:03:11.790
happen. And as an additional bonus photo bombing,

47
00:03:12.240 --> 00:03:15.300
cumin has been removed from the footage. Then you're a renderer.

48
00:03:15.730 --> 00:03:19.980
This work is from the pigs to pigs paper from only three years ago.

49
00:03:20.280 --> 00:03:22.770
And now with some ingenious improvements,

50
00:03:22.950 --> 00:03:25.290
it can be elevated to a whole new level,

51
00:03:25.710 --> 00:03:30.180
huge congratulations to the authors for this incredible achievement and all of

52
00:03:30.181 --> 00:03:34.740
this can be done in an interactive app that is able to quickly preview the

53
00:03:34.741 --> 00:03:37.380
results for us. What a time to be alive.

54
00:03:37.680 --> 00:03:41.580
What you see here is a report of this exact paper we have talked about,

55
00:03:41.730 --> 00:03:45.660
which was made by weights and biases. I put a link to it in the description,

56
00:03:45.960 --> 00:03:50.160
make sure to have the look. I think it helps you understand this paper better.

57
00:03:50.550 --> 00:03:53.970
During my PhD studies, I trained a ton of neural networks,

58
00:03:54.030 --> 00:03:57.390
which were used in our experiments. However, over time,

59
00:03:57.540 --> 00:04:00.450
there was just too much data in our repositories.

60
00:04:00.540 --> 00:04:03.930
And what I am looking for is not data, but insight.

61
00:04:04.380 --> 00:04:08.400
And that's exactly how weights and biases helps you by organizing your

62
00:04:08.401 --> 00:04:13.020
experiments. It is used by more than 200 companies and research institutions,

63
00:04:13.140 --> 00:04:17.070
including open AI Toyota research GitHub and more,

64
00:04:17.490 --> 00:04:22.410
and get this weights and biases is free for all individuals academics

65
00:04:22.620 --> 00:04:25.920
and open source projects. Make sure to visit them through

66
00:04:28.320 --> 00:04:30.990
wmb.com/papers, or just click the link in the video description.

67
00:04:31.290 --> 00:04:35.580
And you can get the freedom or today our thanks to weights and biases for their

68
00:04:36.180 --> 00:04:39.240
longstanding support and for helping us make better videos for you.

69
00:04:39.540 --> 00:04:43.500
Thanks for watching and for your generous support. And I'll see you next time.

