WEBVTT

1
00:00:00.600 --> 00:00:01.433
<v 0>The fellow scholars,</v>

2
00:00:01.710 --> 00:00:06.210
this is too many papers with Dr. Károly Zsolnai-Fehér in computer graphics research.

3
00:00:06.390 --> 00:00:09.240
We spend most of our time dealing with images.

4
00:00:09.840 --> 00:00:13.080
An image is a bunch of pixels put onto a 2d plane,

5
00:00:13.350 --> 00:00:15.450
which is a tiny window into reality,

6
00:00:15.780 --> 00:00:18.690
but reality is inherently 3d.

7
00:00:19.230 --> 00:00:23.220
This is easy to understand for us because if we look at the flat image,

8
00:00:23.460 --> 00:00:27.840
we see the geometric structures that it depicts. If we look at this image,

9
00:00:27.990 --> 00:00:31.620
we know that this is not a sticker, but a three-dimensional fluid domain.

10
00:00:32.220 --> 00:00:37.020
If I would freeze an image and ask a human to imagine rotating around this

11
00:00:37.021 --> 00:00:41.430
fluid domain, that human will do a pretty good job at that. However,

12
00:00:41.460 --> 00:00:42.750
for a computer algorithm,

13
00:00:42.930 --> 00:00:47.340
it would be extremely difficult to extract the 3d structure out from this image.

14
00:00:47.880 --> 00:00:52.500
So can we use these shiny new neural network based learning algorithms to

15
00:00:52.501 --> 00:00:55.500
accomplish something like this? Well,

16
00:00:55.590 --> 00:01:00.330
have a look at this new technique that takes a 2d image as an input and tries to

17
00:01:00.331 --> 00:01:01.710
guess three things.

18
00:01:02.100 --> 00:01:06.210
The cool thing is that the geometry problem we talked about is just the first

19
00:01:06.211 --> 00:01:08.340
one beyond that too.

20
00:01:08.610 --> 00:01:13.020
It also guesses what the lighting configuration is that leads to an appearance

21
00:01:13.021 --> 00:01:14.550
like this. And three,

22
00:01:14.820 --> 00:01:18.060
it also produces the texture map for an object as well.

23
00:01:18.570 --> 00:01:21.870
This would already be great, but wait, there's more.

24
00:01:22.470 --> 00:01:25.140
If we plug all this into a rendering program,

25
00:01:25.410 --> 00:01:30.390
we can also specify a camera position and this position can be different

26
00:01:30.420 --> 00:01:33.510
from the one that was used to take this input image.

27
00:01:34.110 --> 00:01:36.840
So what does that mean? Exactly? Well,

28
00:01:36.900 --> 00:01:41.760
it means that maybe it can not only reconstruct the geometry light

29
00:01:42.060 --> 00:01:43.410
and texture of the object,

30
00:01:43.800 --> 00:01:48.570
but even put this all together and make a photo of it from a novel

31
00:01:48.571 --> 00:01:52.170
viewpoint. Wow. Let's have a look at an example.

32
00:01:52.800 --> 00:01:56.460
There's a lot going on in this image. So let me try to explain how to read it.

33
00:01:57.090 --> 00:02:01.560
This image is the input photo and the white silhouette image is called a mask,

34
00:02:01.740 --> 00:02:06.360
which can either be given with the image or be approximated by already

35
00:02:06.361 --> 00:02:10.110
existing methods. This is the reconstructed image by this technique.

36
00:02:10.680 --> 00:02:15.480
And then this is a previous method from 2018 by the name category

37
00:02:15.481 --> 00:02:18.660
specific mesh reconstruction CMR in short,

38
00:02:19.530 --> 00:02:22.950
and now hold onto your papers because in the second row,

39
00:02:23.300 --> 00:02:24.121
you'll see this technique,

40
00:02:24.121 --> 00:02:28.050
creating images of this bird from different novel view points.

41
00:02:28.950 --> 00:02:32.010
How cool is that? Absolutely amazing.

42
00:02:32.670 --> 00:02:35.100
Since we can render this bird from any viewpoint,

43
00:02:35.370 --> 00:02:40.230
we can even create a turntable video of it and all of this from just

44
00:02:40.231 --> 00:02:41.370
one input photo.

45
00:02:44.220 --> 00:02:48.060
Let's have a look at another example here. You'll see how it puts together.

46
00:02:48.061 --> 00:02:52.680
The final car rendering in the first column from the individual elements like

47
00:02:52.681 --> 00:02:55.020
geometry texture and lighting

48
00:02:57.210 --> 00:03:01.480
the editor comparisons in the paper reveal that this technique is indeed a huge

49
00:03:01.481 --> 00:03:05.500
step up from previous works. Now, all this sounds great,

50
00:03:05.770 --> 00:03:08.740
but what is all this use for? What are some example,

51
00:03:08.741 --> 00:03:13.690
applications of this 3d object from 2d image thing? Well,

52
00:03:13.750 --> 00:03:17.800
techniques like this can be a great deal of help in enhancing the depth

53
00:03:17.801 --> 00:03:20.620
perception, capabilities of robots. And of course,

54
00:03:20.770 --> 00:03:24.820
whenever we would like to build a virtual world creating a 3d version of

55
00:03:24.821 --> 00:03:28.930
something, we only have a picture of can get extremely laborious.

56
00:03:29.290 --> 00:03:32.950
This could have a great deal with that too. For this application,

57
00:03:33.010 --> 00:03:37.210
we could quickly get a starting point with some texture information and get an

58
00:03:37.240 --> 00:03:39.400
artist to fill in the fine details.

59
00:03:39.670 --> 00:03:41.830
This might get addressed in a follow-up paper.

60
00:03:42.370 --> 00:03:46.570
And if you are worried about the slight discoloration around the beak area of

61
00:03:46.571 --> 00:03:51.280
this bird, do not despair. As we always say, two more papers down the line,

62
00:03:51.490 --> 00:03:55.870
and this will likely be improved significantly. What a time to be alive.

63
00:03:56.260 --> 00:04:00.550
This episode has been supported by Lambda. If you're a researcher or a startup,

64
00:04:00.730 --> 00:04:03.820
looking for cheap GPU compute to run these algorithms,

65
00:04:03.970 --> 00:04:07.630
check out Lambda GPU cloud. I've talked about Lambdas,

66
00:04:07.631 --> 00:04:09.640
GPU workstations in other videos,

67
00:04:09.850 --> 00:04:13.840
and I'm happy to tell you that they are offering GPU cloud services as well.

68
00:04:14.050 --> 00:04:18.940
The Lambda GPU cloud can train image net to 93% accuracy for

69
00:04:18.941 --> 00:04:20.710
less than $19.

70
00:04:21.700 --> 00:04:25.600
Lambda's web based IDE lets you easily access your instance right in your

71
00:04:25.601 --> 00:04:26.350
browser.

72
00:04:26.350 --> 00:04:31.150
And finally hold onto your papers because the Lambda GPU cloud costs less

73
00:04:31.151 --> 00:04:33.730
than half of AWS and Azure.

74
00:04:34.030 --> 00:04:38.710
Make sure to go to Lambda labs.com/papers and sign up for one of their

75
00:04:38.711 --> 00:04:40.450
amazing GPU instances today.

76
00:04:40.980 --> 00:04:43.990
Thanks to Lambda for helping us make better videos for you.

77
00:04:44.260 --> 00:04:48.190
Thanks for watching and for your generous support. And I'll see you next time.

