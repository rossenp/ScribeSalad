WEBVTT

1
00:00:00.480 --> 00:00:01.320
<v 0>Dear fellow scholars.</v>

2
00:00:01.590 --> 00:00:05.880
This is two minute papers with Dr. Carriage on IFA here in 2017.

3
00:00:06.000 --> 00:00:08.340
So more than 300 episodes ago,

4
00:00:08.520 --> 00:00:13.410
we talked about an algorithm that took a 3d model of a complex object and

5
00:00:13.550 --> 00:00:17.910
would give us an easy to follow step-by-step breakdown on how to draw it

6
00:00:18.360 --> 00:00:20.400
automated drawing tutorials. If you will.

7
00:00:20.880 --> 00:00:25.230
This was a hand-crafted algorithm that used the graph theory to break these 3d

8
00:00:25.231 --> 00:00:28.050
objects into smaller, easier to manage pieces.

9
00:00:28.290 --> 00:00:33.240
And since then learning algorithms have improved so much that we started looking

10
00:00:33.241 --> 00:00:35.400
more and more to the opposite direction,

11
00:00:35.850 --> 00:00:40.080
and that opposite direction would be giving a crude drawing to the machine and

12
00:00:40.081 --> 00:00:41.940
getting a photo realistic image.

13
00:00:42.480 --> 00:00:47.310
Now that sounds like science fiction until we realize that scientists

14
00:00:47.370 --> 00:00:52.050
at Nvidia already had an amazing algorithm for this around one and a half years

15
00:00:52.051 --> 00:00:56.460
ago in that work, the input was a labeling, which we can draw ourselves.

16
00:00:56.640 --> 00:01:00.990
And the output is a hopefully photo realistic landscape image that adheres to

17
00:01:00.991 --> 00:01:05.550
these labels. I love how first only the silhouette of the rock is drawn.

18
00:01:05.850 --> 00:01:09.420
So we have this hollow thing on the right that is not very realistic.

19
00:01:09.660 --> 00:01:14.430
And then it is now filled in with a Bucca tool. And there you go.

20
00:01:14.910 --> 00:01:18.570
And next thing you know, you have an amazing looking landscape image.

21
00:01:19.020 --> 00:01:21.840
It was capable of much, much more bat.

22
00:01:21.870 --> 00:01:26.790
What it couldn't do is synthesize human faces this way and believe it or

23
00:01:26.791 --> 00:01:31.620
not, this is what today's technique is able to do. Look in goals,

24
00:01:31.860 --> 00:01:36.630
our crudes catch as a guide image and outcomes and nearly realistic human

25
00:01:36.631 --> 00:01:41.340
face that matches it. Interestingly, before we draw the hair itself,

26
00:01:41.730 --> 00:01:45.390
it gives us something as a starting point, but if we choose to,

27
00:01:45.600 --> 00:01:50.280
we can also change the hair shape and the outputs will follow our drawing really

28
00:01:50.281 --> 00:01:53.130
well, but it goes much further than this,

29
00:01:53.310 --> 00:01:57.060
as it bows a few additional appealing features. For instance,

30
00:01:57.180 --> 00:02:00.570
it not only refines the output as we change our drawing,

31
00:02:00.810 --> 00:02:05.250
but since one crude input can be mapped to many, many possible people.

32
00:02:05.490 --> 00:02:09.630
These output images can also be further, are directed with these sliders.

33
00:02:10.140 --> 00:02:11.970
According to the included user study,

34
00:02:12.120 --> 00:02:16.530
journeyman users mainly appreciated the variety they can achieve with this

35
00:02:16.531 --> 00:02:19.830
algorithm. If you look here, you can get a taste of that.

36
00:02:20.100 --> 00:02:24.690
While professionals were more excited about the controllability aspect of this

37
00:02:24.691 --> 00:02:27.750
method. That's what showcase with the footage with the sliders.

38
00:02:28.500 --> 00:02:32.550
Another really cool thing that it can do is called face copy paste,

39
00:02:32.760 --> 00:02:37.290
where we don't even need to draw anything and just take a few aspects of human

40
00:02:37.291 --> 00:02:39.960
faces that we would like to combine. And

41
00:02:41.820 --> 00:02:44.370
there you go, absolutely amazing.

42
00:02:44.820 --> 00:02:48.840
This work is not without failure cases. However you have probably noticed,

43
00:02:48.870 --> 00:02:53.700
but the AI is not explicitly instructed to match the eye Connors where some

44
00:02:53.730 --> 00:02:57.900
asymmetry may arise in the output. I am sure this will be improved.

45
00:02:57.930 --> 00:02:59.650
Just one more paper, the line.

46
00:02:59.800 --> 00:03:03.520
And I am really curious where digital artists will take these techniques in the

47
00:03:03.521 --> 00:03:04.354
near future.

48
00:03:04.600 --> 00:03:09.100
The objective is always to get out of the way and have the artists spend more

49
00:03:09.101 --> 00:03:13.540
time bringing their artistic vision to life and spend less time on the

50
00:03:13.541 --> 00:03:17.350
execution. This is exactly what these techniques can help with.

51
00:03:17.800 --> 00:03:19.270
What a time to be alive.

52
00:03:19.600 --> 00:03:24.130
What you see here is an instrumentation for a previous paper that we covered in

53
00:03:24.131 --> 00:03:27.040
this series, which was made by weights and biases.

54
00:03:27.460 --> 00:03:31.810
I think organizing these experiments really showcases the usability of their

55
00:03:31.811 --> 00:03:36.340
system weights and biases provides tools to track your experiments in your deep

56
00:03:36.341 --> 00:03:40.930
learning projects. Their system is designed to save you a ton of time and money,

57
00:03:41.080 --> 00:03:44.260
and it is actively used in projects at prestigious labs,

58
00:03:44.380 --> 00:03:48.520
such as open AI Toyota research GitHub and more.

59
00:03:48.910 --> 00:03:53.200
And the best part is that if you have an open source academic or personal

60
00:03:53.201 --> 00:03:58.180
project, you can use their tools for free. It really is as good as it gets,

61
00:03:58.450 --> 00:03:59.740
make sure to visit them through

62
00:04:02.170 --> 00:04:05.800
wmb.com/papers or click the link in the video description to start tracking your

63
00:04:05.801 --> 00:04:07.570
experiments in five minutes,

64
00:04:08.170 --> 00:04:12.160
our thanks to weights and biases for their longstanding support and for helping

65
00:04:12.161 --> 00:04:13.660
us make better videos for you.

66
00:04:14.110 --> 00:04:18.100
Thanks for watching and for your generous support. And I'll see you next time.

