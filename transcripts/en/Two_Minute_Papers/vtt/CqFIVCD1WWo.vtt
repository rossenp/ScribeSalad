WEBVTT

1
00:00:00.300 --> 00:00:04.590
Dear fellow scholars,
this is two minute papers with Károly Zsolnai-Fehér.

2
00:00:04.860 --> 00:00:06.630
When I opened my inbox today,

3
00:00:06.660 --> 00:00:10.890
I was greeted by a huge deluge of messages about wavenet.

4
00:00:11.160 --> 00:00:15.360
Well first it's great to see that so many people are excited about these

5
00:00:15.361 --> 00:00:17.140
inventions and second,

6
00:00:17.320 --> 00:00:22.070
may all your wishes come true as quickly as this one.
So here we go.

7
00:00:22.250 --> 00:00:27.250
This piece of work is about generating audio wave forms for text to speech and

8
00:00:27.531 --> 00:00:32.060
more text to speech basically means that we have a voice reading whatever we

9
00:00:32.061 --> 00:00:35.270
have written down.
The difference in this work is however,

10
00:00:35.271 --> 00:00:38.810
that it can synthesize these samples in someone's voice,

11
00:00:38.900 --> 00:00:42.380
provided that we have training samples of this person speaking.

12
00:00:43.940 --> 00:00:46.730
The avocado is a pear shaped fruit with leathery skin,

13
00:00:46.790 --> 00:00:48.740
smooth edible flesh and a large stone.

14
00:00:50.010 --> 00:00:52.800
<v 1>The avocado is a pear shaped fruit with leathery skin,</v>

15
00:00:52.830 --> 00:00:54.810
smooth edible flesh and a large stone.

16
00:00:56.290 --> 00:00:59.080
The avocado is a pear shaped fruit with leathery skin,

17
00:00:59.110 --> 00:01:01.150
smooth edible flesh and a large stone.

18
00:01:02.340 --> 00:01:05.130
The avocado is a pear shaped fruit with leathery skin,

19
00:01:05.160 --> 00:01:07.140
smooth edible flesh and a large stone.

20
00:01:08.640 --> 00:01:12.120
<v 0>It also generates way forms sample by sample,</v>

21
00:01:12.180 --> 00:01:16.380
which is particularly perilous because we typically need to produce these at the

22
00:01:16.381 --> 00:01:21.381
rate of 16 to 24,000 samples per second and as we listen to the TV,

23
00:01:22.440 --> 00:01:25.830
radio and talk to each other several hours a day,

24
00:01:25.890 --> 00:01:30.450
the human ear and brain is particularly suited to processing this kind of

25
00:01:30.451 --> 00:01:34.170
signal.
If the result is off by only the slightest amount,

26
00:01:34.340 --> 00:01:36.080
we immediately recognize it.

27
00:01:36.390 --> 00:01:40.980
It is not using a recurrent neural network which is typically suited to learn

28
00:01:40.981 --> 00:01:45.240
sequences of things and it's widely used for some synthesis.

29
00:01:45.450 --> 00:01:48.120
It is using a convolutional neural network,

30
00:01:48.180 --> 00:01:53.070
which is quite surprising because it is not meant to process sequences of data

31
00:01:53.130 --> 00:01:55.140
that change in time.
However,

32
00:01:55.170 --> 00:01:58.770
this variant contains an extension that is able to do that.

33
00:01:58.980 --> 00:02:03.980
They call this extension dilated convolutions and the open up the possibility of

34
00:02:04.261 --> 00:02:09.060
making large skips in the input data so we have a better global view of it.

35
00:02:09.250 --> 00:02:11.620
If we were working in computer vision,

36
00:02:11.740 --> 00:02:16.060
it would be like increasing the receptive field of the eye so we can see the

37
00:02:16.061 --> 00:02:19.720
entire landscape and not only a tree on a photograph.

38
00:02:19.910 --> 00:02:23.450
It is also a bit like the temporary coherence problem we have talked about

39
00:02:23.480 --> 00:02:24.110
earlier.

40
00:02:24.110 --> 00:02:29.110
Taking all this into consideration results in more consistent outputs over

41
00:02:29.331 --> 00:02:34.331
larger time scales so the technique knows what it had done several seconds ago.

42
00:02:34.630 --> 00:02:39.630
Also training a convolutional neural network is a walk in the park compared to

43
00:02:40.301 --> 00:02:41.770
our recurrent neural network.

44
00:02:42.090 --> 00:02:47.090
Really cool and the results speed all existing widely used techniques by a large

45
00:02:47.861 --> 00:02:49.920
margin.
One of these is the concrete,

46
00:02:49.921 --> 00:02:54.600
the native technique which builds sentences from a huge amount of small speech

47
00:02:54.601 --> 00:02:55.434
fragments.

48
00:02:55.460 --> 00:02:59.980
These have seen a ton of improvements during the years but the outputs are still

49
00:02:59.981 --> 00:03:04.640
robotic and it is noticeable that we are not listening to human but a computer.

50
00:03:05.040 --> 00:03:07.950
The deep mind guys also report that quote.

51
00:03:08.300 --> 00:03:13.300
Notice that non speech sounds such as breathing and mouth movements are also

52
00:03:14.151 --> 00:03:16.160
sometimes generated by wavenet.

53
00:03:16.250 --> 00:03:21.060
This reflects the greater flexibility of a raw audio model.
End Quote,

54
00:03:22.740 --> 00:03:26.610
<v 1>the Blue Lagoon is an 1980 American romance and adventure film directed by</v>

55
00:03:26.611 --> 00:03:27.570
Randal Kleiser.

56
00:03:29.200 --> 00:03:34.200
The Blue Lagoon is a 1980 American romance and adventure film directed by Randal

57
00:03:34.240 --> 00:03:35.073
Kleiser

58
00:03:36.210 --> 00:03:41.210
aspects of the sublime in English poetry and painting 1770 to 1850 aspects of

59
00:03:42.881 --> 00:03:47.170
the sublime in English,
poetry and painting 1770 to 1850

60
00:03:48.210 --> 00:03:49.170
<v 0>at the same time.</v>

61
00:03:49.200 --> 00:03:54.200
I like to note that in the next few episodes it may be that my voice is a bit

62
00:03:54.391 --> 00:03:59.130
different.
Don't worry about that.
It may also happen that I am on a vacation,

63
00:03:59.290 --> 00:04:02.860
but new episodes and voice samples pop up on the channel.

64
00:04:03.050 --> 00:04:07.460
Please don't worry about that either.
Everything is working as intended.

65
00:04:07.880 --> 00:04:12.880
They also experimented with music generation and the results are just stunning.

66
00:04:14.670 --> 00:04:15.503
<v 2>Yeah.</v>

67
00:04:45.530 --> 00:04:47.630
[inaudible] [inaudible]

68
00:04:49.610 --> 00:04:52.460
<v 0>I don't know what to say.
These difficult problems.</v>

69
00:04:52.670 --> 00:04:57.440
These impenetrable walls crumble one after another as deep mind takes on them.

70
00:04:57.710 --> 00:05:02.550
Insanity.
Their blog post and the paper are both really well written.

71
00:05:02.610 --> 00:05:06.450
Make sure to check them out.
They are both linked in the video description box.

72
00:05:06.750 --> 00:05:11.750
I wager that artistic style transfer for sound and instruments is not only

73
00:05:11.851 --> 00:05:13.710
coming,
but it will be here soon.

74
00:05:13.910 --> 00:05:18.200
I imagined that will play a guitar and it will sound like a harp and we'll be

75
00:05:18.201 --> 00:05:22.280
able to sing something in.
Lady Gaga has voice and the intonation.

76
00:05:22.580 --> 00:05:27.350
I've also seen someone pitching the idea of creating audio books automatically

77
00:05:27.440 --> 00:05:29.470
with such a technique.
Wow.

78
00:05:29.710 --> 00:05:32.750
I travel a lot and then almost always on the go,

79
00:05:32.860 --> 00:05:36.130
so I personally would love to have such audio books.

80
00:05:36.290 --> 00:05:39.710
I have linked to the mentioned machine learning reddit thread in the description

81
00:05:39.711 --> 00:05:43.320
box.
As always,
there's lots of great discussion and ideas there.

82
00:05:43.690 --> 00:05:48.690
It was also reported that the algorithm currently takes 90 minutes to synthesize

83
00:05:49.000 --> 00:05:52.420
one second of sound wave forms.
You know the trail,

84
00:05:52.510 --> 00:05:56.440
one followup paper down the line.
It will take only a few minutes,

85
00:05:56.560 --> 00:05:59.270
a few more papers down the line.
It will be real time.

86
00:05:59.800 --> 00:06:02.200
Just think about all these advancements,

87
00:06:02.420 --> 00:06:07.130
what a time we are living in and I am extremely excited to present them all to

88
00:06:07.131 --> 00:06:09.590
you.
Fellow scholars into minute papers.

89
00:06:09.790 --> 00:06:12.850
Make sure to leave your thoughts and ideas in the comment section.

90
00:06:13.030 --> 00:06:14.050
We'll love reading them.

91
00:06:14.260 --> 00:06:18.150
Thanks for watching and for your generous support and I'll see you next time.

92
00:06:18.610 --> 00:06:23.610
<v 2>[inaudible].</v>

