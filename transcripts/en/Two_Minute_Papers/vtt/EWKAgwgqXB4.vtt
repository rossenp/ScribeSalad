WEBVTT

1
00:00:00.060 --> 00:00:04.110
<v 0>Dear fellow scholars. This is two minute papers with Dr. Károly Zsolnai-Fehér.</v>

2
00:00:04.110 --> 00:00:04.110
A few years ago, we have mainly seen neural network based techniques being used for image classification. This means that they were able to recognize objects for instance, animals and traffic signs in images. But today with the incredible pace of machine learning research, we now have 

3
00:00:04.110 --> 00:00:04.110
a

4
00:00:04.110 --> 00:00:04.110
 selection of neural network based techniques for not only classifying images, but also synthesizing them. The images that you see here and throughout this video is generated by one of these learning based methods. But of course, in this series, we are always obsessed with artistic control or in other words, how much of a say we have in the creation of these images after all getting thousands and thousands of images without any overarching theme or artistic control is hardly useful for anyone. One way of being able to control the 

5
00:00:04.110 --> 00:00:04.943
output is to use a technique that is capable of image translation.

6
00:01:00.540 --> 00:01:03.480
What you see here is a work by the name cycle. Again,

7
00:01:03.990 --> 00:01:08.910
it could transform apples into oranges, zebras into horses and more,

8
00:01:09.300 --> 00:01:14.040
it was called cycle GaN because it introduced a cycle consistency loss function.

9
00:01:14.460 --> 00:01:18.120
This means that if we convert a summer image to a winter image,

10
00:01:18.450 --> 00:01:22.710
and then back to a summer image, we should get the same image back,

11
00:01:22.920 --> 00:01:25.350
or at least something very similar.

12
00:01:25.770 --> 00:01:28.020
If our learning system obeys this principle,

13
00:01:28.260 --> 00:01:32.280
the output quality of the translation is going to be significantly better.

14
00:01:32.910 --> 00:01:33.450
Today.

15
00:01:33.450 --> 00:01:37.350
We are going to study the more advanced image translation technique that takes

16
00:01:37.351 --> 00:01:42.180
this further. This paper is amazingly good at daytime image translation.

17
00:01:42.570 --> 00:01:46.710
It looks at a selection of landscape images. And then as you see here,

18
00:01:47.010 --> 00:01:51.900
it learns to reimagine our input photos as if they were taken at different times

19
00:01:51.930 --> 00:01:52.763
of the day.

20
00:01:53.010 --> 00:01:57.870
I love how clouds form and move over time in the synthesized images

21
00:01:58.140 --> 00:02:02.040
and the night sky with the stars is also truly a sight to behold,

22
00:02:02.640 --> 00:02:07.410
but wait cycle again, and many other follow-up works, did image translation.

23
00:02:07.830 --> 00:02:11.910
This also does image translation. So what's really new here.

24
00:02:12.750 --> 00:02:15.120
Well, one this word proposers,

25
00:02:15.300 --> 00:02:20.070
the novel upsampling scheme that helps creating output images with lots and lots

26
00:02:20.071 --> 00:02:24.660
of detail to it can also create not just a bunch of images,

27
00:02:24.750 --> 00:02:25.830
a few hours apart,

28
00:02:26.130 --> 00:02:30.780
but it can also make beautiful time-lapse videos where the transitions are

29
00:02:30.781 --> 00:02:35.430
smooth. Oh my goodness, I love this. And three,

30
00:02:35.640 --> 00:02:40.050
the training happens by shoveling 20,000 landscape images into the neural

31
00:02:40.051 --> 00:02:45.000
network, and it becomes able to perform this translation task without labels.

32
00:02:45.450 --> 00:02:49.200
This means that we don't have to explicitly search for all the daytime images

33
00:02:49.470 --> 00:02:53.820
and tell the learner that these are daytime images and these other images are

34
00:02:53.821 --> 00:02:54.654
not,

35
00:02:54.660 --> 00:02:59.440
this is amazing because the algorithm is able to learn by itself without

36
00:02:59.441 --> 00:03:00.274
labels,

37
00:03:00.280 --> 00:03:04.660
but it is also easier to use because we can feed in lots and lots more training

38
00:03:04.661 --> 00:03:08.770
data without having to label these images correctly. As a result,

39
00:03:08.830 --> 00:03:13.240
we now know that this daytime translation task is used as a test bed to

40
00:03:13.241 --> 00:03:17.830
demonstrate that this method can be reused for other kinds of image translation

41
00:03:17.831 --> 00:03:18.664
tasks.

42
00:03:19.150 --> 00:03:23.920
The fact that it can learn on its own and still compete with other works in this

43
00:03:23.921 --> 00:03:27.730
area is truly incredible. Due to this kind of generality.

44
00:03:28.000 --> 00:03:31.570
It can also perform other related tasks. For instance,

45
00:03:31.690 --> 00:03:35.380
it can perform style transfer or in other words,

46
00:03:35.500 --> 00:03:37.300
not just change the time of day,

47
00:03:37.540 --> 00:03:41.410
but reimagine our pictures in the style of famous artists.

48
00:03:41.860 --> 00:03:43.180
I think with this paper,

49
00:03:43.360 --> 00:03:47.170
we have a really capable of technique on our hands that is getting closer and

50
00:03:47.171 --> 00:03:51.880
closer to the point where they can see use in mainstream software packages and

51
00:03:51.881 --> 00:03:55.360
image editors. That would be absolutely amazing.

52
00:03:55.960 --> 00:03:57.550
If you have a closer look at the paper,

53
00:03:57.580 --> 00:04:01.750
you will see that it tries to minimize seven things at the same time,

54
00:04:02.200 --> 00:04:03.580
what a time to be alive.

55
00:04:04.060 --> 00:04:07.840
This episode has been supported by weights and biases here.

56
00:04:07.900 --> 00:04:12.130
They show you how to build a proper convolutional neural network for image

57
00:04:12.131 --> 00:04:13.030
classification,

58
00:04:13.270 --> 00:04:17.950
and how to visualize the performance of your model weights and biases provides

59
00:04:17.951 --> 00:04:21.010
tools to track your experiments in your deep learning project.

60
00:04:21.370 --> 00:04:24.550
Their system is designed to save you a ton of time and money,

61
00:04:24.760 --> 00:04:27.850
and it is actively used in projects at prestigious labs,

62
00:04:28.000 --> 00:04:31.990
such as open AI Toyota research GitHub and more.

63
00:04:32.380 --> 00:04:37.150
And the best part is that if you're an academic or have an open source project,

64
00:04:37.300 --> 00:04:41.620
you can use their tools for free. It really is as good as it gets,

65
00:04:41.980 --> 00:04:45.490
make sure to visit them through wmb.com/papers,

66
00:04:45.700 --> 00:04:48.100
or just click the link in the video description.

67
00:04:48.370 --> 00:04:52.390
And you can get the freedom or today our thanks to weights and biases for their

68
00:04:52.960 --> 00:04:56.050
longstanding support and for helping us make better videos for you.

69
00:04:56.410 --> 00:05:00.340
Thanks for watching and for your generous support. And I'll see you next time.

