WEBVTT

1
00:00:00.150 --> 00:00:04.950
<v 0>Dear fellow scholars. This is two minute papers with Károly Zsolnai-Fehér. In this series,</v>

2
00:00:05.010 --> 00:00:09.840
we often discuss a class of techniques by the name image in painting image in

3
00:00:09.841 --> 00:00:14.460
painting methods are capable of filling in missing details from a mostly intact

4
00:00:14.461 --> 00:00:18.120
image. You see the legendary patch match algorithm at work here,

5
00:00:18.390 --> 00:00:20.160
which is more than 10 years old,

6
00:00:20.310 --> 00:00:24.480
and it is a good old computer graphics method with no machine learning insight.

7
00:00:24.750 --> 00:00:28.890
And after so much time, 10 years is an eternity in research years.

8
00:00:29.250 --> 00:00:32.640
It still punches way above its weight. However,

9
00:00:32.670 --> 00:00:35.400
with the ascendancy of neural network based learning methods,

10
00:00:35.670 --> 00:00:39.750
I am often wondering whether it would be possible to take a more difficult

11
00:00:39.751 --> 00:00:42.150
problem, for instance, in painting,

12
00:00:42.210 --> 00:00:45.960
not just images but movies as well. For instance,

13
00:00:46.140 --> 00:00:47.580
let's take an old, old,

14
00:00:47.581 --> 00:00:51.960
black and white movie that suffers from missing data flickering

15
00:00:52.230 --> 00:00:54.330
blurriness, and interestingly,

16
00:00:54.510 --> 00:00:59.340
even the contrast of the footage has changed as it faded over time. Well,

17
00:00:59.430 --> 00:01:03.630
hold onto your papers because this learning based approach fixes all of these

18
00:01:03.990 --> 00:01:07.380
and even more step number one is restoration,

19
00:01:07.560 --> 00:01:10.710
which takes care of all of these artifacts and contrast issues.

20
00:01:11.310 --> 00:01:14.550
You can not only see how much better the restored version is,

21
00:01:14.700 --> 00:01:19.470
but it is also reported what the technique did. Exactly. However,

22
00:01:19.620 --> 00:01:23.820
it does more. What more could we possibly ask for? Well,

23
00:01:24.030 --> 00:01:24.960
colorization,

24
00:01:25.380 --> 00:01:29.490
what it does is that it looks at only six colorized reference images that we

25
00:01:29.491 --> 00:01:34.260
have to provide and uses this as our direction and propagate it to the remainder

26
00:01:34.261 --> 00:01:37.920
of the frames. And it does an absolutely amazing work at that.

27
00:01:38.490 --> 00:01:42.720
It even tells us which reference image it is looking at when colorizing some of

28
00:01:42.721 --> 00:01:46.650
these frames. So if something does not come out favorably,

29
00:01:46.800 --> 00:01:51.270
we know which image to recolor the architecture of the neural network that is

30
00:01:51.271 --> 00:01:55.380
used for all. This also has to follow the requirements appropriately.

31
00:01:55.710 --> 00:01:58.830
For instance, beyond the standard spatial convolution layers.

32
00:01:59.040 --> 00:02:02.370
It also makes ample use of temporal convolution layers,

33
00:02:02.580 --> 00:02:07.320
which helps smearing out the colorization information from one reference image

34
00:02:07.560 --> 00:02:10.830
to multiple frames. However, in research,

35
00:02:10.890 --> 00:02:15.030
the technique is rarely the very first at doing something. And sure enough,

36
00:02:15.270 --> 00:02:18.870
this is not the first technique that does this kind of restoration and

37
00:02:18.871 --> 00:02:23.340
colorization. So how does it compare to previously published methods?

38
00:02:23.880 --> 00:02:28.050
Well, quite favorably with previous methods, in some cases,

39
00:02:28.260 --> 00:02:33.060
the colorization just appears and disappears over time while it is much

40
00:02:33.061 --> 00:02:33.930
more stable here.

41
00:02:34.530 --> 00:02:38.520
Also fewer artifacts make it to the final footage as is cleaning.

42
00:02:38.760 --> 00:02:42.780
These up is one of the main objectives of these methods. It's also great news.

43
00:02:43.380 --> 00:02:46.500
If we look at some quantitative results or in other words,

44
00:02:46.680 --> 00:02:48.600
numbers that describe the difference.

45
00:02:49.020 --> 00:02:52.740
You can see here that we get a three to four decibels cleaner image,

46
00:02:53.040 --> 00:02:57.630
which is outstanding. Not that the decibel scale is not linear,

47
00:02:57.810 --> 00:03:02.680
but the logarithmic scale, therefore, if you read 28 instead of 24,

48
00:03:02.860 --> 00:03:07.300
it does not mean that it's just approximately 15% better. It is a much,

49
00:03:07.480 --> 00:03:09.310
much more pronounced difference than that.

50
00:03:09.880 --> 00:03:13.780
I think these results are approaching a state where they are becoming close to

51
00:03:13.781 --> 00:03:18.490
good enough so that we can revive some of these old masterpiece movies and give

52
00:03:18.491 --> 00:03:22.120
them a much deserved facelift. What a time to be alive.

53
00:03:22.480 --> 00:03:25.900
This episode has been supported by weights and biases, weights,

54
00:03:25.901 --> 00:03:29.440
and biases provides tools to track your experiments in your deep learning

55
00:03:29.441 --> 00:03:30.250
project.

56
00:03:30.250 --> 00:03:34.300
It can save you a ton of time and money in these projects and is being used by

57
00:03:34.301 --> 00:03:37.840
open AI Toyota research, Stanford and Berkeley.

58
00:03:38.140 --> 00:03:41.230
They also wrote a guide on the fundamentals of neural networks,

59
00:03:41.410 --> 00:03:45.820
where they explain in simple terms, how to train a neural network properly.

60
00:03:46.090 --> 00:03:49.870
What are the most common errors you can make and how to fix them?

61
00:03:50.320 --> 00:03:51.490
It is really great.

62
00:03:51.550 --> 00:03:55.030
You got to have a look so make sure to visit them through Wendy

63
00:03:56.620 --> 00:03:59.350
db.com/papers, or just click the link in the video description.

64
00:03:59.530 --> 00:04:01.360
And you can get a free demo today.

65
00:04:01.870 --> 00:04:05.320
Our thanks to weights and biases for helping us make better videos for you.

66
00:04:05.590 --> 00:04:09.520
Thanks for watching and for your generous support. And I'll see you next time.

