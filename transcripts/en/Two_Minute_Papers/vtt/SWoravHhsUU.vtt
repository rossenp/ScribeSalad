WEBVTT

1
00:00:00.210 --> 00:00:01.290
<v 0>Dear fellow scholars.</v>

2
00:00:01.530 --> 00:00:05.490
This is two minute papers with [inaudible] neural network based learning

3
00:00:05.491 --> 00:00:07.680
algorithms are on the rise these days.

4
00:00:07.890 --> 00:00:11.550
And even though it is common knowledge that they are capable of image

5
00:00:11.551 --> 00:00:14.310
classification, or in other words,

6
00:00:14.490 --> 00:00:18.540
looking at an image and saying whether it depicts a dog or a cat

7
00:00:18.780 --> 00:00:22.890
nowadays, they can do much, much more. In this series.

8
00:00:22.891 --> 00:00:27.060
We covered a stunning paper that showcase the system that could not only

9
00:00:27.061 --> 00:00:28.110
classify an image,

10
00:00:28.290 --> 00:00:33.120
but write the proper sentence on what is going on and could cover

11
00:00:33.300 --> 00:00:36.960
even highly non-trivial cases. You may be surprised,

12
00:00:37.140 --> 00:00:38.940
but this thing is not recent at all.

13
00:00:39.330 --> 00:00:43.500
This is four year old news insanity. Later.

14
00:00:43.590 --> 00:00:48.090
Researchers turned this whole problem around and performed something that was

15
00:00:48.091 --> 00:00:50.310
previously thought to be impossible.

16
00:00:50.760 --> 00:00:54.960
They started using these networks to generate photorealistic images from a

17
00:00:54.961 --> 00:00:56.130
written text description.

18
00:00:56.520 --> 00:01:01.110
We could create new bird species by specifying that it should have orange legs

19
00:01:01.350 --> 00:01:03.600
and a short, a little bit later.

20
00:01:03.720 --> 00:01:07.890
Researchers at Nvidia who recognized and addressed two shortcomings.

21
00:01:08.370 --> 00:01:12.240
One was that the images were not that detailed and tool,

22
00:01:12.540 --> 00:01:14.220
even though we could input text,

23
00:01:14.340 --> 00:01:19.230
we couldn't exert too much artistic control over the results in came

24
00:01:19.231 --> 00:01:20.730
style again to the rescue,

25
00:01:20.910 --> 00:01:24.690
which was able to perform both of these difficult tasks really well.

26
00:01:25.230 --> 00:01:27.270
These images were progressively grown,

27
00:01:27.480 --> 00:01:31.980
which means that we started out with a course image and go over it over and over

28
00:01:31.981 --> 00:01:35.640
again, adding new details. This is what the results look like.

29
00:01:35.700 --> 00:01:40.620
And we can Marvel at the fact that none of these people are real. However,

30
00:01:40.680 --> 00:01:44.940
some of these images were still contaminated by unwanted artifacts.

31
00:01:45.300 --> 00:01:48.510
Furthermore, there are some features that are highly localized.

32
00:01:48.750 --> 00:01:50.940
As we exert control over these images,

33
00:01:51.210 --> 00:01:55.980
you can see how this part of the teeth and eyes are pinned to a particular

34
00:01:55.981 --> 00:02:00.630
position and the algorithm just refuses to let it go sometimes to the

35
00:02:00.631 --> 00:02:05.460
detriment of its surroundings. This new work is titled style again, too,

36
00:02:05.760 --> 00:02:08.880
and it addresses all of these problems in one go,

37
00:02:09.540 --> 00:02:13.860
perhaps this is the only place on the internet where we can say that finally,

38
00:02:14.010 --> 00:02:18.960
teeth and eyes are now allowed to float around freely and mean it with a

39
00:02:18.961 --> 00:02:23.640
positive sentiment here, you see a few handpicked examples from the best ones.

40
00:02:23.940 --> 00:02:28.110
And I have to say these are eye-popping really detailed and correct looking

41
00:02:28.111 --> 00:02:32.220
images. My goodness,

42
00:02:32.730 --> 00:02:37.500
the mixing examples you'll see here are also outstanding way better than the

43
00:02:37.501 --> 00:02:38.334
previous version.

44
00:02:38.910 --> 00:02:43.620
Also note that as there are plenty of training images out there for many other

45
00:02:43.621 --> 00:02:48.180
things beyond human faces, it can also generate cars, churches,

46
00:02:48.570 --> 00:02:51.390
horses, and of course, cats.

47
00:02:52.380 --> 00:02:55.980
Now that the original star and one work has been out for awhile,

48
00:02:56.160 --> 00:03:00.580
we have a little more clarity and understanding as to how it does what it does

49
00:03:00.850 --> 00:03:04.860
and the readings and parts of the architecture have been revised and simplified.

50
00:03:05.370 --> 00:03:10.170
This clarity comes with additional advantages beyond faster and higher quality

51
00:03:10.380 --> 00:03:14.880
training and in his generation. For instance, interestingly, despite the,

52
00:03:14.910 --> 00:03:19.200
the fact that the quality has improved significantly images made with a new

53
00:03:19.201 --> 00:03:23.640
method can be detected more easily. Not that the paper was much,

54
00:03:23.790 --> 00:03:24.840
much more than this.

55
00:03:25.020 --> 00:03:28.440
So make sure to have a look in the video description in this series,

56
00:03:28.441 --> 00:03:32.280
we always say that two more papers down the line and this technique will be

57
00:03:32.281 --> 00:03:35.640
leaps and bounds beyond the first iteration. Well,

58
00:03:35.760 --> 00:03:39.690
here we are not two, but only one more paper down the line.

59
00:03:40.140 --> 00:03:44.580
What a time to be alive. The source code of this project is also available.

60
00:03:44.910 --> 00:03:48.390
What's more, it even runs in your browser, this,

61
00:03:48.630 --> 00:03:51.120
so it has been supported by weights and biases,

62
00:03:51.300 --> 00:03:54.990
weights and biases provides tools to track your experiments in your deep

63
00:03:54.991 --> 00:03:55.830
learning projects.

64
00:03:56.100 --> 00:04:00.780
It can save you a ton of time and money in this project and is being used by an

65
00:04:00.781 --> 00:04:04.740
AI Toyota research Stanford and Berkeley here,

66
00:04:04.741 --> 00:04:09.210
you see a beautiful final report on one of their projects on classifying parts

67
00:04:09.240 --> 00:04:14.190
of streets, images, and see how these learning algorithms evolve over time.

68
00:04:14.580 --> 00:04:19.260
Make sure to visit them through when db.com/papers or just click the link,

69
00:04:19.530 --> 00:04:22.530
the video description, and you can get a free demo today.

70
00:04:22.980 --> 00:04:26.490
Our thanks to weights and biases for helping us make better videos for you.

71
00:04:26.760 --> 00:04:30.690
Thanks for watching and for your generous support. And I'll see you next time.

