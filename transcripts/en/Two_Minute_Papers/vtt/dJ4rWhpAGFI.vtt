WEBVTT

1
00:00:00.210 --> 00:00:04.190
<v 0>Dear fellow scholars. This is two minute papers with Dr. Károly Zsolnai-Fehér .</v>

2
00:00:04.590 --> 00:00:09.060
<v 1>Between 2013 and 2015 deep mind worked on an</v>

3
00:00:09.090 --> 00:00:13.770
incredible learning algorithm by the name deep reinforcement learning this

4
00:00:13.771 --> 00:00:18.360
technique looked at the pixels of the game was given a controller and

5
00:00:18.361 --> 00:00:23.250
played much like a human would with the exception that it learned to play

6
00:00:23.251 --> 00:00:25.950
some Atari games on a superhuman level.

7
00:00:26.460 --> 00:00:28.830
I have tried to train it a few years ago,

8
00:00:29.070 --> 00:00:33.750
and we'd like to invite you for a marvelous journey to see what happened when it

9
00:00:33.751 --> 00:00:38.100
starts learning to play an old game Atari breakout. At first,

10
00:00:38.220 --> 00:00:42.900
the algorithm loses all of its lives without any signs of intelligent action.

11
00:00:43.590 --> 00:00:46.620
If we wait, I bet it becomes better at playing the game,

12
00:00:46.920 --> 00:00:51.900
roughly matching the skill level of an adapt player, but here's the catch.

13
00:00:52.110 --> 00:00:53.340
If we wait for longer,

14
00:00:53.610 --> 00:00:57.870
we get something absolutely spectacular over time.

15
00:00:58.080 --> 00:01:02.940
<v 0>It learns to play like a pro and finds out that the best way to win the game is</v>

16
00:01:02.941 --> 00:01:06.570
digging a tunnel through the brakes and hit them from behind.

17
00:01:07.080 --> 00:01:11.190
This technique is a combination of a neural network that processes the visual

18
00:01:11.191 --> 00:01:15.990
data that we see on the screen and the reinforcement learner that comes

19
00:01:15.991 --> 00:01:20.520
up with the gameplay related decisions. This is an amazing algorithm,

20
00:01:20.640 --> 00:01:22.680
a true breakthrough in AI research.

21
00:01:23.250 --> 00:01:26.700
<v 1>However, it had its own issues. For instance,</v>

22
00:01:26.790 --> 00:01:31.230
it did not do well on Montezuma's revenge or pitfall because these games

23
00:01:31.231 --> 00:01:35.100
require more long-term planning. Believe it or not.

24
00:01:35.190 --> 00:01:39.930
The solution in a followup work was to infuse these agents with a very

25
00:01:40.290 --> 00:01:44.700
human like property curiosity, that agent was able to do much,

26
00:01:44.760 --> 00:01:49.050
much better at these games and then got addicted to the TV.

27
00:01:49.740 --> 00:01:53.850
But that's a different story note that this has been remedied since,

28
00:01:54.540 --> 00:01:57.780
and believe it or not, as impossible as it may sound.

29
00:01:58.050 --> 00:02:00.630
<v 0>All of this has been improved significantly.</v>

30
00:02:01.050 --> 00:02:05.790
This no work is called agent 57 and it plays better than humans

31
00:02:05.940 --> 00:02:10.260
on all 57 Atari games. Absolute insanity.

32
00:02:10.620 --> 00:02:13.890
Let's have a look at it in action. And then in a moment,

33
00:02:14.070 --> 00:02:16.710
I try to explain how it does what it does.

34
00:02:17.550 --> 00:02:21.840
You see agent 57 doing really well at the Solari's game here.

35
00:02:22.560 --> 00:02:26.730
This space battle game is one of the most impressive games on the Atari.

36
00:02:27.000 --> 00:02:31.590
<v 1>As it contains 16 quadrants, 48 sectors space battles,</v>

37
00:02:32.070 --> 00:02:36.660
war mechanics, pirate ships, fuel management, and much more you name it.

38
00:02:37.140 --> 00:02:39.150
This game is not only quite complex,

39
00:02:39.360 --> 00:02:43.650
but it also is the credit assignment nightmare for an AI to play

40
00:02:44.280 --> 00:02:47.310
this credit assignment problem means that it can happen,

41
00:02:47.311 --> 00:02:51.960
that we choose an action and we only win or lose hundreds of actions

42
00:02:51.961 --> 00:02:56.850
later leaving us with no idea as to which of our actions led to this

43
00:02:56.851 --> 00:03:01.060
win or loss does making difficult to learn from our actions.

44
00:03:01.660 --> 00:03:04.780
<v 0>This Solari's game is a credit assignment. Nightmare.</v>

45
00:03:05.260 --> 00:03:10.030
Let me try to bring this point to life by talking about school in school.

46
00:03:10.060 --> 00:03:11.140
When we take an exam,

47
00:03:11.290 --> 00:03:15.910
we hand it in and the teacher gives us feedback for every single one of our

48
00:03:15.911 --> 00:03:19.360
solutions and tells us whether we were correct or not.

49
00:03:19.780 --> 00:03:24.310
We know exactly where we did well and what we need to practice to do better.

50
00:03:24.370 --> 00:03:28.690
Next time, clear, simple, easy Solaris.

51
00:03:28.780 --> 00:03:32.740
<v 1>On the other hand, not so much, if this were a school project,</v>

52
00:03:32.920 --> 00:03:36.310
the Solaria game would be a brutal merciless teacher.

53
00:03:36.970 --> 00:03:41.380
Would you like to know your grade? No grades, but he tells you that you failed?

54
00:03:42.130 --> 00:03:46.780
Well, that's weird. Okay. Where did we fail? He won't say,

55
00:03:47.410 --> 00:03:51.550
what should we do better next time to improve. You'll figure it out. Bacco.

56
00:03:52.030 --> 00:03:54.760
Also, we wrote this exam 10 weeks ago.

57
00:03:55.030 --> 00:03:57.790
Why do we only get to know about the results now?

58
00:03:58.210 --> 00:04:00.850
<v 0>No answer. I think in this case,</v>

59
00:04:00.880 --> 00:04:04.420
we can conclude that this would be a challenging learning environment,

60
00:04:04.660 --> 00:04:06.370
even for a motivated human.

61
00:04:06.640 --> 00:04:09.820
So just imagine how hard it is for an AI.

62
00:04:10.300 --> 00:04:15.010
<v 1>Hopefully this puts into perspective how incredible it is that agent 57</v>

63
00:04:15.040 --> 00:04:16.570
performs. Well on this game,

64
00:04:17.280 --> 00:04:22.060
it truly looks like science fiction to understand what agent 57

65
00:04:22.150 --> 00:04:22.983
as to this,

66
00:04:23.080 --> 00:04:27.610
it was given something called a matter controller that can decide

67
00:04:27.850 --> 00:04:32.620
when to prioritize short and long-term planning on the short term,

68
00:04:32.740 --> 00:04:37.390
we typically have mechanical challenges like avoiding a skull in Montezuma's

69
00:04:37.391 --> 00:04:41.530
revenge or dodging the shots of an enemy ship in Solaris.

70
00:04:42.040 --> 00:04:46.330
The long-term part is also necessary to explore new parts of the game

71
00:04:46.720 --> 00:04:50.470
and have a good strategy plan to eventually win the game.

72
00:04:51.010 --> 00:04:55.630
This is great because this new technique can now deal with the brutal and

73
00:04:55.631 --> 00:04:57.880
merciless teacher who we just introduced.

74
00:04:58.390 --> 00:04:59.320
<v 0>Alternatively,</v>

75
00:04:59.380 --> 00:05:03.940
this agent can be thought of as someone who has a motivation to explore the game

76
00:05:04.390 --> 00:05:08.380
and do well at mechanical tasks at the same time,

77
00:05:08.770 --> 00:05:13.540
and can also prioritize these tasks with this for the first time.

78
00:05:13.660 --> 00:05:18.250
Scientists at deep mind found a learning algorithm that exceeds

79
00:05:18.280 --> 00:05:21.850
human performance on all 57 Atari games.

80
00:05:22.390 --> 00:05:26.950
And please do not forget about the fact that deep mind tries to solve general

81
00:05:26.951 --> 00:05:31.930
intelligence and then use general intelligence to solve everything else.

82
00:05:32.350 --> 00:05:35.230
<v 1>This is their Holy grail. In other words,</v>

83
00:05:35.320 --> 00:05:39.790
they are seeking an algorithm that can learn by itself and achieve

84
00:05:39.791 --> 00:05:44.530
human-like performance in a variety of tasks. There is still plenty to do,

85
00:05:44.830 --> 00:05:47.410
but we are now one step closer to that.

86
00:05:48.040 --> 00:05:50.500
If you learn only one thing from this video,

87
00:05:50.710 --> 00:05:54.040
let it be the fact that there are not 57 different methods,

88
00:05:54.280 --> 00:05:59.240
but one general algorithm that plays 57 games better than

89
00:05:59.241 --> 00:06:00.074
humans.

90
00:06:00.140 --> 00:06:01.490
<v 0>What a time to be alive.</v>

91
00:06:02.000 --> 00:06:06.050
I would like to show you a short message from a few days ago that melted my

92
00:06:06.051 --> 00:06:10.940
heart. This I got from Nathan, who has been inspired by these incredible works,

93
00:06:11.180 --> 00:06:15.140
and he decided to turn his life around and go back to study more.

94
00:06:15.830 --> 00:06:20.510
I love my job and reading messages like this is one of the absolute best parts

95
00:06:20.511 --> 00:06:21.260
of it.

96
00:06:21.260 --> 00:06:22.460
<v 1>Congratulations, Nathan,</v>

97
00:06:22.760 --> 00:06:26.960
and note that you can take this inspiration and greatness can materialize in

98
00:06:26.961 --> 00:06:28.220
every aspect of life.

99
00:06:28.460 --> 00:06:32.390
Not only in computer graphics or machine learning research, good luck.

100
00:06:32.930 --> 00:06:37.190
If you're a researcher or a startup looking for cheap GPU compute to run these

101
00:06:37.191 --> 00:06:41.630
algorithms, check out Lambda GPU cloud. I've talked about Lambda,

102
00:06:41.660 --> 00:06:43.820
GPU workstations in other videos,

103
00:06:44.060 --> 00:06:48.350
and I'm happy to tell you that they are offering GPU cloud services as well.

104
00:06:48.890 --> 00:06:53.480
The Lambda GPU cloud can train image net to 93% accuracy

105
00:06:53.690 --> 00:06:55.730
for less than $19.

106
00:06:56.090 --> 00:07:00.440
Lambda's web based IDE lets you easily access your instance right in your

107
00:07:00.441 --> 00:07:01.220
browser.

108
00:07:01.220 --> 00:07:06.170
And finally hold onto your papers because the Lambda GPU cloud costs less

109
00:07:06.171 --> 00:07:08.840
than half of AWS and Asia.

110
00:07:09.350 --> 00:07:14.330
Make sure to go to Lambda labs.com/papers and sign up for one of their

111
00:07:14.390 --> 00:07:16.220
amazing GPU instances today.

112
00:07:16.610 --> 00:07:19.940
Our thanks to Lambda for helping us make better videos for you.

113
00:07:20.330 --> 00:07:24.260
Thanks for watching and for your generous support. And I'll see you next time.

