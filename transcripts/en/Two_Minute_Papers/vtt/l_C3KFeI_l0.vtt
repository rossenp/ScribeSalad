WEBVTT

1
00:00:00.180 --> 00:00:01.260
<v 0>Dear fellow scholars.</v>

2
00:00:01.410 --> 00:00:05.610
This is two minute papers with Dr. [inaudible] through the power of news.

3
00:00:05.870 --> 00:00:08.150
<v 1>On that work-based learning algorithms today.</v>

4
00:00:08.330 --> 00:00:11.630
It is possible to perform video to video translation.

5
00:00:11.960 --> 00:00:13.730
This means that for instance,

6
00:00:14.000 --> 00:00:18.980
in goes a daytime video and outcomes and nighttime version of the same

7
00:00:18.981 --> 00:00:23.960
footage. This previous method had some remarkable properties. For instance,

8
00:00:24.110 --> 00:00:24.650
look,

9
00:00:24.650 --> 00:00:29.030
you can even see the reflections of the nightlights appearing on the car hood.

10
00:00:29.540 --> 00:00:31.580
This is reassuring news, indeed,

11
00:00:31.700 --> 00:00:35.720
because the spark of some sort of intelligence was already there in these

12
00:00:35.721 --> 00:00:38.960
algorithms. And believe it or not, this is old,

13
00:00:39.050 --> 00:00:43.160
old news because we have been able to do these for about three years now,

14
00:00:43.610 --> 00:00:47.570
of course, this was not perfect. The results were missing. A lot of details.

15
00:00:47.870 --> 00:00:50.420
The frames of the video were quite a bit apart.

16
00:00:50.810 --> 00:00:52.880
Artifacts were abandoned and more,

17
00:00:53.240 --> 00:00:55.820
but this paper was a huge leap at the time.

18
00:00:56.180 --> 00:01:00.080
And today I wonder how far have we come in three years?

19
00:01:00.590 --> 00:01:04.370
What can we do now that we were not able to do three years ago?

20
00:01:04.880 --> 00:01:08.780
Let's have a look together. This input video is much more detailed,

21
00:01:09.050 --> 00:01:13.370
a lot more continuous. So I wonder what we could do with this. Well,

22
00:01:13.460 --> 00:01:17.180
hold onto your papers. And woo.

23
00:01:17.420 --> 00:01:19.340
Look at that one.

24
00:01:19.370 --> 00:01:23.990
We have changed a sky and put a spaceship in there that is already

25
00:01:23.991 --> 00:01:28.790
amazing. But look to the spaceship is not stationary,

26
00:01:29.000 --> 00:01:31.730
but moves in harmony with the other objects,

27
00:01:31.760 --> 00:01:36.050
individual and three, since the sky has changed,

28
00:01:36.230 --> 00:01:38.510
the lighting situation has also changed.

29
00:01:38.750 --> 00:01:42.230
So the colors of the remainder of the image also have to change.

30
00:01:42.740 --> 00:01:47.420
Let's see the before and after on that, yes. Excellent.

31
00:01:48.110 --> 00:01:50.840
And we can do so much more with this, for instance,

32
00:01:50.990 --> 00:01:55.700
put a castle in the sky or you know what let's

33
00:01:55.701 --> 00:01:59.960
think big, make it an extra planet, please. Wow.

34
00:02:00.260 --> 00:02:02.900
Thank you. And wait a minute.

35
00:02:03.140 --> 00:02:07.130
If it is able to recolor the image after changing its surroundings,

36
00:02:07.490 --> 00:02:11.690
how well does it do it? Can we change the background to a dynamic one?

37
00:02:12.140 --> 00:02:15.500
What about a thunderstorm? Oh yeah.

38
00:02:15.680 --> 00:02:20.360
That's as dynamic as it gets and a new method handles this case beautifully.

39
00:02:20.990 --> 00:02:25.160
And before we look under the hood to see how all this wizardry is done,

40
00:02:25.760 --> 00:02:28.130
let's list our expectations. One,

41
00:02:28.250 --> 00:02:31.220
we expect that it has to know what picks us to change,

42
00:02:31.250 --> 00:02:35.900
to load a different sky model to it should know how the image is

43
00:02:35.901 --> 00:02:37.910
changing and rotating over time.

44
00:02:38.390 --> 00:02:41.390
And three summary coloring has to take place.

45
00:02:41.900 --> 00:02:45.530
Now let's have a look and see if we find the parts we are expecting.

46
00:02:46.430 --> 00:02:49.430
And yes, it has a sky mapping network.

47
00:02:49.700 --> 00:02:52.340
This finds the parts of the image where the sky is.

48
00:02:52.820 --> 00:02:56.840
There is the motion estimator that computes the optical flow of the image

49
00:02:57.680 --> 00:02:59.680
distracts the movement of the sky over time.

50
00:03:00.100 --> 00:03:04.210
And there is the recoloring module as well. So there we go.

51
00:03:04.480 --> 00:03:06.760
This can do not only scary placement,

52
00:03:06.910 --> 00:03:11.440
but detailed weather and lighting synthesis is also possible for these videos.

53
00:03:11.890 --> 00:03:15.520
One at a time to be alive. Now, if you remember, first,

54
00:03:15.640 --> 00:03:18.490
we looked at the results, listed our expectations,

55
00:03:18.760 --> 00:03:21.970
and then we looked at the architecture of this neural network.

56
00:03:22.210 --> 00:03:25.510
This is a technique that I try to teach to my students in my lab,

57
00:03:25.540 --> 00:03:28.900
transport simulation course at the technical university of Vienna.

58
00:03:29.170 --> 00:03:33.550
And I think if you check it out, you will be surprised by how effective it is.

59
00:03:33.850 --> 00:03:37.570
Now note that I was always teaching it to a handful of motivated students.

60
00:03:37.750 --> 00:03:41.980
And I believe that the teachings shouldn't only be available for the privileged

61
00:03:41.981 --> 00:03:44.440
few who can afford a college education,

62
00:03:44.740 --> 00:03:49.360
but the teaching should be available for everyone free education for

63
00:03:49.361 --> 00:03:50.950
everyone. That's what I want.

64
00:03:51.340 --> 00:03:55.540
So the course is available free of charge for everyone, no strings attached.

65
00:03:55.660 --> 00:03:58.690
So make sure to click the link in the video description to get started.

66
00:03:59.050 --> 00:04:03.370
We ride a full light simulation program from scratch there and learn about

67
00:04:03.371 --> 00:04:05.710
physics, the world around us and more.

68
00:04:06.130 --> 00:04:10.480
And what is perhaps even more important is that I try to teach you a powerful

69
00:04:10.481 --> 00:04:15.070
way of understanding difficult mathematical concepts. Make sure to have a look.

70
00:04:15.430 --> 00:04:19.330
What you see here is a report of this exact paper we have talked about,

71
00:04:19.480 --> 00:04:23.410
which was made by weights and biases. I put a link to it in the description,

72
00:04:23.710 --> 00:04:24.850
make sure to have the look.

73
00:04:24.970 --> 00:04:29.770
I think it helps you understand this paper better weights and biases provides

74
00:04:29.771 --> 00:04:32.890
tools to track your experiments in your deep learning project.

75
00:04:33.010 --> 00:04:36.430
Their system is designed to save you a ton of time and money,

76
00:04:36.640 --> 00:04:39.790
and it is actively used in projects at prestigious labs,

77
00:04:39.850 --> 00:04:43.600
such as open AI Toyota research GitHub and more.

78
00:04:44.020 --> 00:04:48.130
And the best part is that weights and biases is free for all individuals

79
00:04:48.340 --> 00:04:52.900
academics and open source projects. It really is as good as it gets,

80
00:04:53.230 --> 00:04:56.980
make sure to visit them through wnb.com/papers,

81
00:04:57.280 --> 00:04:59.830
or just click the link in the video description.

82
00:04:59.980 --> 00:05:01.840
And you can get the free demo today.

83
00:05:02.140 --> 00:05:06.130
Our thanks to weights and biases for their longstanding support and for helping

84
00:05:06.131 --> 00:05:07.660
us make better videos for you.

85
00:05:07.900 --> 00:05:11.800
Thanks for watching and for your generous support. And I'll see you next time.

