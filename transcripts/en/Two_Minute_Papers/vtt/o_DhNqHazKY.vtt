WEBVTT

1
00:00:00.450 --> 00:00:01.283
<v 0>Dear fellow scholars.</v>

2
00:00:01.470 --> 00:00:04.890
This is two minute papers with Cardozo NIFA here in this series.

3
00:00:05.010 --> 00:00:08.430
We often talk about computer animation and physical simulations.

4
00:00:08.640 --> 00:00:12.390
And these episodes are typically about one or the other.

5
00:00:12.780 --> 00:00:17.700
You see it is possible to teach a simulated AI agent to lift weights and jump

6
00:00:17.730 --> 00:00:22.140
really high using physical simulations to make sure that the movements and

7
00:00:22.141 --> 00:00:27.000
forces are accurate. The simulation side is always looking for correctness.

8
00:00:27.330 --> 00:00:30.870
However, let's not forget the things also have to look good.

9
00:00:31.320 --> 00:00:34.620
Animation studios are paying a fortune to record motion,

10
00:00:34.621 --> 00:00:39.570
capture data from real humans and sometimes even dogs to make sure that these

11
00:00:39.571 --> 00:00:41.280
movements are visually appealing.

12
00:00:41.760 --> 00:00:45.990
So is it possible to create something that reacts to our commands with the

13
00:00:45.991 --> 00:00:50.190
controller looks good and also adheres to physics?

14
00:00:50.790 --> 00:00:54.810
Well, have a look, this work was developed at Ubisoft Lafarge.

15
00:00:55.050 --> 00:00:59.730
It responds to our input by other controller and the output animations are fluid

16
00:01:00.000 --> 00:01:04.560
and natural. Since it relies on a technique called deep reinforcement learning,

17
00:01:04.860 --> 00:01:06.120
it requires training.

18
00:01:06.540 --> 00:01:11.100
You see it at early on the blue agent is trying to imitate the white character

19
00:01:11.340 --> 00:01:15.480
and it is not doing well at all. It basically looks like me when going to bed.

20
00:01:15.630 --> 00:01:17.280
After reading papers all night,

21
00:01:17.790 --> 00:01:21.960
the white agents movement is not physically simulated and it was built using

22
00:01:21.990 --> 00:01:25.530
emotion database with only 10 minutes of animation data.

23
00:01:25.920 --> 00:01:28.680
This is the one that is in the looks good category,

24
00:01:29.250 --> 00:01:33.420
or it would look really good if it wasn't pacing around like a drunk card.

25
00:01:33.570 --> 00:01:38.040
So the question naturally arises who in their right minds would control a

26
00:01:38.041 --> 00:01:41.460
character like this? Well, of course, no one,

27
00:01:41.760 --> 00:01:45.420
this sequence was generated by an artificial worst case player,

28
00:01:45.600 --> 00:01:49.860
which is a nightmare situation for any AI to reproduce early on.

29
00:01:49.920 --> 00:01:54.630
It indeed is a nightmare. However, after 30 hours of training,

30
00:01:54.840 --> 00:01:59.520
the blue agent learned to reproduce the motion of the white character while

31
00:01:59.580 --> 00:02:03.750
being physically assimilated. So what is the advantage of that?

32
00:02:04.290 --> 00:02:05.490
Well, for instance,

33
00:02:05.610 --> 00:02:09.810
it can interact with the scene better and is robust against perturbations.

34
00:02:10.170 --> 00:02:13.800
This means that it can rapidly recover from undesirable positions.

35
00:02:14.190 --> 00:02:18.690
This can be validated via something that the paper calls impact testing.

36
00:02:19.500 --> 00:02:22.380
Are you thinking what I am thinking? I hope so,

37
00:02:22.560 --> 00:02:26.100
because I am thinking about throwing blocks at this virtual agent,

38
00:02:26.310 --> 00:02:29.130
one of our favorite pastimes at two minute papers,

39
00:02:29.400 --> 00:02:34.260
and it will be able to handle them. Whoops. Well,

40
00:02:34.500 --> 00:02:38.160
most of them, anyway, it also reacts to a change in direction,

41
00:02:38.280 --> 00:02:43.110
much quicker than previous agents. If all that was not amazing enough,

42
00:02:43.290 --> 00:02:48.030
the whole control system is very light and takes only a few microseconds.

43
00:02:48.300 --> 00:02:53.040
Most of which is spent by not even the control part, but the physics simulation.

44
00:02:53.490 --> 00:02:56.820
So with the power of computer graphics and machine learning,

45
00:02:56.821 --> 00:03:01.090
research animation and physics can now be combined beautifully.

46
00:03:01.390 --> 00:03:02.650
It does not limit controller.

47
00:03:02.651 --> 00:03:07.180
Responsiveness looks very realistic and it is very likely that we'll see this

48
00:03:07.181 --> 00:03:10.870
technique in action in future Ubisoft games, outstanding.

49
00:03:11.470 --> 00:03:14.170
This video was supported by you on Patrion.

50
00:03:14.410 --> 00:03:19.090
If you wish to watch these videos in early access or get your name immortalized

51
00:03:19.270 --> 00:03:20.170
in the video description,

52
00:03:20.320 --> 00:03:25.270
make sure to go to patrion.com/ two-minute papers and pick up one of

53
00:03:25.271 --> 00:03:26.140
those cool perks.

54
00:03:26.470 --> 00:03:30.670
Or we are also test driving the early access program here on YouTube.

55
00:03:30.790 --> 00:03:34.900
Just go ahead and click the join button or use the link in the description.

56
00:03:35.230 --> 00:03:39.100
Thanks for watching and for your generous support. And I'll see you next time.

