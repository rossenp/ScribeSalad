WEBVTT

1
00:00:00.090 --> 00:00:01.260
<v 0>Dear fellow scholars.</v>

2
00:00:01.440 --> 00:00:05.610
This is two minute papers with Dr. Károly Zsolnai-Fehér. The promise of virtual, yeah,

3
00:00:05.650 --> 00:00:09.050
<v 1>Reality. VR is indeed truly incredible.</v>

4
00:00:09.410 --> 00:00:11.420
If one day it comes to fruition.

5
00:00:11.630 --> 00:00:15.410
Doctors could be trained to perform surgery in a virtual environment.

6
00:00:15.650 --> 00:00:18.980
We could train better pilots with better flight simulators,

7
00:00:19.250 --> 00:00:22.850
expose astronauts to virtual zero gravity simulations.

8
00:00:23.120 --> 00:00:27.680
You name it an important part of doing many of these is simulating

9
00:00:27.681 --> 00:00:32.420
walking in a virtual environment. You'll see, we can be located in a small room,

10
00:00:32.660 --> 00:00:37.520
put on a VR headset and enter a wonderful, expensive virtual world.

11
00:00:38.090 --> 00:00:42.740
However, as we start walking, we immediately experience a big problem.

12
00:00:43.280 --> 00:00:46.910
What is that problem? Well,

13
00:00:46.940 --> 00:00:51.710
we bumped into things as a remedy. We could make our virtual world smaller,

14
00:00:52.070 --> 00:00:53.960
but that would defeat the purpose.

15
00:00:54.350 --> 00:00:58.880
This earlier technique addresses this walking problem spectacularly by

16
00:00:59.030 --> 00:01:02.720
redirection. So what is this redirection thing? Exactly.

17
00:01:03.140 --> 00:01:07.490
Redirection is a simple concept that changes our movement in the virtual world.

18
00:01:07.670 --> 00:01:12.560
So it deviates from our real path in the room in a way that both lets us

19
00:01:12.590 --> 00:01:17.570
explore the virtual world and not bump into walls and objects. In reality,

20
00:01:17.630 --> 00:01:21.980
in the meantime here, you can see how the blue and orange lines deviate,

21
00:01:22.190 --> 00:01:25.370
which means that the algorithm is at work, who it is.

22
00:01:25.430 --> 00:01:30.410
We can wonder about in a huge and majestic virtual landscape or a cramped

23
00:01:30.411 --> 00:01:34.070
bar, even when being confined to a small physical room,

24
00:01:34.610 --> 00:01:35.630
loving the idea,

25
00:01:36.140 --> 00:01:41.090
but there is more to interacting with virtual worlds than walking. For instance,

26
00:01:41.330 --> 00:01:45.050
look at this tech demo that requires more precise hand movements.

27
00:01:45.560 --> 00:01:50.180
How do we perform these? Well, the key is here, controllers.

28
00:01:50.750 --> 00:01:53.630
Clearly they work, but can we get rid of them?

29
00:01:54.020 --> 00:01:58.610
Can we just opt for a more natural solution and use our hands instead?

30
00:01:59.120 --> 00:01:59.660
Well,

31
00:01:59.660 --> 00:02:04.400
hold onto your papers because this new work uses a learning based algorithm to

32
00:02:04.430 --> 00:02:09.380
teach a head mounted camera, to tell the orientation of our hands at all times,

33
00:02:09.770 --> 00:02:13.220
of course the quality of the execution matters a great deal.

34
00:02:13.400 --> 00:02:16.100
So we have to ensure at least three things.

35
00:02:16.610 --> 00:02:20.060
One is that the hand tracking happens with minimal latency,

36
00:02:20.330 --> 00:02:24.140
which means that we see our actions immediately with minimal delay

37
00:02:25.400 --> 00:02:26.510
too. We need low jitter,

38
00:02:26.660 --> 00:02:30.560
which means that the key points of the reconstructed hand should not change too

39
00:02:30.561 --> 00:02:34.790
much from frame to frame. This happens a great deal with previous methods.

40
00:02:35.600 --> 00:02:39.470
And what about the new one? Oh yes.

41
00:02:39.650 --> 00:02:40.610
Much smoother.

42
00:02:41.480 --> 00:02:45.500
Check Mark note that the new method also remembers the history of the hand

43
00:02:45.501 --> 00:02:49.160
movement and therefore can deal with difficult occlusion situations.

44
00:02:49.520 --> 00:02:51.410
For instance, look at the pinky here.

45
00:02:51.860 --> 00:02:54.500
The previous technique would not know what's going on with it,

46
00:02:54.680 --> 00:02:59.500
but this new one knows exactly what is going on because it has information on

47
00:02:59.501 --> 00:03:03.040
what the hand was doing a moment ago. And three,

48
00:03:03.220 --> 00:03:06.040
this needs to work in all kinds of lighting conditions.

49
00:03:06.430 --> 00:03:10.990
Let's see if it can reconstruct arrange of mythical creatures in poor lighting

50
00:03:10.991 --> 00:03:12.790
conditions. Yes,

51
00:03:12.880 --> 00:03:17.350
these docks are reconstructed just as well as the mighty postmaster

52
00:03:19.720 --> 00:03:24.220
and D scissors to Bravo. So what can we do with this?

53
00:03:24.820 --> 00:03:26.530
A great deal. For instance,

54
00:03:26.590 --> 00:03:31.210
we can type on a virtual keyboard or implement all kinds of virtual user

55
00:03:31.211 --> 00:03:36.190
interfaces that we can interact with. We can also organize imaginary boxes

56
00:03:38.050 --> 00:03:40.960
and of course we can't leave out the two minute papers,

57
00:03:40.961 --> 00:03:44.620
favorite going into a physics simulation and playing with it.

58
00:03:46.330 --> 00:03:49.990
But of course not, everything is perfect here. Look, hand,

59
00:03:50.260 --> 00:03:52.210
hand interactions don't work so well.

60
00:03:52.360 --> 00:03:56.500
So folks who prefer virtual reality applications that include the washing,

61
00:03:56.501 --> 00:04:00.610
our hands should look elsewhere, but of course, one step at a time.

62
00:04:01.240 --> 00:04:04.570
This episode has been supported by Lambda GPU cloud.

63
00:04:04.750 --> 00:04:08.140
If you're looking for inexpensive cloud GPU's for AI,

64
00:04:08.320 --> 00:04:10.450
check out Lambda GPU cloud,

65
00:04:10.870 --> 00:04:14.530
they recently launched Quadro RTX 6,000 RTX,

66
00:04:14.560 --> 00:04:19.270
8,000 and V 100 instances and hold onto your papers

67
00:04:19.360 --> 00:04:23.980
because Lambda GPU cloud can cost less than half of AWS

68
00:04:24.160 --> 00:04:24.993
and Azure.

69
00:04:25.120 --> 00:04:30.070
Plus they are the only cloud service with 48 gigabyte RTX eight thousands

70
00:04:30.760 --> 00:04:34.000
joined researchers at organizations like Apple, MIT,

71
00:04:34.090 --> 00:04:38.470
and Caltech in using Lambda cloud instances, workstations or servers,

72
00:04:38.710 --> 00:04:43.450
make sure to go to Lambda labs.com/papers to sign up for one of their

73
00:04:43.451 --> 00:04:45.280
amazing GPU instances today.

74
00:04:45.550 --> 00:04:50.050
Our thanks to Lambda for the longstanding support and for helping us make better

75
00:04:50.051 --> 00:04:53.200
videos for you. Thanks for watching and for your generous support.

76
00:04:53.320 --> 00:04:55.030
And I'll see you next time.

