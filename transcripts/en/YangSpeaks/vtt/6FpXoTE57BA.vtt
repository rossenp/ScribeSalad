WEBVTT

1
00:00:00.030 --> 00:00:04.230
<v 0>How do you stay engaged and up on the</v>

2
00:00:04.231 --> 00:00:08.370
news and still keep your wits about you? Like,

3
00:00:08.400 --> 00:00:13.080
how do you keep your mental health in check while the world is,

4
00:00:13.410 --> 00:00:18.000
seems to be falling apart? Don't watch the news all day, every day.

5
00:00:18.150 --> 00:00:22.920
I don't think our brains are designed to really take that much stimulus

6
00:00:22.950 --> 00:00:25.230
over and over and over. And this is how I feel about Twitter,

7
00:00:25.231 --> 00:00:30.210
even though I am on it more than I should be. If you look at your replies,

8
00:00:30.211 --> 00:00:33.180
I bet you, if you look at your applies, even if they're positive,

9
00:00:33.990 --> 00:00:35.310
it's really overwhelming.

10
00:00:35.400 --> 00:00:39.390
I don't think we're supposed to get that much information,

11
00:00:39.420 --> 00:00:43.410
that much communication, that much feedback from that many people at,

12
00:00:43.580 --> 00:00:46.380
in like such a short period of period of time.

13
00:00:46.880 --> 00:00:49.400
<v 1>I don't think that was happening in the state of nature where you say something</v>

14
00:00:49.401 --> 00:00:52.640
on the campfire and then all of a sudden, like hundreds of people's steps

15
00:00:54.560 --> 00:00:55.820
with their opinion. Yeah.

16
00:00:56.270 --> 00:01:00.590
<v 0>Yeah. People are treating you to dunk on you. No, that did not happen.</v>

17
00:01:00.591 --> 00:01:01.880
This is all completely new.

18
00:01:02.840 --> 00:01:06.860
<v 1>And I agree with you about there being an optimal amount of news and social</v>

19
00:01:06.861 --> 00:01:09.920
media to consume in a given day. Uh, and I've been,

20
00:01:09.950 --> 00:01:14.900
so I I'm on CNN, uh, and CNN has 24 hours of news.

21
00:01:15.110 --> 00:01:18.950
Uh, I grew up in a time when there was approximately 30 minutes of news.

22
00:01:20.420 --> 00:01:24.020
It was just, and here's your nightly news and we'll do it again, like the local,

23
00:01:24.021 --> 00:01:25.940
Virgin and whatnot.

24
00:01:26.030 --> 00:01:29.120
And I'm convinced that there's an optimal amount of news.

25
00:01:29.300 --> 00:01:31.550
That's significantly less than 24 hours. Uh,

26
00:01:31.580 --> 00:01:36.140
because is the fact is if I have hours of

27
00:01:36.141 --> 00:01:40.780
bandwidth of content to fill, then I'll talk about something, you know, and,

28
00:01:40.781 --> 00:01:43.400
and I'll try and make it interesting. Um,

29
00:01:43.520 --> 00:01:47.240
and I'll do enough emotional responses to whatever the heck I'm talking about.

30
00:01:48.080 --> 00:01:52.370
Uh, and that that's, uh, and social media is that compounded, uh,

31
00:01:52.430 --> 00:01:56.120
and you're right that right. So I'm, I'm very much on Twitter. Um,

32
00:01:56.210 --> 00:02:00.080
and it was part of my presidential campaign. So it was very, uh,

33
00:02:01.520 --> 00:02:04.010
it was very, uh, high utility, uh,

34
00:02:04.070 --> 00:02:08.360
and it continues to be high utility because I feel like it's my

35
00:02:08.361 --> 00:02:10.670
responsibility. And I feel, I think you, you,

36
00:02:10.671 --> 00:02:14.120
and Emily's clearly feel similarly where it's my responsibility to try and put

37
00:02:14.121 --> 00:02:17.090
some positive sentiments or ideas, uh,

38
00:02:17.120 --> 00:02:21.410
out there because people kind of turn to me for a sense of

39
00:02:21.650 --> 00:02:25.300
uplift. And I, you know, I'm very touched by that and I,

40
00:02:25.301 --> 00:02:28.970
I want to be that. Uh, and, and,

41
00:02:29.050 --> 00:02:33.590
and so it's, it's like a function of, uh,

42
00:02:33.950 --> 00:02:38.660
who I am now and part of my professional role. Um, but it,

43
00:02:38.720 --> 00:02:40.910
occasionally someone in my Twitter feed will be like, Oh,

44
00:02:40.911 --> 00:02:45.380
I'm trying to get off Twitter. I'm like, go me.

45
00:02:46.190 --> 00:02:49.880
I have friends in Silicon Valley who could not watch Silicon Valley or show on

46
00:02:49.881 --> 00:02:53.660
HBO because they said it just hit too close to home. They were like,

47
00:02:53.661 --> 00:02:54.494
it's too real.

48
00:02:55.210 --> 00:02:58.430
<v 0>Well, the first time, it's really interesting because our show,</v>

49
00:02:58.431 --> 00:03:03.310
we started filming in 2011, I think maybe 2000,

50
00:03:04.570 --> 00:03:09.100
maybe 2013, I forget. But when we, when I was doing the pilot, you know, it was,

51
00:03:09.101 --> 00:03:12.250
my judge was HBO. I told my friends, I was, if I'm doing this pilot,

52
00:03:12.280 --> 00:03:13.990
they're like, what was it? What's it about it? And I said,

53
00:03:13.991 --> 00:03:17.110
it's called Silicon Valley. And they were like, Oh, is it set in the nineties?

54
00:03:17.770 --> 00:03:21.040
I'm like, no, there's crazy going on in Silicon Valley right now.

55
00:03:21.070 --> 00:03:25.480
It's weird to think back then, we didn't know. I mean, some people did,

56
00:03:25.481 --> 00:03:28.960
but we didn't know who Elon Musk was. We didn't know who Peter teal was. Like,

57
00:03:28.961 --> 00:03:33.790
people had not heard these names. Now these are household names. Um,

58
00:03:34.390 --> 00:03:38.140
in the six years that we ran or the seven years that we ran,

59
00:03:38.141 --> 00:03:42.730
the way that people look at Silicon Valley has changed so quickly.

60
00:03:43.240 --> 00:03:44.110
And for me,

61
00:03:44.111 --> 00:03:47.410
it was a real wake up call because I think it was season two or three,

62
00:03:47.980 --> 00:03:50.530
we would sort of do these trips, right.

63
00:03:50.560 --> 00:03:53.950
We would go to Silicon Valley and we would show the episode and we'd sort of

64
00:03:53.951 --> 00:03:56.860
like tour companies and get to see what they were working on.

65
00:03:56.940 --> 00:04:00.640
And they were very excited to have us because, because, you know, we're,

66
00:04:01.300 --> 00:04:04.570
we're doing a show about, about, uh, about what they do.

67
00:04:05.140 --> 00:04:09.970
I was done at what little thought was

68
00:04:09.971 --> 00:04:14.560
going into the moral and ethical ramifications of the technology that they were

69
00:04:14.561 --> 00:04:18.700
working on. Um, I remember I won't name the company,

70
00:04:18.701 --> 00:04:20.710
but they were showing us this new product.

71
00:04:20.740 --> 00:04:23.530
That's now on the market that many people have. And they were like,

72
00:04:23.531 --> 00:04:25.270
you can do this, you can do this, I can do this.

73
00:04:25.330 --> 00:04:28.960
And so we brought up a privacy concern and it wasn't,

74
00:04:29.500 --> 00:04:30.730
they didn't have,

75
00:04:32.050 --> 00:04:35.080
they were shocked that they were asked this question.

76
00:04:35.680 --> 00:04:40.090
They didn't even have like a fake corporate answer ready to go.

77
00:04:40.210 --> 00:04:44.770
They were stunned and a little upset and disappointed that we would even think

78
00:04:44.771 --> 00:04:48.220
of that. I feel like there's a sense in the tech world. And, and I'm sure,

79
00:04:48.640 --> 00:04:50.860
you know, this much better than I do.

80
00:04:51.340 --> 00:04:55.180
The technology is completely amoral. Uh,

81
00:04:55.240 --> 00:04:58.450
it's a tool you make it and how it's used. Well, it's not up to us.

82
00:04:58.900 --> 00:05:01.510
I don't think that's right. I think first of all,

83
00:05:01.511 --> 00:05:04.120
there's no way that laws can keep up with technology.

84
00:05:04.121 --> 00:05:08.430
And I do think it's the responsibility of people developing this technology to

85
00:05:08.440 --> 00:05:13.240
consider, uh, the negative, the possible negative uses for it. You know?

86
00:05:13.630 --> 00:05:18.100
Um, I can, I mean, the, the deep, fake stuff, all that stuff,

87
00:05:18.570 --> 00:05:23.530
I don't think you can just like keep developing and close your eyes and ears to

88
00:05:23.531 --> 00:05:27.820
the fact that these things can be, can be really misused.

89
00:05:29.730 --> 00:05:32.340
<v 1>They're being misused every day. Um, in part,</v>

90
00:05:32.341 --> 00:05:35.550
because they serve the almighty marketplace and we know right now the

91
00:05:35.551 --> 00:05:39.540
marketplace just wants to monetize Austin, our attention, um,

92
00:05:39.570 --> 00:05:41.820
whether or not that's good for democracy,

93
00:05:41.970 --> 00:05:46.320
our mental health humanity free will our ability to come together and solve

94
00:05:46.321 --> 00:05:50.520
problems. Our ability to settle on back to the truth. Uh, you know, we're,

95
00:05:50.521 --> 00:05:54.840
we're all now, uh, just subject to this, this, uh,

96
00:05:54.870 --> 00:05:57.350
surveillance capitalism machine, uh,

97
00:05:57.410 --> 00:06:02.300
that sells and resells us to the tune of 200 billion plus a year. Yeah.

98
00:06:02.800 --> 00:06:05.350
<v 0>That's what you always hear where you're like, if the app is free,</v>

99
00:06:05.351 --> 00:06:06.340
you're the product.

100
00:06:07.600 --> 00:06:09.610
<v 1>And so right now,</v>

101
00:06:09.620 --> 00:06:14.440
I'm trying to help people wake up to what's going on with our data

102
00:06:14.800 --> 00:06:15.790
and our privacy rights.

103
00:06:15.791 --> 00:06:19.630
There's actually a prompt in California in November prop 24,

104
00:06:19.631 --> 00:06:24.550
that I'm super excited about that it's going to create a dedicated,

105
00:06:25.270 --> 00:06:25.300
uh,

106
00:06:25.300 --> 00:06:29.170
data protection agency in the state of California to look out for California,

107
00:06:29.680 --> 00:06:32.440
uh, data and privacy rights, which right now a lot of companies are frankly,

108
00:06:32.441 --> 00:06:35.080
just totally abusing and just be like, whatever, like there's no enforcement,

109
00:06:35.081 --> 00:06:39.790
of course. So if prop 24 passes in November, then all of a sudden, uh,

110
00:06:39.910 --> 00:06:43.180
the state has to create an enforcement agency and mechanism.

111
00:06:43.270 --> 00:06:46.870
And then you're going to see corporate behavior change because until there's

112
00:06:47.440 --> 00:06:50.110
until deal, actually someone looking after it and then showing up and saying,

113
00:06:50.111 --> 00:06:53.890
Hey, there's a problem here. Uh, so, so believe it or not,

114
00:06:53.891 --> 00:06:55.510
this stuff is the cutting edge right now.

115
00:06:55.540 --> 00:06:58.030
This does literally on the ballot in like a matter of weeks.

116
00:06:58.900 --> 00:07:02.170
<v 0>Good. I mean, that's the tricky thing, you know, if you see like these hearings,</v>

117
00:07:02.171 --> 00:07:05.470
when wouldn't like Zuckerberg or at any of these folks go,

118
00:07:05.980 --> 00:07:09.070
the questions they're being asked, it's, it's scary.

119
00:07:11.880 --> 00:07:12.850
<v 1>It's not inspiring stuff.</v>

120
00:07:13.090 --> 00:07:17.410
<v 0>About the most basic text stuff. Like it just is.</v>

121
00:07:18.130 --> 00:07:22.450
It's really upsetting that, um, I honestly,

122
00:07:22.451 --> 00:07:26.500
I mean this pro prop 24, but he has on prop 24. That's good. I'm gonna,

123
00:07:26.530 --> 00:07:27.070
I'm gonna,

124
00:07:27.070 --> 00:07:31.870
I'm gonna use to do it to get that word out because I do think that that

125
00:07:31.871 --> 00:07:36.430
is sort of the big existential crisis that we're heading towards right now is,

126
00:07:36.970 --> 00:07:41.470
is, um, is a big tack. I think, I think it's a formidable for,

127
00:07:41.471 --> 00:07:46.060
I feel like for all the great stuff that the internet has done,

128
00:07:46.210 --> 00:07:51.130
I think it's, it's, it's, I mean, you know, it's, it's,

129
00:07:51.310 --> 00:07:55.180
it's fractured the conversations so much to the point where it's not even a

130
00:07:55.181 --> 00:07:57.970
conversation. I remember when I was a computer science major,

131
00:07:58.780 --> 00:08:00.460
I would go to my professor's office.

132
00:08:00.850 --> 00:08:04.480
And he was this guy who was like a philosopher and a computer scientist.

133
00:08:04.930 --> 00:08:09.100
And he was one of the original guys who was involved with the internet and

134
00:08:09.101 --> 00:08:09.520
stuff.

135
00:08:09.520 --> 00:08:14.290
And he had this quote on his desk from a group of early people who were sort of

136
00:08:14.291 --> 00:08:18.640
trying to talk about technology and the benefits it's going to provide humanity.

137
00:08:18.641 --> 00:08:23.530
And it said something like the rise of the internet is the promise

138
00:08:23.531 --> 00:08:27.730
of the return of voice. Um, and I found that so inspiring. I was like,

139
00:08:27.760 --> 00:08:28.570
that's true.

140
00:08:28.570 --> 00:08:33.280
The promise of the internet is I can talk to someone in Bulgaria. You know,

141
00:08:33.281 --> 00:08:35.380
I can like have a real conversation with them.

142
00:08:35.381 --> 00:08:38.980
You really can connect with people who have different experiences from your

143
00:08:38.981 --> 00:08:41.680
different perspectives from you see the world entirely differently,

144
00:08:41.740 --> 00:08:43.720
and you can have a conversation with them.

145
00:08:44.500 --> 00:08:48.310
And reality what's happened is you just find the people who exactly agree with

146
00:08:48.311 --> 00:08:49.144
you.

147
00:08:49.240 --> 00:08:52.300
And then you just talk amongst yourselves and then you yell at the other people

148
00:08:52.301 --> 00:08:57.170
who disagree with you. So, uh, it it's gone in a completely different direction.

149
00:08:57.240 --> 00:08:59.790
I think these original sort of, uh,

150
00:08:59.850 --> 00:09:03.780
tech thinkers had thought had thought it would. Um, and I,

151
00:09:03.781 --> 00:09:07.740
I don't know how, I don't know.

152
00:09:07.800 --> 00:09:09.150
I don't know where we go.

153
00:09:09.151 --> 00:09:12.540
I feel like the internet is like this third print that we made.

154
00:09:12.541 --> 00:09:14.010
That's not swallowing as whole.

155
00:09:15.380 --> 00:09:15.440
<v 1>Uh,</v>

156
00:09:15.440 --> 00:09:19.790
one of my goals is to get the serpent under control Camille and I may actually

157
00:09:19.791 --> 00:09:23.000
have that job, uh, before too long. If,

158
00:09:23.060 --> 00:09:24.710
if things headed in a particular direction.

159
00:09:25.460 --> 00:09:27.530
<v 0>I hope they head in a particular direction.</v>

160
00:09:29.720 --> 00:09:32.930
<v 1>You know, it's funny. I was just using device off the fact that, uh,</v>

161
00:09:32.960 --> 00:09:37.070
I feel like you're one of the most prominent voices in this direction because of

162
00:09:37.071 --> 00:09:40.280
Silicon Valley, which is sort of ironic because obviously it, you know,

163
00:09:40.281 --> 00:09:45.020
it was a television show. And yet I feel like everyone identifies you so closely

164
00:09:46.790 --> 00:09:50.210
with this set of issues. It part, because, you know,

165
00:09:50.211 --> 00:09:53.390
we just watched you on HBO for years on end. I know.

166
00:09:53.700 --> 00:09:55.490
<v 0>Just saying stuff that they wrote for me,</v>

167
00:09:55.491 --> 00:09:59.120
I really shouldn't be the guy don't look to me for any insight into it. But,

168
00:09:59.510 --> 00:10:04.070
but, you know, we, we, the, the writers and the creators were very, very,

169
00:10:04.071 --> 00:10:06.800
I mean, they knew all these CEOs, right? So.

170
00:10:07.280 --> 00:10:09.210
<v 1>It's all real, like, you know, the,</v>

171
00:10:09.211 --> 00:10:11.420
the fact that it's like art imitating life or whatnot,

172
00:10:11.450 --> 00:10:15.230
plus the fact that you you're genuinely like a computer science crowd who worked

173
00:10:15.231 --> 00:10:17.000
in the field for years. Uh,

174
00:10:17.030 --> 00:10:19.610
so I don't know if that helped them cast you and they're like, Oh,

175
00:10:19.611 --> 00:10:20.750
this guy's really convincing.

176
00:10:23.390 --> 00:10:27.710
<v 0>Well, no, because I was really bad at computer science. I never got it,</v>

177
00:10:27.711 --> 00:10:28.640
but I was just,

178
00:10:28.850 --> 00:10:32.890
it's funny to go from sitting behind a row of computers,

179
00:10:32.900 --> 00:10:34.700
being the worst guy to then being,

180
00:10:35.180 --> 00:10:37.640
on-set sitting behind the Royal computers and being the best guy.

181
00:10:37.880 --> 00:10:41.810
Like I was the only one out of the cast that like understood a little bit what

182
00:10:41.811 --> 00:10:43.790
the code was. Uh, so that was.

183
00:10:43.880 --> 00:10:46.370
<v 1>Weird experience. Thank you for listening in,</v>

184
00:10:46.371 --> 00:10:50.690
I hope you enjoyed this conversation. If you did, please do subscribe to yang,

185
00:10:50.691 --> 00:10:54.290
speaks and click on notifications so we can let you know every time we have a

186
00:10:54.291 --> 00:10:54.800
new episode.

