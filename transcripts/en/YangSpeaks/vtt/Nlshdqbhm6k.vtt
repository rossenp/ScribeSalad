WEBVTT

1
00:00:00.150 --> 00:00:01.710
<v 0>The big thing, I want to pick your brain on.</v>

2
00:00:01.711 --> 00:00:05.400
So I'm so full disclosure because this might entertain you. People would,

3
00:00:05.580 --> 00:00:09.210
I would say things on the trail like, Hey, I'm

4
00:00:10.800 --> 00:00:13.140
quoting you. I, sometimes I attributed, sometimes I did.

5
00:00:13.141 --> 00:00:13.974
And I knew you wouldn't care.

6
00:00:14.970 --> 00:00:18.420
I would say we have some of the smartest engineers in the country turning super

7
00:00:18.421 --> 00:00:21.630
computers into dopamine delivery devices for our kids.

8
00:00:21.631 --> 00:00:25.500
And it's having a disastrous effect on our mental health teenage girls in

9
00:00:25.501 --> 00:00:29.550
particular, according to Jonathan Hayden and Jean Twain used data. Um,

10
00:00:29.670 --> 00:00:34.620
and then every parent in Iowa, New Hampshire who heard this were like, yeah,

11
00:00:34.650 --> 00:00:39.060
because they see their kids getting addicted to their screens and you know,

12
00:00:39.061 --> 00:00:41.940
it's not great for their development. And then they would turn to me and say,

13
00:00:41.941 --> 00:00:44.070
what are we going to do about it? And that I would say,

14
00:00:44.071 --> 00:00:48.660
you know what we're going to do? Here's where, I don't know if you said this.

15
00:00:48.661 --> 00:00:52.410
I said, as your president, I'm going to start at a pension, the tent, uh,

16
00:00:52.430 --> 00:00:53.970
department of the attention economy.

17
00:00:54.270 --> 00:00:58.680
And I'm going to have my friend Tristan Harris wrote it just on his bed

18
00:00:59.190 --> 00:01:00.023
bed,

19
00:01:00.330 --> 00:01:03.510
trying to change the design decisions of these tech companies for years now,

20
00:01:03.540 --> 00:01:06.630
most of them, you know, just gave like, Oh, like, you know,

21
00:01:06.631 --> 00:01:11.070
Andrew knows someone specifically who has the right thinking on this.

22
00:01:11.580 --> 00:01:14.490
But, uh, if we were to play that scenario out,

23
00:01:14.820 --> 00:01:18.750
what do we need to do to try and, uh,

24
00:01:18.780 --> 00:01:22.110
humanize our technology and our use of it.

25
00:01:23.780 --> 00:01:28.670
<v 1>First. I just want to say a few things to what you shared. Um, man. Yeah. Well,</v>

26
00:01:28.800 --> 00:01:29.420
I just want to say,

27
00:01:29.420 --> 00:01:33.980
I appreciate it so much that you like with universal basic income and like with

28
00:01:33.981 --> 00:01:35.870
other aspects of your platform, you,

29
00:01:36.140 --> 00:01:40.730
I think have always prioritized to kind of public education in your work, um,

30
00:01:40.760 --> 00:01:43.760
and trying to help people understand and elevate issues that are not being

31
00:01:43.761 --> 00:01:46.160
talked about and using your presidential campaign to do that.

32
00:01:46.161 --> 00:01:47.720
I think that was amazing.

33
00:01:47.721 --> 00:01:51.020
You did that with UBI and you've also been doing that with the attention economy

34
00:01:51.050 --> 00:01:54.800
and, um, you know, I think you helped make it even a bigger issue.

35
00:01:54.801 --> 00:01:57.620
And I just really want to say, I really appreciated that, that you,

36
00:01:57.650 --> 00:01:59.990
you led the way, uh, on, on elevating it as,

37
00:01:59.991 --> 00:02:03.530
as I think to its rightful position as one of the top issues facing society,

38
00:02:03.531 --> 00:02:06.860
because it's underneath and exacerbating all the other issues.

39
00:02:07.340 --> 00:02:10.850
<v 0>It makes it impossible to solve any problems if we can't even agree on reality.</v>

40
00:02:11.060 --> 00:02:12.920
<v 1>Exactly, exactly. And that's what we say in the film.</v>

41
00:02:12.921 --> 00:02:15.710
So clearly is if we can't agree in reality, we can't solve any problem.

42
00:02:15.711 --> 00:02:19.220
Whether it's climate change poverty or social justice and racism or whatever we

43
00:02:19.221 --> 00:02:23.090
want to, we want to deal with. So truth be told,

44
00:02:23.091 --> 00:02:25.940
this is not an easy thing to regulate. Um,

45
00:02:26.180 --> 00:02:28.280
it has to do with core business models.

46
00:02:28.281 --> 00:02:33.170
I do think we can look to ways that the climate movement

47
00:02:33.171 --> 00:02:37.820
thinks about an increasing over time tax, um,

48
00:02:37.850 --> 00:02:40.910
to carbon, you know, to, to carbon externalities setting a price on carbon.

49
00:02:40.940 --> 00:02:43.730
You know, so essentially as we've talked about, um,

50
00:02:43.760 --> 00:02:47.360
this is an extractive economy where instead of extracting oil out of the ground

51
00:02:47.361 --> 00:02:51.830
and then producing, you know, climate change at a global level in the commons,

52
00:02:51.831 --> 00:02:54.940
depleting the environmental commons and also eroding the,

53
00:02:54.941 --> 00:02:58.940
the life support systems of the planet. That's the fossil fuel economy in this.

54
00:02:59.380 --> 00:03:03.790
We have an extractive economy built on not just extracting human attention,

55
00:03:03.791 --> 00:03:06.430
but as we talked about in an earlier interview, we did, um,

56
00:03:06.460 --> 00:03:08.920
fracking for human attention because, uh,

57
00:03:08.921 --> 00:03:12.310
we're worth more also when we're multitasking, um, really quickly on that,

58
00:03:12.311 --> 00:03:15.700
we're worth more when you have a tablet, a phone and your television up,

59
00:03:15.730 --> 00:03:17.590
and that triples the size of the attention economy,

60
00:03:17.591 --> 00:03:19.630
because now you're paying attention to three things.

61
00:03:20.130 --> 00:03:24.310
<v 2>So dark, but one.</v>

62
00:03:24.630 --> 00:03:27.600
<v 1>The thing that very much like that when you use the metaphor of fracking for</v>

63
00:03:27.601 --> 00:03:31.320
attention, you start to see that we're selling just like the financial crisis,

64
00:03:31.710 --> 00:03:36.660
thinner and thinner slices of human attention as if it's worth the

65
00:03:36.661 --> 00:03:39.900
same as valuable, concentrated attention. But it's kind of junk attention,

66
00:03:39.901 --> 00:03:44.040
just like we're selling thinner and thinner credit default swap type junk

67
00:03:44.041 --> 00:03:45.450
instruments, financial instruments,

68
00:03:45.750 --> 00:03:49.590
and selling it as if it's this bigger thing and propping up this kind of

69
00:03:49.591 --> 00:03:53.100
inflated, uh, advertising attention market. Um,

70
00:03:53.101 --> 00:03:57.060
so I think one thing we can do is we can correct for that inflation. Um,

71
00:03:57.090 --> 00:03:57.241
you know,

72
00:03:57.241 --> 00:04:00.420
I think there's one study from a couple of years ago where Facebook was found to

73
00:04:00.421 --> 00:04:05.010
inflate the amount of advertising reporting that it did for their

74
00:04:05.011 --> 00:04:09.210
advertisers by 900%, meaning they exaggerated how much, um,

75
00:04:09.240 --> 00:04:13.350
the viewership or clicks there was by 900%. So that's just like, you know,

76
00:04:13.351 --> 00:04:17.520
a financial broker exaggerating the value of a financial instrument by bylaws.

77
00:04:17.550 --> 00:04:22.080
So we can kind of clean up, um, comprehensively this systemically,

78
00:04:22.081 --> 00:04:26.250
fragile, uh, fragility creating system so much like you want to, you,

79
00:04:26.251 --> 00:04:29.310
can't just say, we're going to get completely off of oil in one year.

80
00:04:29.311 --> 00:04:32.910
And carbon prices are going to be set to a million dollars a ton,

81
00:04:32.940 --> 00:04:36.540
and we're going to move over. You set up a transition plan over 10 years.

82
00:04:36.900 --> 00:04:41.880
So I think what we need is a transition plan from each company maximizing how

83
00:04:41.881 --> 00:04:46.680
much attention that they kind of extract to winding down how much

84
00:04:46.710 --> 00:04:50.730
commodification of human attention that we can do over time. Um,

85
00:04:50.760 --> 00:04:53.880
one model of this actually comes from, uh,

86
00:04:53.940 --> 00:04:56.130
the way that we regulate energy companies,

87
00:04:56.460 --> 00:04:59.880
because it used to be that PG and E or con Edison or whatever your energy

88
00:04:59.881 --> 00:05:02.640
company is. There are for-profit company, uh,

89
00:05:02.670 --> 00:05:05.250
theoretically they want you to use as much energy as possible.

90
00:05:05.251 --> 00:05:08.730
So leave the lights on, leave the faucets on maximize.

91
00:05:08.970 --> 00:05:13.470
You're just wasting of energy and you're maximizing climate pollution, you know,

92
00:05:13.500 --> 00:05:14.760
activity and behavior.

93
00:05:15.000 --> 00:05:18.600
They can even put those nests in your home and then maximize how much you use to

94
00:05:18.601 --> 00:05:20.280
like manipulate you into using the most.

95
00:05:20.580 --> 00:05:22.320
That would be a kind of dystopian reality.

96
00:05:22.860 --> 00:05:27.810
<v 2>Our, our, our recommended home temperature is 95 degrees. Exactly,</v>

97
00:05:28.170 --> 00:05:29.760
exactly. And get you to change.

98
00:05:29.880 --> 00:05:32.340
<v 1>All the time and, you know, um, anyway,</v>

99
00:05:32.370 --> 00:05:36.000
so obviously that would be an extractive kind of business.

100
00:05:36.210 --> 00:05:38.340
And it's fundamentally misaligned with the comments because it,

101
00:05:38.430 --> 00:05:40.140
it accelerates climate change, et cetera.

102
00:05:40.500 --> 00:05:43.650
So we've dealt with this problem before we actually have regulated utilities

103
00:05:43.950 --> 00:05:48.360
that, um, set, um, seasonal targets for how much money you can make as a,

104
00:05:48.361 --> 00:05:51.870
as a utility off of a certain amount of energy. So for example,

105
00:05:52.110 --> 00:05:54.510
if there's a seasonal availability of so much energy,

106
00:05:54.780 --> 00:05:56.910
it costs this much for this lower tier two.

107
00:05:57.650 --> 00:06:00.680
And then if you're a consumer and you use, let's say beyond that amount,

108
00:06:01.010 --> 00:06:02.120
because it's a hot summer,

109
00:06:02.360 --> 00:06:05.930
they actually double charge you for that next phase of, of, um,

110
00:06:06.140 --> 00:06:07.220
of energy that you're using.

111
00:06:07.520 --> 00:06:12.110
Except those extra profits don't go into the coffers of PGNE or con Edison.

112
00:06:12.350 --> 00:06:14.900
They go into a public fund, uh,

113
00:06:14.930 --> 00:06:18.440
that actually invests in the renewable energy infrastructure that we need.

114
00:06:18.860 --> 00:06:20.630
So that's a nice, I don't know if you've got the bits,

115
00:06:20.720 --> 00:06:22.520
they're sort of a nice transition plan of.

116
00:06:22.690 --> 00:06:24.130
<v 0>Oh, I see all I caught that.</v>

117
00:06:26.900 --> 00:06:28.630
<v 1>You probably know these better than I do, frankly.</v>

118
00:06:28.810 --> 00:06:30.910
<v 0>But no, no, no, no, no. So let me,</v>

119
00:06:30.970 --> 00:06:34.750
let me just try and walk through this just for fun. So let's say, um,

120
00:06:34.780 --> 00:06:37.630
you and I are getting together and we're part of the department of detached

121
00:06:37.631 --> 00:06:42.310
economy and we're like, all right, Hey, Facebook, here's the deal. Um,

122
00:06:42.490 --> 00:06:44.530
we, we find you, um,

123
00:06:45.250 --> 00:06:49.960
excessively extractive in terms of the amount of attention you're getting from

124
00:06:49.961 --> 00:06:51.460
folks. So step number one,

125
00:06:51.790 --> 00:06:54.100
stop exaggerating the amount of time we actually spend on you.

126
00:06:54.330 --> 00:06:56.680
That's that's number one, but number two, um,

127
00:06:56.830 --> 00:07:00.340
for every bit of attention you get beyond a certain period,

128
00:07:00.341 --> 00:07:05.320
let's call it like our, uh, four plus for a teenager.

129
00:07:05.770 --> 00:07:10.330
Like there's actually like some negative social value associated with that. Um,

130
00:07:10.360 --> 00:07:15.280
so we're going to have you pay a penalty,

131
00:07:16.240 --> 00:07:20.230
um, and then use that penalty then to fund some alternatives,

132
00:07:20.260 --> 00:07:23.950
let's call it like little leagues or whatever,

133
00:07:24.670 --> 00:07:28.990
but something that, that would be like the anti, um,

134
00:07:29.050 --> 00:07:33.910
Facebook, um, uh, type of countermeasure, uh,

135
00:07:33.970 --> 00:07:35.680
is that more or less accurate?

136
00:07:36.820 --> 00:07:40.390
<v 1>Well, I also want to say this is a tiny part of a,</v>

137
00:07:40.391 --> 00:07:43.690
probably a more comprehensive way of dealing with these problems, but I think,

138
00:07:44.500 --> 00:07:45.760
um, there's an, there's a part of it,

139
00:07:45.761 --> 00:07:50.170
which is that we have to remove some of the perverse incentives. Um,

140
00:07:50.740 --> 00:07:52.990
you're what you're saying now reminds me of something. I said,

141
00:07:52.991 --> 00:07:56.350
when I went to the can con whatever you say, call it, uh,

142
00:07:56.710 --> 00:08:00.790
pronounce it advertising festival, where, um, you know,

143
00:08:00.970 --> 00:08:03.850
we were talking to the advertisers that fund all this activity and these mental

144
00:08:03.851 --> 00:08:06.940
health harms and said, um, you know,

145
00:08:06.941 --> 00:08:10.810
after there's a mental health crisis from kids, and there's a loneliness crisis,

146
00:08:11.050 --> 00:08:13.540
someone's gonna ask the question who paid for all of this to happen.

147
00:08:14.290 --> 00:08:15.760
And it's obviously these advertisers.

148
00:08:15.761 --> 00:08:19.360
And one of the things we proposed was imagine you just simply cannot make money

149
00:08:19.361 --> 00:08:22.690
from usage between, let's say midnight and six in the morning.

150
00:08:22.691 --> 00:08:27.520
If you're a tech company that disincentivizes usage of sort of late night

151
00:08:27.521 --> 00:08:32.290
lonely use that sort of the low willpower period of, of, of use. Now,

152
00:08:32.530 --> 00:08:33.340
that's, that's definitely.

153
00:08:33.340 --> 00:08:35.020
<v 0>Again, I don't know what you're talking about. Tristan.</v>

154
00:08:35.021 --> 00:08:39.820
I have never done any low willpower to attack social media use between those

155
00:08:39.821 --> 00:08:40.654
hours.

156
00:08:42.910 --> 00:08:45.700
<v 1>I think you, you were the superhuman willpower, a one among us.</v>

157
00:08:47.440 --> 00:08:49.630
<v 0>Kidding. We've all done it, but it's,</v>

158
00:08:49.840 --> 00:08:53.920
but I love that idea so much where you cordon off a number of hours where you're

159
00:08:53.921 --> 00:08:57.900
like, look, extracting attention in these hours is, is not, not a good thing.

160
00:08:58.210 --> 00:09:00.230
<v 1>It's like treating a park, you know, those trees,</v>

161
00:09:00.231 --> 00:09:03.230
some of the trees we extract and we turn into lumber, other trees, we say,

162
00:09:03.231 --> 00:09:06.500
this is part of a national park and there for walking and exploring and

163
00:09:06.501 --> 00:09:11.000
enjoying, right? And it's like, some of our attention can be maybe, you know,

164
00:09:11.030 --> 00:09:14.330
part of, uh, a system that obviously wants to commoditize it.

165
00:09:14.360 --> 00:09:14.991
But that's another thing.

166
00:09:14.991 --> 00:09:19.940
Is there sort of a violation of turning alive humanness and alive human choice

167
00:09:20.210 --> 00:09:24.440
into these dead slabs of human behavior through behavior modification engines,

168
00:09:24.441 --> 00:09:25.070
right? So we can,

169
00:09:25.070 --> 00:09:29.000
we turn like alive consciousness into this sort of dead end consciousness in

170
00:09:29.001 --> 00:09:32.300
which your behavior is more or less predictable because we've taken what could

171
00:09:32.301 --> 00:09:35.330
be a free choice and turn it into an unconscious habit,

172
00:09:35.540 --> 00:09:38.060
which is a form of kind of like dead lumber is to a tree.

173
00:09:38.061 --> 00:09:41.060
What dead human behavior is to alive human being.

174
00:09:41.450 --> 00:09:44.120
There's many different aspects of this that I think we have to correct.

175
00:09:44.121 --> 00:09:47.090
I think what we need here is overall something more comprehensive,

176
00:09:47.091 --> 00:09:49.400
just like with the financial crisis. If you asked me Andrew and say,

177
00:09:49.410 --> 00:09:52.220
what's the one law that we passed, that's going to fix all this.

178
00:09:52.520 --> 00:09:56.180
I like your approach that this is sort of an ongoing issue and that we need a

179
00:09:56.181 --> 00:09:59.360
cabinet level department of the attention economy to, uh,

180
00:09:59.420 --> 00:10:00.590
to deal with these problems.

181
00:10:02.030 --> 00:10:04.040
<v 0>Oh, let's dig into the tool kit a little bit more,</v>

182
00:10:04.190 --> 00:10:06.620
cause I'm already learning a ton from you. Um,

183
00:10:06.650 --> 00:10:11.180
so I love seeing it as something of a negative externality,

184
00:10:11.210 --> 00:10:13.250
like attention beyond a certain point where you say,

185
00:10:13.251 --> 00:10:17.120
look like I was thinking beyond our ex, um,

186
00:10:17.150 --> 00:10:20.630
is probably not a great thing for you. I love your saying,

187
00:10:20.631 --> 00:10:23.920
look between midnight and 6:00 AM probably terrible for

188
00:10:24.950 --> 00:10:29.090
teenagers to be, uh, Facebooking it up or whatnot.

189
00:10:29.300 --> 00:10:32.810
Like what, uh, just throw a few things out there,

190
00:10:32.811 --> 00:10:36.440
like that also belong somewhere in the consideration set or tool kit.

191
00:10:37.220 --> 00:10:40.070
<v 1>Yeah. You know, we're going to be publishing, um, some more on this,</v>

192
00:10:40.071 --> 00:10:42.860
on our website. Soon. I have some of it up here right now,

193
00:10:42.890 --> 00:10:47.180
but I think a more comprehensive approach is something like what we had for the

194
00:10:47.181 --> 00:10:47.961
financial crisis,

195
00:10:47.961 --> 00:10:52.220
where we had a comprehensively risk creating system and we needed a

196
00:10:52.221 --> 00:10:56.210
comprehensive basil three reforms in Europe or the Dodd-Frank kind of reforms,

197
00:10:56.211 --> 00:10:58.340
the United States. I know there's some problems with that,

198
00:10:58.341 --> 00:11:00.890
but that's the magically what we would want to be going after.

199
00:11:01.100 --> 00:11:04.430
So we need protection for kids, privacy, for people, transparency,

200
00:11:04.431 --> 00:11:08.690
for platforms, you can imagine you get section two 30 protections for content,

201
00:11:08.691 --> 00:11:11.630
but not for amplification or recommendation systems.

202
00:11:11.870 --> 00:11:14.960
And in exchange for getting section two 30 protections for those who don't know,

203
00:11:15.200 --> 00:11:19.700
it's what prevents is what enables platforms to not be liable for bad content on

204
00:11:19.701 --> 00:11:21.800
their platforms. But in exchange for that,

205
00:11:21.801 --> 00:11:25.910
there has to be transparency to the public and to many civil society groups,

206
00:11:26.210 --> 00:11:31.190
to be able to say which things we want to measure about the use or, or, um,

207
00:11:31.460 --> 00:11:34.970
prevalence of certain kinds of content so that we can actually do a better job

208
00:11:34.971 --> 00:11:35.720
of regulating them.

209
00:11:35.720 --> 00:11:38.900
Cause we don't even have transparency now about how bad is the teenage mental

210
00:11:38.901 --> 00:11:39.441
health problem.

211
00:11:39.441 --> 00:11:43.310
How many users beneath the age of 16 are using it between two and four in the

212
00:11:43.311 --> 00:11:44.960
morning. If we had transparency,

213
00:11:44.961 --> 00:11:47.780
we could actually make them report not to a board of directors,

214
00:11:47.781 --> 00:11:51.380
but to a board of the people based on these metrics that matter to us in a

215
00:11:51.381 --> 00:11:53.150
democratically governance society.

216
00:11:54.130 --> 00:11:55.210
<v 0>That is enormous.</v>

217
00:11:55.240 --> 00:12:00.040
So modifying section two 30 in those ways would be huge because in many

218
00:12:00.041 --> 00:12:04.240
ways, uh, that is these companies licensed to,

219
00:12:05.050 --> 00:12:07.840
uh, operate in print money really, you know,

220
00:12:08.350 --> 00:12:11.950
and this was written in 96 before any of these companies even existed.

221
00:12:11.951 --> 00:12:12.784
Like we couldn't.

222
00:12:12.860 --> 00:12:15.900
<v 1>Really anticipated YouTube and Facebook and sick talk, you know,</v>

223
00:12:15.960 --> 00:12:16.793
many years later.

224
00:12:18.030 --> 00:12:18.391
<v 0>Yeah.</v>

225
00:12:18.391 --> 00:12:23.070
So we need to examine this license essentially.

226
00:12:23.071 --> 00:12:27.060
And what you're suggesting is a difference between, um,

227
00:12:27.180 --> 00:12:30.150
posting content, um, and then, uh,

228
00:12:30.180 --> 00:12:34.560
spreading advertising content or messages or videos that there's some kind of

229
00:12:34.561 --> 00:12:37.680
commercial incentive attached to. Um, so that's a very,

230
00:12:37.800 --> 00:12:40.020
that's a very interesting distinction. Um,

231
00:12:40.050 --> 00:12:42.990
the other interesting thing you're attaching to it is to say, look,

232
00:12:43.230 --> 00:12:45.120
we're going to give you this. And in some cases,

233
00:12:45.121 --> 00:12:48.300
this franchise is worth billions, even trillions of dollars,

234
00:12:48.540 --> 00:12:49.860
but in return we get data,

235
00:12:49.980 --> 00:12:53.640
they get real data about what the actual public harms are. Um,

236
00:12:53.670 --> 00:12:56.940
because if you compare this to a negative externality where you look at,

237
00:12:57.240 --> 00:12:59.670
you know, for example, with pollution, you look around and say, okay, there's,

238
00:12:59.880 --> 00:13:02.700
uh, uh, you know, there are negative effects through climate change.

239
00:13:02.730 --> 00:13:03.211
And this one,

240
00:13:03.211 --> 00:13:06.000
we actually need the data that the social media companies have in order to

241
00:13:06.001 --> 00:13:08.550
measure, um, a lot of the harms.

242
00:13:08.880 --> 00:13:10.170
<v 1>Right? And so this is table stakes.</v>

243
00:13:10.171 --> 00:13:11.910
This is not the thing that answers the problems.

244
00:13:11.911 --> 00:13:14.790
This is the sort of prerequisite for being able to do anything, a metaphor.

245
00:13:14.791 --> 00:13:17.010
I often have Andrew, since you're using these climate change,

246
00:13:17.011 --> 00:13:19.980
analogies is it's like Facebook is like Exxon,

247
00:13:20.040 --> 00:13:22.170
but they're the Exxon of human anxiety,

248
00:13:22.440 --> 00:13:26.760
except they also don't just own the kind of, you know, extraction of oil.

249
00:13:26.940 --> 00:13:31.110
They also own the entire satellite network that we have to observe and measure

250
00:13:31.111 --> 00:13:32.460
how much CO2.

251
00:13:33.480 --> 00:13:36.780
So they actually control the measurement of how bad the problem is.

252
00:13:37.140 --> 00:13:38.970
So this is ridiculous. It's almost like it's, you know,

253
00:13:38.971 --> 00:13:40.290
if you take the monopoly conversation,

254
00:13:40.291 --> 00:13:43.590
it's a vertically integrated company that owns both the measurement, you know,

255
00:13:43.591 --> 00:13:47.370
either the exclusive access to measurement of the harm and also the harm

256
00:13:47.371 --> 00:13:51.510
creation. That's a vertically integrated perverse sort of company. Um,

257
00:13:51.540 --> 00:13:53.700
there's also other aspects of freedom from manipulation,

258
00:13:53.730 --> 00:13:56.790
accountability for harms, enabling more, uh, competition.

259
00:13:56.820 --> 00:13:59.430
And we can dig into that because it's less about, as you said,

260
00:13:59.610 --> 00:14:00.840
magically breaking them up,

261
00:14:00.870 --> 00:14:04.530
causes the removal of misinformation or addiction in society because you still

262
00:14:04.531 --> 00:14:07.830
have a race to the bottom to create those problems. Um,

263
00:14:07.860 --> 00:14:11.070
and then also national security, because we haven't talked about that, that,

264
00:14:11.100 --> 00:14:14.940
you know, while we've been obsessed, you know, by some folks, um,

265
00:14:14.970 --> 00:14:17.640
and politicians of protecting our physical borders,

266
00:14:17.820 --> 00:14:20.100
we've been leaving our digital borders wide open.

267
00:14:20.460 --> 00:14:22.230
And this is really important because if Russia,

268
00:14:22.280 --> 00:14:26.250
China tried to fly a plane into the physical United States where they try to get

269
00:14:26.251 --> 00:14:27.840
across the passport controls,

270
00:14:28.050 --> 00:14:31.830
we have huge billions of dollars invested in either shooting down that plane or

271
00:14:32.010 --> 00:14:33.180
stopping them at the border.

272
00:14:33.770 --> 00:14:37.110
<v 0>But none of us would accept it. None of us would accept the fact that you have,</v>

273
00:14:37.170 --> 00:14:41.160
you have 70 countries right now that are, uh, investing in misinformation.

274
00:14:41.161 --> 00:14:41.994
And everyone's like, Oh,

275
00:14:42.470 --> 00:14:45.240
you had 70 countries flying planes through our airspace. We'd all be like,

276
00:14:45.241 --> 00:14:45.990
what the heck is it?

277
00:14:45.990 --> 00:14:47.040
<v 1>That's exactly right. And so,</v>

278
00:14:47.041 --> 00:14:50.770
and so if you think about it as w how much of the surface area of our,

279
00:14:50.960 --> 00:14:55.100
of our country's activity is happens in the physical world and how much of that

280
00:14:55.101 --> 00:14:58.940
surface area is moving into the virtual world of kind of Facebook,

281
00:14:58.941 --> 00:15:01.670
Instagram clicks, advertising, email, et cetera,

282
00:15:02.150 --> 00:15:05.120
and more and more of our economic activity is moving from the physical to the

283
00:15:05.121 --> 00:15:07.400
digital, but we don't protect the digital borders.

284
00:15:07.610 --> 00:15:11.840
So if Russia and China tried to fly an information plane into the virtual

285
00:15:11.841 --> 00:15:15.020
United States, instead of being met by the Pentagon to shoot it down,

286
00:15:15.021 --> 00:15:17.570
they're met by a Facebook algorithm with a white glove that says, yeah,

287
00:15:17.600 --> 00:15:21.410
exactly which zip code or minority group would you like to target with more

288
00:15:21.411 --> 00:15:23.780
divisive information that could stir up culture Wars.

289
00:15:24.140 --> 00:15:28.220
So this is a urgent national security threat that we've been meaning to try to

290
00:15:28.221 --> 00:15:30.920
get, you know, more into the agenda. Cause I think we don't,

291
00:15:31.010 --> 00:15:34.610
we massively underestimate the vulnerability of culture, you know,

292
00:15:34.670 --> 00:15:39.380
after world war two, you know, big powers like Russia, China, Iran, Turkey,

293
00:15:39.410 --> 00:15:41.360
they're not going to, um, you know,

294
00:15:41.630 --> 00:15:43.940
attack the United States with nuclear weapons anymore.

295
00:15:43.941 --> 00:15:46.820
They can't do kinetic warfare. And so what would you do?

296
00:15:46.821 --> 00:15:49.940
You would actually want to take the divisions in a country that already exists,

297
00:15:50.210 --> 00:15:53.720
walk over their virtual borders and stir up culture Wars and racial divides

298
00:15:53.721 --> 00:15:56.900
everywhere, which is exactly what we're seeing them doing. Um,

299
00:15:56.901 --> 00:15:58.970
we also know that Russia has gone after, um,

300
00:15:59.540 --> 00:16:03.270
XUS veteran groups and trying to so more discontent about, you know, uh,

301
00:16:03.510 --> 00:16:05.390
the dark. We know that there are,

302
00:16:05.510 --> 00:16:08.660
we know that Russia is going after environmentalist groups. Um, in fact,

303
00:16:08.810 --> 00:16:10.910
they actually go after in pro environmentalist,

304
00:16:10.970 --> 00:16:15.650
anti-fracking us advocates like Greenpeace and Mack and amplify them because

305
00:16:15.651 --> 00:16:17.570
what happens if in the U S we don't frack,

306
00:16:18.020 --> 00:16:20.930
we have to buy more foreign oil from where from Russia.

307
00:16:21.260 --> 00:16:23.960
So there's many different aspects to this problem,

308
00:16:23.961 --> 00:16:27.380
but I think what people need to know is that this is an, all of our interests.

309
00:16:27.381 --> 00:16:32.360
It's not a partisan issue. Um, it's really a global issue and a national scale.

310
00:16:32.380 --> 00:16:36.730
<v 2>Security issue that affects everyone. Thank you for listening in.</v>

311
00:16:36.731 --> 00:16:41.050
I hope you enjoyed this conversation. If you did, please do subscribe to yang,

312
00:16:41.051 --> 00:16:43.780
speaks and click on notifications so we can let you know,

313
00:16:43.781 --> 00:16:45.190
every time we have a new episode.

